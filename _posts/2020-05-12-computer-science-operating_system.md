---
layout: post
topic: computer-science
title: 운영체제
---

이전 책을 읽으면서 우리가 프로그래밍 하는 모든 것은 운영체제 위에서 실행됨을 알게 되었다.  
그래서 운영체제에 대해 보다 더 알고 싶은 마음이 생겨 운영체제를 다루는 책을 한 권 읽어보았다.  
내가 읽은 책은 Operating System Concepts 으로 소위 공룡책으로 알려진 유명한 책이다.  
읽었다고 하기도 민망할만큼 겉핥기 식으로 읽었지만 그래도 리뷰를 남겨본다.  
글은 목차 별로 나누어 작성한다.  


#### 1장) 서론
    - 운영체제를 바라보는 관점 및 구분과 기초적인 지식을 설명한다. 패스
    
#### 2장) 시스템 구조
    - 운영체제의 대표적인 서비스로 사용자 인터페이스, 프로그램 실행, 입출력 연산, 파일 시스템 조작, 통신, 오류탐지, 
    자원 할당, 자원 관리, 보호 및 보안 등이 있다.  
    - 운영체제를 설계할 때 가장 중요한 원칙 중 하나가 바로 메커니즘과 정책을 분리하는 것이다. 매커니즘은 범용적인 것이 선호된다.  
    - 운영체제는 주로 C/C++ 과 같은 고급언어로 작성되어 있는데, 자주 제기되던 단점은 속도가 느리다는 것이다. 
    그러나 컴퓨터 사양 향상으로 이는 더 이상 문제가 아니다.
    - 운영체제의 구조로는 간단한 구조, 계층적 구조, 마이크로 커널, 모듈 구조 등이 있다.  
    - 간단한 구조는 초기 OS 에서 많이 나타난다. 기능이 예상 범위보다 추가됨에 따라 품질이 저하되는 현상이 있다.  
    - 계층적 구조는 각 층이 직전 층의 API 만을 사용하여 구현된다. 
    어려운 점 중 하나는 각 층마다의 적절한 정의 및 추상화이며, 속도가 느릴 수 있는 단점이 있다.  
    - 마이크로 커널은 최소한의 동작만을 커널 모드로 수행하고, 그 외의 동작은 사용자 공간에서 수행하도록 하는 것이다.
    확장은 용이하지만 가중된 시스템 동작 때문에 오버헤드가 발생하여 성능이 감소한다.  
    - 모듈 구조는 Linux 및 Max OS X 등에서 사용하는 구조로 각 기능을 모듈화하여 구현한다.  
    - 가상기계의 기본적인 아이디어는 한 컴퓨터의 하드웨어를 추상화하여 다수의 다른 실행환경을 제공하는 것이다.  
    - 대표적인 가상기계로는 VMWare, JVM(Java Virtual Machine) 등이 있다.  
    - 커널 고장은 종종 충돌(Crash)라고 불리고, 충돌 덤프에 저장된다.  
    - 컴퓨터가 전원이 켜지면 명령 레지스터는 미리 지정된 메모리 위치를 가리킨다. 이 위치에 운영체제를 로드하기 위한
    매우 작은 부트스트랩 로더가 존재하고, 해당 로더가 실행되며 운영체제가 실행된다.  
    
#### 3장) 프로세스
    - 프로세스 상태는 new(생성 중), running, waiting, ready, terminated 로 나뉜다.
    ready 는 모든 준비가 되어 실행 준비 직전의 상태를 뜻하고 waiting 은 I/O 등에 의하여 대기하고 있는 상태를 뜻한다.
    - 각 프로세스는 PCB(Process Control Block) 에 의해 표현된다.
    PCB의 정보로는 프로세스 상태, 번호, 프로그램 카운터, open file 리스트, 스케쥴링 정보, 메모리 및 레지스터 관련 정보 등이 있다.
    프로세스 카운터는 프로세스가 다음에 실행할 명령어의 주소를 나타낸다.
    - 스레드란 프로세스 내에서의 태스크를 나눠 각각의 태스크가 동시에 수행할 수 있도록 하는 태스크의 개념이다.
    - 스케쥴러는 프로세스의 실행 순서를 결정하기 위해 필요하며 장기, 중기, 단기로 나뉜다. 대부분의 현대 OS 는 단기~중기 스케쥴러를 사용한다.  
    - 문맥 교환(Context Switching) 이란 현재 프로세스의 상태를 저장하고 다른 프로세스를 실행하는 것을 말한다.
    문맥 교환 시간 동안 CPU 는 아무 것도 하지 못하기 때문에 이는 순수한 오버헤드이며, 문맥 교환 시간은 하드웨어 자원에 크게 의존한다.  
    - 프로세스에 대한 대표적 연산으로 생성과 종료가 있다.
    - 프로세스 간 통신(IPC, Interprocess Communication) 를 구성하는 이유로는 정보 공유, 계산 가속화, 모듈성, 편의성 등이 있다.
    구현 방법으로 크게 공유 메모리 사용과 메시징 전달 방법이 있다.
    - 공유 메모리의 경우 유한 버퍼와 무한 버퍼 이슈가 있다. 유한 버퍼일 경우 생산자는 소비자가 소비할 때까지 생산하지 않는다.
    - 메시징 전달 방법은 간접/직접, 동기식/비동기식, 자동/명시적 버퍼링으로 나뉜다.
    - 간접 통신에서 메시지는 port 로 송신되어 소비된다. 
    - 동기식/비동기식은 봉쇄형/비봉쇄형이라고도 표현되며 메시지 송신 수신에 따라 동기식/비동기식으로 처리하는지에 대한 이슈이다.
    - 버퍼는 무용량(이 경우 수신자가 메시지를 수신할 때까지 기다려야 함), 유한 용량, 무한 용량으로 나뉜다.
    - IPC 기법을 활용하여 클라이언트-서버 시스템의 통신에도 사용할 수 있다. 통신 전략은 크게 소켓, RPC 및 파이프 통신으로 나뉜다.
    - 소켓 통신은 양측의 주소와 포트 번호를 필요로 한다. telnet, http, ftp 등 서비스를 구현하는 서버는 특정 포트로부터 메시지를 기다리고 있는 것이다.
    소켓은 다시 TCP(연결 기반 소켓)와 UDP(비연결성 소켓)으로 나뉜다.
    - RPC 는 네트워크에 연결되어 있는 두 시스템 사이의 통신에 사용하기 위하여 프로시저 호출을 추상화하기 위한 방편으로 설계되었다.
    - 대부분의 RPC 시스템은 기종 중립적인 데이터 표현 방식을 정의한다. 대표적인 예가 XDR(external data representation) 이다.
    - RPC를 사용하기 위해 포트 번호를 바인딩해야 하는데, 서버의 포트 번호를 확인하기 위하여 
    사전에 전송 포트를 미리 고정하거나 또는  
    미리 정의되어 있는 고정 RPC 포트를 사용해 서비스 사용 포트 정보를 전송하여 바인딩한다. 이를 랑데부용 디먼(Match Maker)라고 한다.
    - 파이프는 양방향/단방향, 반이중/전이중(양방향 동시 전송 가능 유무), 부모-자식 관계 등 필요 유무, 네트워크 통신 유무로 나뉜다.
    
#### 4장) 다중 스레드 프로그래밍
    - 다중 스레드의 장점으로 응답성, 자원 공유, 경제성, 규모 가변셩이 있다.
    - 다중 코어를 잘 활용하기 위하여 설계자는 작업 나누기, 부하의 균형, 데이터 분리, 데이터 종속성, 시험 및 디버깅에 대한 어려움을 극복해야 한다.
    - 사용자가 생성한 다중 스레드 모델은 커널과의 관계도 고려해야 한다. 다대일 모델, 일대일 모델, 다대다 모델이 있다.
    - 다대일 모델의 경우 다중 스레드를 해도 한 번에 하나의 스레드만 커널에 접근할 수 있기 때문에 병렬로 작동할 수 없다.
    - 일대일 모델은 사용자 스레드가 생성될 때마다 커널 스레드가 생성되어야 하므로 그 수가 커지면 오버헤드가 발생한다. 보통 시스템에 의해 지원 스레드 수가 제한된다.
    - 다대다 모델은 위 두가지 단점을 어느정도 해결했다.
    - 다중 스레드를 구현할 때 (1) Fork() 및 Exec() 시스템 호출 (2) 스레드 취소(비동기식/지연 취소) (3) 신호 처리  
    (4) 스레드 풀 (5) 스레드별 데이터 (6) 스케쥴러 액티베이션(다대다 모델 사용 시 사용자 스레드와 커널 스레드를 맵핑하는 방법) 등을 고려해야 한다.  
    - (6) 스케쥴러 액티베이션을 위해 LWP라 불리는 경량 자료구조가 필요하며, 커널이 응용에 특정 사건을 알려주는 것을 업콜이라고 한다.  
    
#### 5장) CPU 스케쥴링
    - CPU 스케쥴링의 목적은 CPU 이용률을 최대화 하는데에 있다.
    - 프로세스는 CPU-입츌력 버스트 사이클(CPU-I/O Burst Cycle) 로 구성되고, 일반적/통계적으로 CPU 버스트 소요 시간은 지수 분포를 따른다.  
    - 비선점 스케쥴링에서는 일단 CPU가 한 프로세스에 할당되면 프로세스가 종료/대기 상태로 전환될 때까지 CPU를 점유한다.
    - 선점 스케쥴링은 공유 자료에 접근하는 데에 비용을 유발한다. 예를 들어 A 가 자료를 수정하다 B가 실행되면 비일관적인 자료가 나타나는데 이를 해결할 방법이 필요하다.
    - 디스패처(Dispatcher) 는 CPU 제어를 단기 스케쥴러가 선택한 프로세스에 할당한는 모듈이다.
    - 디스패처(Dispatcher) 는 문맥 교환, 사용자 모드 전환, 프로세스 재개 시 특정 위치로 jump 하는 일 등을 한다.  
    - 스케쥴링 기준으로 CPU 이용률, 처리량(단위시간 당 완료 프로세스 개수), 총처리 시간, 대기시간, 응답시간 등이 있다.
    - CPU 스케쥴링으로 선입 선처리 스케쥴링(FCFS, Frist-Come First-Served) 이 쓰일 수 있다.
    모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양보하기 기다리는 것을 호위 효과(Convoy Effect) 라고 한다.  
    - CPU 스케쥴링으로 최단 작업 우선 스케쥴링(SJF, Shortest-Job Frist) 이 쓰일 수 있다.  
    이는 프로세스 전체 길이가 아니라 다음 CPU버스트가 가장 짧은 프로세스에 할당하는 방법이다.  
    실질적으로 CPU 요청 길이를 파악하는 것이 어렵다. 주로 장기 스케쥴링에 쓰인다.  
    단기 스케쥴링에서는 지수평균으로 다음 CPU 버스트 길이를 근사하여 사용한다.  
    - 우선순위 스케쥴링(Priority Scheduling) 은 범용적 스케쥴링으로, SJF 같은 경우 CPU 버스트에 따른 우선순위 스케쥴링이라고 할 수 있다.  
    우선순위 스케쥴링의 문제점은 새롭게 생성되는 프로세스의 우선순위가 기존 프로세스의 우선순위보다 높아 무기한 봉쇄, 다른 말로는 기아 상태에 빠질 수 있다는 점이다.    
    한 가지 해결 방법은 프로세스의 우선순의를 시간이 지남에 따라 점진적으로 높이는 방법이다.  
    - 라운드 로빈 스케쥴링(RR, Round Robin Scheduling) 은 원형 큐로 구현된 준비완료 큐를 돌면서 각 프로세스에 주어진 시간만큼만 CPU를 할당하는 것이다. 시간 할당량에 따라 성능이 좌우된다.  
    - 다단계 큐 스케쥴링(Multilevel Queue Scheduling) 은 준비완료 큐를 별도의 큐로 분류한다. 프로세스 특성에 따라 큐에 종속되며, 각 큐는 자신의 알로리즘에 따라 스케쥴링된다.   
    큐 사이의 스케쥴링은 일반적으로 고정 우선순위의 선점형 스케쥴링으로 구현된다.  
    - 다단계 피드백 큐 스케쥴링(Multilevel Feedback Queue Scheduling) 는 다단계 큐 스케쥴링과 유사하나 프로세스의 우선순위가 바뀔 수 있다는 점이 다르다. 각 프로세스의 CPU 버스트에 따라 큐 사이를 이동한다.
    - 멀티쓰레딩에서 다대다 모델, 다대일 모델을 사용할 경우 프로세스에 속한 사용자 스레드들 사이에서 경쟁이 발생한다. 이른 프로세스 경쟁 범위(Process Contention Scope) 라고 한다.  
    - CPU 상에서 어느 커널 스레드를 스케쥴할 것이지 결정하는 것은 시스템 경쟁 범위(System Contention Scope) 에서 발생하는 것이다.  
    - 다중처리기(Multi-Core 등) 에서 스케쥴링 할 때에 비대칭 다중처리, 대칭 다중처리 방법이 있다.
    - 비대칭 다중처리는 주 서버인 하나의 처리기가 스케쥴링 결정과 입출력 처리, 그리고 다른 시스템 활동을 처리하는 것이다. 구현이 간단하다.  
    - 대칭 다중처리(SMP, Symmetric multiprocessing) 는 공용 준비완료 큐와 사유 준비완료 큐를 갖고 각 처리기가 독자적으로 스케쥴링된다. 두 처리기가 같은 프로세스를 선택하지 않고 프로세스가 사라지지 않는다는 것을 보장해야 한다.  
    - 가장 최근에 접근된 데이터가 캐시를 채우게 된다. 따라서 프로세스를 재시작할 때 이전에 실행한 처리기에서 다시 처리하는 것이 효율적이다. 이러한 성질을 처리기 친화성이라고 한다.  
    노력하지만 보장하지 않을 때를 약한 친화성, 보장되는 경우를 강한 친화성이라고 표현한다.  
    - 부하 균등화(Load balancing)은 SMP 시스템에서 각 처리기의 부하가 고르게 분배되도록 하는 것이다. pull 이주와 push 이주가 있다.  
    Pull 이주는 쉬고 있는 처리기가 바쁜 처리기의 프로세스를 갖고 오는 것이고, Push 이주는 특정 태스크가 각 처리기가 과부화 상태인지 확인하여 과부화 상태인 처리기의 프로세스를 다른 처리기에 이주시키는 것이다.  
    - 스케쥴링 알고리즘 분석 방법으로 특정 시나리오의 결과를 확인하는 결정론적 모델링, 분포를 근사하여 샘플링하는 큐잉 모델, 모의실험 등이 있다.  
    스케쥴링 알고리즘이 안정 상태에 있다면 큐의 길이가 일정할 것이다. 따라서 평균 큐 길이(n) = 평균 도착률(a) * 단위시간 동안 발생한 새로운 프로세스(W) 가 성립한다. 이를 Little's Formula 라고 한다.  
    
#### 6장) 프로세스 동기화
    - 동시에 여러 개의 프로세스가 동일한 자료에 접근하여 조작하고, 그 실행 결과가 접근이 발생한 순서에 의존하는 상황을 경쟁상황(Race Condition)이라고 한다.  
    - 각 프로세스는 임계 영역(Critical Section) 이라 부르는 코드 부분이 존재하고, 가장 큰 특징은 특정 프로세스가 자신의 임계영역에서 실행되는 동안 다른 프로세스가 자신의 임계영역에 접근할 수 없다는 것이다.  
    - 각 프로세스는 자신의 임계영역에 접근하기 위해 진입 허가를 요청해야 하는데, 이러한 요청을 구현하는 코드를 진입 영역(Entry Section)이라고 한다.  
    - 임계영역 뒤에 퇴출 영역이 따라올 수 있고, 그 외 모든 부분을 나머지 영영이라고 부른다.  
    - 임계 영역 접근은 상호 배제(Mutual Exclusion), 진행(Progress), 한정된 대기(Bounded wating) 의 세 가지 조건을 충족해야 한다.  
    상호 배제란 특정 프로세스가 임계영역에서 실행되는 동안 다른 프로세스는 자신의 임계영역에 접근할 수 없다는 성질이다.  
    진행이란 현재 임계영역에서 실행되는 프로세스가 없다면 현재 나머지 부분에서 실행 중이지 않은 프로세스만 임계영역에 접근할 수 있는 가능성이 존재하며, 이 선택이 무기한 연기될 수 없다는 성질이다.  
    한정된 대기란 프로세스가 자신의 임계 영역으로 진입하려는 요청을 한 후부터 그 요청이 허용될 떄까지 다른 프로세스가 자신의 임계 영역에 접근 허용되는 횟수가 제한되어 있어야 한다는 성질이다.  
    - 비선점형 커널은 한 순간에 커널 안에서 실행 중인 프로세스가 하나 밖에 없기 때문에 커널 자료구조에 대한 경쟁 조건을 염려할 필요가 없다.  
    - 선점형 커널은 실시간 프로세스가 현재 커널에서 실행 중인 프로세스를 선점할 수 있기 때문에 실시간 프로그래밍에 더 적합하다.  
    - 임계 영역에 대한 고전적인 소프트웨어 기반 해결책 중 하나가 피터슨의 해결안(Peterson's Solution)이다. 
    그러나 현대 컴퓨터 구조가 load/store 같은 기본적인 기계어를 실행하는 방식이므로 이러한 구조에서 피터슨의 해결안이 올바르게 작동한다고 보장할 수 없다.  
    피터슨의 해결안은 임계 영역과 나머지 영역을 번갈아 가며 실행하는 두 개의 프로세스(Pi, Pj)를 가정한다.
    ```
    int turn;
    boolean flag[2];
    do 
    {
        flag[i] = TRUE;
        turn = j;
        while (flag[j] && turn == j); 무한 루프
        임계 영역
        flag[i] = False;
        나머지 영역
    } while (TRUE);
    ```
    - 일반적으로 임계 영역에 대한 임의의 해결책은 락(lock)이라는 간단한 도구를 사용하여 해결할 수 있다.  
    - 단일처리기 환경에서 공유 변수가 변경되는 동안 인러턻트 발생을 혀용하지 않음으로써 임계영역 문제를 간단히 해결할 수 있다.  
    - 원래 값을 반환하고 현재 값을 변경(true) 하는 작동이 원자적으로, 또는 두 개 값을 교환하는 swap 이 원자적으로 실행된다면 동기화된 하드웨어로 임계 영역 문제가 간단히 해결된다.  
    - 다중처리기 환경에서는 인터럽트 불능화에 상당한 시간이 소요되어 사용할 수 없다.  
    - 하드웨어 기반 해결책을 응용 프로그래머가 사용하기에 복잡하므로 세마포(Semaphore)라고 하는 동기화 도구를 이용할 수 있다.    
    세마포는 정수 변수로서 초기화를 제외하고 원자적 연산으로 wait()과 signal() 로만 접근 가능하다.  
    - 운영체제는 종종 카운팅과 이진 세마포를 구분한다. 카운팅 세마포의 값은 제한 없는 영역을 가진다. 이진 세마포의 값은 0 과 1 사의의 값만 가능하다. 이진 세마포는 mutex 락이라고도 불린다.  
    카운팅 세마포는 유한한 개수를 가진 자원에 대한 접근을 제어하는 데에 사용될 수 있다. 세마포는 가용한 자원의 개수로 초기화된다.  
    각 자원을 사용하려는 프로세스는 세마포에 wait() 연산을 실행하며, 이 때 세마포 값은 감소된다.  
    프로세스가 자원을 방출할 때 signal() 연산이 수행되고 세마포 값이 증가한다. 세마포 값이 0이면 모든 자원이 사용 중임을 나타낸다.  
    프로세스는 세마포 값이 0보다 클 때까지 봉쇄된다.  
    - 세마포 정의의 주된 단점은 바쁜 대기(Busy Waiting)을 해야 한다는 점이다. 이렇듯 프로세스가 락을 기다리는 동안 회전하기 때문에 이런 타입의 세마포를 스핀락(Spinlock)이라고 부르기도 한다.  
    문맥 교환이 필요하지 않다는 점에서 락이 짧은 시간 동안만 소유될 것으로 예상될 결우 스핀락이 유용하다.  
    - 바쁜 대기 대신에 봉쇄를 할 수 있는데, 봉쇄 연산은 프로세스를 세마포에 연관된 대기 큐에 넣고, 프로세스의 상태를 대기 상태로 전환한다.  
    - 다중처리기 환경에서 임계 영역 문제를 해결하기 위해 spinlocks 와 같은 다른 락킹 비법을 제공해야 한다.  
    - 교착상태(Deadlock)와 기아(Stravation) 문제가 발생하지 않도록 고려해야 한다. 무기한 봉쇄(Indefinite Blocking)는 세마포와 연관된 큐가 LIFO를 따를 때에 발생할 수 있다.  
    - 우선순위 역전(Priority Inversion)이란 높은 순위의 프로세스가 대기 중인 상황에서 중간 순위의 프로세스가 실행 가능 상태로 변경됨으로써 낮은 순위의 프로세스를 선점하는 것을 말한다.    
    우선순위 상속 프로토콜을 사용하여 이 문제를 해결할 수 있다.  
    - 고전적인 동기화 문제들로 유한 버퍼 문제, Readers-Writers 문제(쓰는 도중에 읽으면 엉뚱한 데이터를 읽으므로), 식사하는 철학자들 문제(모든 프로세스가 각각 하나의 자원을 점유하고 있고, 프로세스를 완료하기 위해 다른 프로세스가 점유한 자원을 요구할 때)가 있다.  
    - 프로그래머가 세마포를 잘못 사용하면 문제가 발생할 수 있는 여지가 많으므로 모니터(Monitor)라는 고급 언어 구조물이 도입되었다.  
    - 모니터 구조물은 모니터 안에 있는 프로세스 중 항상 하나의 프로세스만 활성화되도록 보장한다.  
    - 하나의 논리적 기능을 실행하는 명령어의 집합을 트랜잭션이라고 하고, 원자성(Atomicity)가 보장되어야 한다.  
    - 철회된 트랜잭션이 이미 접근한 데이터를 변경했을 수도 있기 때문에 시스템이 원자성을 보장하기 위해 롤백(roll back)을 책임지고 해야 한다.  
    - 트랜잭션 메모리는 스레드-안전 동시실행 응용 개발을 위한 락, 세마포 등 외의 대체 전략을 제공한다.  
    - 원자성을 보장하는 간단한 방법 중 하나는 트랜잭션에 의해 접근된 데이터에 가해지는 모든 변경내역을 안전 저장장치에 기록하는 것이다.  
    이런 형태의 기록을 얻기 위해 가장 많이 사용되는 기법이 로그 우선 쓰기(Write-Ahead Logging)이다.  
    각 로그 레코드는 트랜잭션 이름, 데이터 항목 이름, 이전 값, 새 값의 정보를 가진다.  
    - 로그에 검사점(Checkpoint)를 추가하여 로그 우선 쓰기의 성능을 향상할 수 있다. 
    - 트랜잭션을 병렬로 실행시키면 그 결과는 모든 트랜잭션을 차례대로 순차적으로 실행시킨 것과 같아야 한다. 이러한 성질을 직렬가능성(Serializability)라고 한다.  
    - 일련의 비충돌(Nonconflicting) 연산들을 서로 swap 함으로써 직렬 스케쥴로 변환할 수 있다면 이를 충돌 직렬가능(Conflict Serializable)하다고 한다.  
    - 직렬 가능성을 보장하는 한 가지 방법은 각 데이터 항목마다 락을 두고, 각 트랜잭션이 일정한 락킹 프로토콜에 맞추어 락을 획득하고 반납하도록 규정하는 것이다.  
    락은 다양항 모드가 있을 수 있으며, 보통 공유(Shared) 와 독점(Exclusive) 가 필요하다.  
    - 두 단계 락킹 프로토콜(Two Stage Locking Protocol) 은 직렬 가능성을 보장해주는 프로토콜 중 하나이다. 각 트랜잭션이 락과 언락을 두 단계를 실행할 것을 요구한다.  
    확장 단계에서는 트랜잭션이 락을 새로 얻을 수 있지만 얻었던 락을 반납해서는 안된다.  
    수축 단계에서는 얻었던 락을 반납할 수 있지만 새로운 락을 얻어서는 안된다.  
    - 직렬 가능한 순서를 결정하는 또 다른 방법은 미리 순서를 선택하는 방법이다. 이 방법 중 가장 많이 사용되는 방법은 타임스탬프 순서 기법(timestamp ordering scheme)이다.  
    - 타임스탬프 순서 기법은 트랜잭션이 실행되기 전에 각 트랜잭션마다 타임스탬프를 부여하고 트랜잭션이 이 순서에 따라 수행되는 것이다.
    - 타임스탬프를 구현하는 방법으로 시스템 클록(system clock)을 사용할 수 있다. 즉 타임스탬프가 트랜잭션이 시스템에 도착했을 때의 시스템 클록 값으로 입력되는 것이다.  
    - 또 다른 방법으로 논리적인 카운터를 사용할 수 있다. 즉 타임스탬프가 트랜잭션이 시스템에 도착했을 때의 논리적인 카운터 값으로 기록된다.  
    
#### 7장) 교착상태
    - 정상적인 작동 중 프로세스는 요쳥->사용->방출 의 순서로만 자원을 사용할 수 있다.
    - 자원의 요청과 방출은 시스템 호출로, 프로세스나 스레드가 커널이 관리하는 자원을 사용할 때매다 매번 운영체제는 프로세스가 자원을 요청했는지와 할당받았는지 확인하다.  
    시스템은 각 자원이 어느 프로세스에 할당되었는지 기록한다.  
    - 교착상태에 빠진 프로세스들은 결코 끝날 수 없으며, 자원이 묶여 있어 다른 작업을 시작하는 것도 불가능하다.  
    - 교착상태는 상호배제(최소 하나의 자원이 비공유 모드로 점유된 상태), 점유하며 대기(프로세스가 최소 하나의 자원을 점유한 채 다른 자원을 얻기 위하여 대기), 
    비선점(프로세스가 자원을 선점할 수 없음), 순환대기(P0 가 P1이 점유한 자원을 요청하고, ..., Pn이 P0이 점유한 자원을 요청하는 순환상태에 있어야 함) 의 네 가지 조건이 성립되어야 발생한다.  
    - 교착상태를 보다 정확하게 기술하기 위해 자원 할당 그래프를 활용할 수 있다. 정점은 각 프로세스와 자원의 집합을 의미한다.  
    프로세스로부터 자원으로 향하는 간선은 요청을 뜻하며, 자원에서 프로세스로 향하는 간선은 점유를 뜻한다.  
    그래프가 사이클을 포함하지 않으면 교착상태가 아님을 보일 수 있다. 반면 사이클이 존재할 경우 교착상태가 존재할 수 있다. 만약 각 자원의 인스턴스가 하나라면 사이클은 교착상태임을 의미한다.  
    - 교착상태 처리 방법으로 교착상태가 발생하지 않도록 보장하거나, 교착상태가 되면 회복시키거나 문제를 무시하고 교착상태가 발생하지 않은 척하는 방법이 있다.  
    문제를 무시하고 교착상태가 발생하지 않은 척 하는 방법이 Unix 및 Windows 를 포함한 대부분의 운영체제가 사용하는 방법이다. 이 경우 문제를 해결하는 것은 프로그래머의 몫이다.  
    - 교착상태를 탐지하고 복구하는 알고리즘이 없다면 시스템은 교착상태에 이를 수 있고, 그럼에도 교착상태가 발생한 것을 인식하지 못할 수 있다.  
    결국 시스템은 작동을 정지하고, 수작업으로 다시 시작할 필요가 있다. 대부분의 운영체제에서 이 방법을 사용하고 있다.  
    - 교착상태를 만드는 네 가지 조건 중 일부를 회피함으로써 교착상태를 예방할 수 있다.  
    - 상호배제: 공유가능한 자원은 배타적 접근을 요구하지 않으므로 해당 문제가 없다. 그러나 일반적으로 상호 배제 조건을 인정하지 않음으로써 예방하는 것은 불가능하다.  
    - 점유하며 대기: 한 가지 프로토콜은 각 프로세스가 실행되기 전에 반드시 자신의 모든 자원을 요청하여 할당받게 하는 것이다.  
    다른 프로토콜로 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원을 요철할 수 있도록 하는 것이다. 이 때 자원의 추가 요청은 기존 자원을 전부 방출하고 재요청하는 식으로 수행된다.  
    이 두 프로토콜의 단점으로 많은 자원들이 할당된 후 오래 사용되지 않아 이용률이 낮을 수 있다는 점과 필요한 자원 중 하나가 항상 다른 프로세스에 할당되어 기아 상태가 가능하다는 점이 있다.  
    - 비선점: 만일 어떤 자원을 점유하고 있는 프로세스가 즉시 할당할 수 없는 다른 자원을 요청하면 현재 점유되어 있는 자원들을 선점한다. 즉 묵시적으로 방출한다.  
    다른 대안으로 한 프로세스가 자원을 요청하면 사용 가능한지 검사하고, 사용 가능하면 할당한다.  
    사용 불가능하다면 그 자원들이 추가 자원을 기다리고 있는 다른 프로세스에 할당되어있는지 검사하고, 만약 그렇다면 해당 자원을 선점해 요청 프로세스에 할당하고 그렇지 않다면 대기한다.  
    대기하는 동안 그 프로세스의 자원들 중 일부는 다른 프로세스로부터 요청받아 선점될 수 있다.  
    이 프로토콜은 CPU레지스터나 메모리처럼 그 상태가 쉽게 저장되고 복원될 수 있는 자원에 종종 적용된다. 프린터나 테이프 드라이브같은 자원에는 적용할 수 없다.  
    - 순환대기: 한 가지 방법은 모든 자원에 전체적인 순서를 부여하여 각 프로세스가 열거된 순서대로 오름차순으로 자원을 요청하도록 하는 것이다.  
    대안으로 프로세스가 현재 선점한 자원보다 낮은 순위의 자원을 요청할 때 요청 자원보다 높은 순위의 자원을 방출하도록 요구할 수 있다.  
    순서나 계층 구조를 정하는 것 자체만으로 교착상태를 예방할 수 없다. 순서를 지키는 프로그램을 작성해야 한다.  
    락이 동적으로 획득될 수 있다면 락 순서를 부여한다고 해서 교착상태가 예방되지 않는다는 것에 주의해야 한다.  
    - 교착상태가 발생하지 않도록 한 위 방법의 문제점은 장치의 이용률이 저하되고 시스템 처리율이 감소된다는 것이다.  
    - 교착상태를 회피하는 다른 방법은 자원이 어떻게 요청될지에 대한 추가 정보를 제공하도록 하는 것이다. 각 프로세스의 요청과 방출에 대한 완전한 순서를 파악할 수 있다면 각 요청에 대해 교착상태를 회피하기 위해 대기 여부를 결정할 수 있다.  
    - 이 방법 중 가장 단순한 방법은 각 프로세스가 자신이 필요로 하는 자원의 종류와 최대 개수를 선언하는 것이다.  
    - 안전 상태란 시스템이 어떤 순서로든 프로세스들이 요청하는 모든 자원을 교착상태 없이 차례로 모두 할당해 줄 수 있는 상태이다.  
    - 시스템이 불안전하다는 것은 앞으로 교착상태로 가게 될 수도 있다는 가능성을 의미한다.  
    - 회피 알고리즘이 교착상태를 회피하는 기본 원칙은 시스템이 안전 상태에 머물도록 하는 것이다.  
    - 만약 각 자원 타입마다 하나의 인스턴스를 갖는다면 교착상태 회피를 위해 자원 할당 그래프의 변형을 사용할 수 있다.  
    프로세스가 자원을 요청할 때에 사이클 탐지 알고리즘을 활용해 해당 요청이 사이클을 만들지 않을 때에만 요청을 허용할 수 있다.  
    - 은행원 알고리즘은 자원 타입마다 여러 개의 인스턴스가 있을 때 사용 가능하지만 자원 할당 그래프보다 효율성이 떨어진다.  
    - 은행원 알고리즘은 안전성 알고리즘와 자원 할당 알고리즘으로 구성된다.  
    - 만약 시스템이 교착상태 예방이나 교착상태 방지 알고리즘을 사용하지 않는다면 교착상태가 발생할 수 있다. 이런 환경에서 시스템은 시스템의 상태를 검사하는 알고리즘과 교착상태로부터 회복하는 알고리즘을 반드시 지원해야 한다.  
    - 각 자원 타입의 인스턴스가 한 개씩 있는 경우 대기 그래프(wait-for graph)라고 하는 자원할당 그래프의 변형을 사용해 교착상태 탐지 알고리즘을 정의할 수 있다.  
    - 각 자원 타입마다 여러 개의 인스턴스가 존재하는 경우 은행원 알고리즘 유사한 알고리즘을 사용해 탐지할 수 있다.  
    - 교착상태 탐지 알고리즘을 언제 실행하는가 하는 것은 교착상태 발생 빈도와 교착상태에 연관된 프로세스의 평균 갯수에 의존한다.  
    일반적으로 교착상태가 자주 일어난다면 탐지 알고리즘도 자주 실행해야 한다.
    - 교착상태가 탐지되었다면 해결해야 한다. 첫 째 해결방법은 운영자에서 통지해 운영자가 해결하는 방법이고, 다른 방법은 교착상태를 야기시킨 한 개 이상의 프로세스를 중지시키는 것이다. 마지막 방법은 자원을 선점하는 것이다.  
    - 프로세스를 중지시키는 방법은 교착 상태의 프로세스를 모두 중지하거나 차례대록 한 프로세스씩 중지하는 방법이 있다.  
    프로세스를 중저시키는 것은 비용이 크므로 비용이 최소인 프로세스를 중지시키는 것을 고려해야 한다. 프로세스의 우선순위 및 진척도 등 여러 요인에 따라 비용이 결정된다.  
    - 자원 선점을 이용해 교착상태를 제거하려면 교착상태가 깨질 때까지 자원을 선점해야 한다. 이 때 어느 자원을 어느 프로세스로부터 선점할 것이지 비용을 고려하여 결정해야 하며,  
    선점된 자원을 점유했던 프로세스를 어떻게 안전한 상태로 롤백할 것인지, 기아 상태가 발생하지 않는 것을 어떻게 보장할 것인지 고려해야 한다.
    
#### 8장) 메모리 관리 전략
    - 명령어 실행은 먼저 메모리로부터 한 명령어를 가져오는 데에서 시작한다.  
    - 주 메모리와 프로세서 레지스터 자체에 내장되어 있는 레지스터들은 CPU가 직접 접근할 수 있는 유일한 저장장치이다.  
    - CPU에 내장되어 있는 레지스터들은 일반적으로 CPU 클록의 1사이클 내에 접근 가능하다.  
    - 반면 주 메모리의 접근을 완료하기 위해서는 많은 사이클이 소요되며, CPU가 필요한 데이터가 없어서 명령어를 실행하지 못하고 지연(stall)되는 현상이 발생한다.  
    - CPU와 주 메모리 사이에 존재하는 캐시(Cache)라고 메모리 버퍼가 속도의 차이를 완화시키기 위해 사용된다.  
    - 각각의 프로세스는 독립된 메모리 공간을 가진다.   
    이러한 보호 기법은 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 기준(base)와 상환(limit)이라 불리는 두 개의 레지스터를 활용해 구현한다.  
    기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 적재된다.  
    - 사용자 모드에서 실행되는 프로그램에 의해 운영체제의 메모리 공간이나 다른 프로그램의 메모리 공간에 대한 접근이 일어나면 치명적인 에러로 간주되어 트랩(trap)을 발생시킨다.  
    - 주소 할당 방법으로 컴파일 시간 바인딩, 적재 시간 바인딩, 실행 시간 바인딩이 있다.  
    컴파일 시간 바인딩이란 컴파일 될 때에 절대 주소를 결졍하는 것이다. MS-DOS 의 .COM 양식 프로그램이 컴파일 시간에 바인딩하는 절대 코드의 예이다.  
    적재 시간 바인딩이란 프로그램이 메모리에 실제로 적재될 때 절대 주소가 생성되는 것이다.  
    실행 시간 바인딩은 만약 프로세스가 실행되는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 이동 가능한 것을 말한다. 이를 가능하게 하려면 특별한 하드웨어를 이용해야 한다.  
    - CPU가 생성하는 주소를 일반적으로 논리 주소라 하며, 메모리가 취급하게 되는 주소(MAR, 메모리 주소 레지스터)는 일반적으로 물리 주소라고 한다.  
    컴파일 시간 바인딩과 적재 주소 바인딩의 경우 논리 주소와 물리 주소가 같다. 반면 실행 시간 바인딩은 물리 주소와 논리 주소가 다르다. 이러한 경우 논리 주소를 가상 주소라고 한다.  
    - 프로그램 실행 중에 이와 같은 가상 주소를 물리 주소로 바꾸어야 하는데 이 변환 작업은 하드웨어 장치인 메모리 관리기(MMU, Memory Management Unit)에 의해 실행된다.  
    - 동적 적재란 각 프로세스의 특정 루틴이 실제 호출되기 전까지 메모리에 올라오지 않고 재배치 가능한 상태로 디스크에 대기하는 것이다.  
    동적 적재의 장점은 사용되지 않는 루틴들이 미리 적재되지 않아서 메모리 공간 이용률이 높아진다는 점이다.  
    동적 적재는 프로그래머가 직접 구현해야 하며, 동적 적재를 구현하는 운영체제의 라이브러리 루틴을 활용할 수 있다.  
    - 동적 연결이란 동적 적재와 유사하게 연결(Linking)이 실행 시기까지 미루어지는 것이다.  
    동적 연결에서는 라이브러리를 부르는 곳마다 스텁(stub)이 생긴다. 스텁은 작은 코드 조각으로 메모리에 존재하는 메모리를 찾는 방법 또는 메모리에 없을 경우 라이브러리를 적재하는 방법을 알려준다.  
    예를 들어 printf() 라이브러리를 10 개의 프로세스에서 사용한다고 하더라도 해당 라이브러리 코드는 하나만 있어도 된다.  
    동적 적재와는 달리 동적 연결은 일반적으로 운영체제의 도움이 필요하다.  
    - 필요한 경우 프로세스는 실행 도중 보조 메모리로 교체되어 나갔다가 다시 메모리로 되돌아올 수 있는데 이를 스왑(Swap)이라고 한다.  
    예를 들어 라운드 로빈 스케쥴링을 사용할 경우 프로세스가 시간 할당량을 모두 소비했을 때 그 프로세스를 스왑시킬 수 있다.  
    만약 바인딩이 컴파일 시간 바인딩이나 적재 시간 바인딩이라면 절대주소가 결정되었기 때문에 스왑되어 나간 프로세스가 다시 돌아오기 위해서는 똑같은 메모리 위치로 돌아와야 한다.  
    실행 시간 바인딩이라면 임의의 주소로 되돌아올 수 있다.  
    - 새로운 프로세스 또는 되돌아오는 프로세스의 메모리를 확보하기 위해 기존 프로세스를 스왑하려고 할 때, 기존 프로세스가 입출력을 기다리고 있다면 프로세스를 스왑할 수 없다.  
    이를 구현하는 방법은 입출력이 종료되지 않은 프로세스를 스왑하지 말거나 입출력을 항상 운영체제의 버퍼와만 하도록 하는 방법이 있다. 운영체제와 프로세스 사이의 전송은 스왑되어 들어온 상태에서 하면 된다.  
    - 이러한 표준 스와핑 방식은 스와핑 시간이 오래 걸려서 현재 거의 사용되지 않는다.  
    - 보통 여러 프로세스가 동시에 메모리에 올라와 있는 것이 바람직하기 때문에 메모리에 올라오기 위해 입력 큐에 대기하고 있는 프로세스들에 메모리를 어떻게 할당하는 것이 좋을지 고려해야 한다. 연속 메모리 할당 시스템에서 각 프로세스는 연속된 메모리 공간을 차지한다.  
    - 가장 간단한 메모리 할당 방법은 메모리를 고정된 크기로 분할하는 것이다. 이 때 분할의 개수가 다중 프로그래밍의 정도를 결정한다.  
    이런 고정 분할 기법을 일반화시킨 형태로 MVT라고 부르며, 주로 배치 환경에서 사용된다.  
    - 가변 분할 기법에서 운영체제는 메모리의 어떤 부분이 사용되고 있는지 파악할 수 있는 테이블을 유지한다.  
    - 동적 메모리 할당 문제란 일련의 자유 공간 리스트에서 크기 n바이트인 블록 요청을 어떻게 만족할지 결정하는 문제이다.  
    최초 적합(First-Fit), 최적 적합(Best-Fit)과 최악 적합(Worst-Fit)이 가장 일반적인 기법이다.  
    최초 적합은 요청을 만족시키는 충분히 큰 첫 번째 사용 가능한 공간에 할당하는 것이다.  
    최적 적합은 충분히 큰 공간들 중 가장 작은 공간에 할당하는 것이다.  
    최악 적합은 가장 큰 공간에 할당하는 것이다. 이 때 프로세스가 들어가고도 충분한 크기의 공간이 존재하므로 다른 프로세스 역시 사용될 수 있다.  
    - 외부 단편화란 프로세스가 메모리에 적재되고 제거되는 일이 반복되다보면 각 자유 공간이 너무 작은 조각이 되어버려 가용 공간을 모두 합치면 충분한 공간이 되지만 각각의 공간은 너무 작아 사용되지 못하는 상황을 말한다.  
    일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수 배로만 해주게 되는데, 이러한 경우에도 각각의 내부적 공간에 남는 공간이 발생할 수 있다. 이러한 것을 내부 단편화라고 한다.  
    - 외부 단편화 문제를 해결하는 한 가지 방법은 압축이다. 이는 메모리의 모든 내용을 한 군데로 몰고 모든 자유 공간을 다른 곳으로 모아서 큰 블록을 만드는 것이다. 그러나 이 방법은 비용이 많이 든다.  
    - 외부 단편화 문제를 해결하는 다른 방법은 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 것이다. 이 해결책을 구현하는 방법으로 페이징과 세그먼테이션, 또는 두 개의 결합이 사용될 수 있다.  
    - 페이징은 물리 메모리를 프레임(Frame)이라 불리는 고정 크기의 블록으로 나누고, 논리 메모리는 페이지(Page)라고 불리는 같은 크기의 블록으로 나눈 후, 프로세스가 실행될 때 각 페이지가 가용한 프레임에 적재되는 식이다.  
    - 페이징을 위한 하드웨어가 존재하고, CPU의 각 주소는 페이지 번호와 페이지 변위 두 개의 부분으로 나뉜다. 페이지 번호는 페이지 테이블을 액세스할 때 사용되며 페이지 테이블은 주 메모리에 존재하는 페이지의 기준 주소를 갖고 있다.  
    - 만약 논리 주소 공간의 크기가 2^m 이고, 페이지가 2^n 크기라면 상위 m-n 비트는 페이지 번호를 나타내고 하위 n 비트는 페이지 변위를 나타낸다.  
    - 페이징을 사용하면 외부 단편화가 발생하지 않는 반면 내부 단편화가 발생한다.    
    내부 단편화를 고려했을 때 페이지 크기가 작은 것이 선호되나 페이지 크기가 작아지면 페이지 테이블의 크기가 커지게 되고, 이 테이블이 차지하는 공간이 낭비된다.  
    - 페이징의 가장 중요한 특징은 메모리에 대한 사용자 인식과 실제 물리 메모리를 명확하게 분리한다는 사실이다.  
    - 만약 사용자가 시스템 호출을 호출하여 매개변수로 어떤 주소를 전달했을 때 제대로 사상하여 해당 주소로 찾아가기 위해 운영체제는 각 프로세스에 대해 페이지 테이블의 복사본을 유지해야 한다.  
    또한 프로세스가 CPU를 할당받았을 때 페이지 테이블을 설정하는 데에 CPU디스패처가 사용된다. 따라서 페이징은 문맥 교환 시간을 증가시킨다.  
    - 대부분의 운영체제는 각 프로세스마다 하나의 페이지 테이블을 할당한다. 페이지 테이블을 가리키는 포인터는 PCB에 저장된다.  
    - 가장 간단한 페이지 테이블은 전용 레지스터의 집합으로 구현될 수 있다. 이들 레지스터는 고속 논리 회로로 설계된다. 그러나 대부분의 경우 페이지 테이블이 크므로 이는 실현 가능하지 않다.    
    따라서 대부분의 컴퓨터는 페이지 테이블을 주 메모리에 저장하고 페이지 테이블 기준 레지스터(PTBR, Page Table Base Register)로 하여 페이지 테이블을 가리키도록 한다. 이 방식의 문제점은 사용자의 메모리 접근 시간이 오래 걸린다는 것이다.  
    이 문제를 해결하는 표준 방법은 TLB(Translation Look-aside Buffers)라고 불리는 특수한 소형 하드웨어 캐시를 사용하는 것이다.  
    TLB에 페이지를 찾아달라는 요청이 들어오면 찾고자 하는 페이지를 동시에 여러 개의 내부 키와 비교한다. 페이지 번호가 발견되면 대응하는 프레임 번호를 알려준다.    
    만약 페이지 번호가 연관 레지스터 TLB에서 찾아지지 않으면 주 메모리에 있는 페이지 테이블에서 찾아 사용하고 이 정보를 TLB에 추가한다.  
    만약 TLB가 가득 차 있으면 교체 작업을 해야 하는데 교체 정책은 LRU부터 무작위 교체까지 다양한 정책이 사용된다.  
    어떤 TLB는 각 항목에 ASIDs(Address-Space Identifers)를 저장하기도 한다. ASID는 그 TLB항목이 어느 프로세스에 속한 것인지 알려주며, 그 프로세스의 주소 공간을 보호하기 위해서 사용된다.  
    - 페이지 번호가 TLB에서 발견되는 비율을 적중률(hit ratio)라고 부른다.  
    - 페이지화된 환경에서 메모리의 보호는 각 프레임과 연관된 보호 비트에 의해 구현된다. 읽기 전용 페이지에 대해 쓰기를 시도하면 운영체제에게 하드웨어 트랩 또는 메모리 보호 위한이 전달된다.  
    - 페이지 테이블의 각 엔트리에는 유효/무효 비트가 하나 더 존재한다. 유효로 설정되면 프로세스의 합법적 페이지임을 나타낸다.  
    - 페이징의 또 다른 장점은 공통 코드를 공유할 수 있다는 점이다. 어떤 웅영체제는 메모리 공유를 공유 페이지를 사용하여 구현하기도 한다.  
    - 메모리 크기가 m, 페이지 크기가 n이라면 페이지 테이블은 2^m-n 의 항목으로 구성된다. 이렇게 할 경우 페이지 테이블의 크기가 커지게 되는데, 한 가지 간단한 방법은 페이지 테이블을 여러 개의 작은 조각으로 나누는 것이다.  
    - 해결 방법 중 하나로 2단계 페이징 기법을 사용하는 것이 있다.  
    - 주소 공간이 32비트보다 코지면 가상 주소를 해시값으로 사용하는 해시 페이지 테이블을 많이 쓴다. 해시 페이지 테이블의 각 항목은 연결 리스트를 갖고 있고 각 원소는 가상 페이지 번호, 맵핑되는 페지이 프레임 번호와 다음 원소를 가리키는 포인터를 갖고 있다.  
    - 해시 페이지 테이블 알고리즘은 가상 주소의 가장 페이지 번호를 해싱하고, 해당 해시 값의 연결 리스트의 첫 번째 원소와 가상 페이지 번호를 비교한다.  
    일치하면 그에 대응하는 페이지 프레임 번호를 사용하여 물리 주소를 얻는다. 만약 일치하지 않으면 연결 리스트의 다음 원소를 탐색해가며 일치하는 가상 페이지 번호를 찾는다.  
    - 해시 페이지 테이블의 변형으로 클러스터 페이지 테이블이 제안되었다. 클러스터 페이지 테이블은 메모리 액세스가 비연속적이면서 전체 주소 공간에 넓게 흩어져 있는 경우에 유용하다.  
    - 보통 프로세스는 각자 하나씩 페이지 테이블을 가진다. 이러한 기법의 단점 중 하나는 페이지 테이블의 크기이다. 이 문제를 해결하는 한 방법이 역 페이지 테이블이다.  
    역 페이지 테이블에서는 물리 메모리 프레임마다 한 항목씩 할당한다. 각 항목은 프레임에 올라와 있는 페이지의 가상 주소와 프로세스 ID로 구성된다.  
    이렇게 하면 시스템에 단 하나의 페이지 테이블만 존재하게 되어 메모리에서 훨씬 작은 공간을 점유한다.  
    반면 주소변환 시간이 더 오래 걸릴 수 있다. 역 페이지 테이블은 물리 주소에 따라 정렬되어 있지만 탐색은 가상 주소를 기준으로 하기 때문이다.  
    이를 해결하기 위해 해시 테이블을 사용할 수 있고, 이 역시도 TLB를 사용하여 성능 향상을 꾀할 수 있다.  
    한편 역 페이지 테이블을 사용하는 경우 메모리 공유가 더 어렵다. 메모리 공유는 보통 하나의 물리 영역에 사상되는 여러 개의 가상주소를 갖기 때문이다.  
    - 세그먼테이션은 사용자 관점의 메모리를 그대로 지원하는 메모리 관리 기법이다. 논리 주소 공간을 세그먼트의 집합으로 정의하고 각 세그먼트는 이름과 길이를 갖는다.  
    예를 들어 C컴파일러는 코드, 전역 변수, 힙, 스택과 표준 C 라이브러리를 위한 세그먼트를 생성한다.  
    - 사용자는 2차원 주소로 객체를 지정할 수 있지만(n번째 세그먼트, 18번째 바이트) 실제 물리 메모리는 바이트들의 1차원 배열이다. 따라서 사용자가 지정한 2차원 주소는 1차원 물리 주소로 사상되어야 한다.  
    이 사상은 세그먼트 테이블에 의해 이루어진다. 세그먼트 테이블의 각 항목은 세그먼트 기준과 세그먼트 한계로 구성된다.  
    - 펜티엄 시스템에서 CPU는 세그먼테이션 유닛에게 보내질 논리 주소를 만들고, 세그먼테이션 유닛은 각각의 논리 주소를 선형 주소로 변환한다. 선형 주소는 다시 페이지 유닛으로 보내진다.  
    
#### 9장) 가상 메모리
    - 가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것이다. 이렇게 함으로써 작은 메모리를 가지고 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.  
    - 논리적인 페이지를 물리적인 프레임으로 사상하는 것은 MMU가 할 일이다.  
    - 공백을 포함하는 가상 주소 공간을 성긴(sparse) 주소 공간이라고 한다.  
    - 가상메모리는 페이지 공유를 통해 파일이나 메모리가 둘 또는 그 이상의 프로세스들에게 공유되는 것을 가능하게 한다.  
    예를 들어 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있고, 프로세스 간에 메모리를 공유할 수 있다.  
    또 fork() 시스템 호출을 통한 프로세스 생성 과정에서 페이지를 공유함으로써 프로세스 생성 속도를 빠르게 할 수 있다.  
    - 요구 페이징(Demand Paging)이란 페이지들이 실행 과정에서 실제로 필요할 때에 메모리에 적재하는 것이다.  
    - 가상 메모리는 대체로 요구 페이징 기법으로 구현되며, 세그먼테이션을 사용하는 경우에는 각 세그먼테이션이 다시 여러 페이지로 나뉘는 페이지된 세그먼테이션을 사용한다.  
    - 스왑퍼(Swaper)와 유사하나 스왑은 전체 프로세스를 관리하는 반면 페이저(Pager)는 프로세스 내의 개별 프로세스를 관리한다.  
    - 메모리에 올라와 있지 않은 페이지에 접근할 때에 페이지 부재 트랩(Page-Fault Trap)이 발생하고,  
    PCB 를 검사하여 해당 메모리 참조가 유효인지 무효인지 확인하고,  
    만약 무요한 페이지에 대한 참조라면 그 프로세스는 중단되고, 유효한 참조인데 메모리에 존재하지 않는다면 빈 공간인 자유 프레임을 찾는다.  
    할당된 프레임으로 페이지를 읽고, 페이지 테이블과 프로세스가 유지하고 있는 내부 테이블을 수정한다.  
    이후 트랩에 의해 중단되었던 명령어를 다시 실행한다.  
    - 순수 요구 페이징이란 어떤 페이지가 필요해지기 전에 결코 그 페이지를 프레임에 적재하지 않는 방법이다.  
    - 참조 지역성(Locality of Reference)이란 앞으로의 실행될 부분은 현재 실행되고 있는 프로그램 부분과 가까울 것이라는 성질이다.  
    - 요구 페이징을 지원하기 위해 페이지 테이블과 보조 기억장치 하드웨어가 필요하다.  
    - 요구 페이징 성능 척도 중 하나로 유효 접근 시간(Effective Access Time)이 사용된다. 계산을 위해 페이지 부재 확률, 페이지 존재 시 접근 시간과 부재 시 접근 시간이 필요하다.  
    - fork()는 부모 프로세스와 동일한 자식 프로세스를 만드는 것이고, 대부분의 자식 프로세스는 만들어지자마자 exec() 시스템 호출을 한다.  
    그래서 자식 프로세스는 부모 프로세스의 모든 페이지를 복사할 필요가 없으며, 쓰기-시-복사(Copy-On-Write) 방식을 사용할 수 있다.  
    쓰기 시 복사 방식은 부모와 자식 둘 중 한 프로세스가 공유 중인 페이지에 쓰기 시작할 때에 해당 페이지의 복사본이 만들어지는 방식이다.  
    - 많은 운영체제들에서 각 프로세스는 빈 페이지 집합을 유지하고 있고, 페이지 복사본을 만들거나 스택 또는 힙 공간을 확장할 때 빈 페이지 집합에 속한 페이지가 사용된다.  
    - 메모리 과할당(Over Allocating)이란 다중 프로그래밍 정도가 높아 빈 프레임이 없는 경우를 말한다.  
    이런 상황을 해결하기 위해 특정 프로세스를 스왑 아웃하여 다중 프로그래밍의 정도를 낮추거나 페이지를 교체할 수 있다.  
    - 페이지 교체 사용 시 기존 페이지를 디스크에 저장하고, 새로운 페이지를 디스크에서 읽어들여야 하므로 디스크에 두 번 접속해야 한다.  
    이러한 오버헤드는 변경 비트(modify bit 또는 dirty bit)를 사용해서 감소시킬 수 있다.  
    만약 교체되어 나가는 페이지의 변경 비트가 설정되어 있지 않다면 기존 디스크 정보와 같다는 의미이므로 디스크에 기록할 필요가 없다.  
    - 요구 페이징은 프레임 할당 알고리즘과 페이지 교체 알고리즘을 필요로 한다. 주요한 페이지 교체 알고리즘 성능 척도 중 하나가 페이지 부재율이다.  
    - FIFO 페이지 교체 알고리즘은 각 페이지마다 메모리에 적재된 시간을 기억하다가 페이지 교체가 필요하면 가장 옛날에 적재되었던 페이지를 내보내는 알고리즘이다.  
    구현이 쉬우나 항상 성능이 좋은 것은 아니다.  
    - Belady의 모순이란 프로세스가 사용 가능한 프레임 갯수를 더 늘렸는데도 페이지 부재율이 증가하는 현상을 말한다.  
    FIFO 페이지 교체 알고리즘은 Belady의 모순이 발생할 가능성이 존재한다.  
    - 최적 페이지 교체 알고리즘은 말 그대로 최적 알고리즘으로, 프로세스가 앞으로 어떻게 메모리를 참조할 것인지 미리 알아야 하기 때문에 구현하기 어렵다.  
    - LRU(Least Recently Used) 페이지 교체 알고리즘은 각 페이지마다 마지막 사용 시간을 유지하여 페이지 교체가 필요할 때 가장 오랫동안 사용되지 않는 페이지를 교체하는 알고리즘이다.  
    일반적으로 좋은 알고리즘으로 인정받고 있으나, 이를 구현하기 위해서는 하드웨어의 지원이 필요하다.  
    가장 간단한 방법으로 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가하여 기록하는 방법이 있다.  
    또 다른 방법으로 페이지 번호의 스택을 유지하여 페이지가 참조될 때마다 스택 중간에서 제일 꼭대기로 페이지 번호를 이동하는 방법이 있다. 교체 시 가장 하단의 페이지가 교체된다.  
    - 최적 교체 알고리즘과 마찬가지로 LRU 알고리즘은 Belady의 모순 현상이 발생하지 않는다.  
    - Belady의 모순 현상이 발생하지 않는 알고리즘을 스택 알고리즘이라고 힌다.  
    - 진정한 LRU 페이지 교체 알고리즘을 지원하는 시스템은 거의 없으며, 대신 LRU 근사 페이지 교체 알고리즘이 사용된다.  
    참조 비트는 페이지 참조 여부를 가리키는 비트로 LRU 근사 페이지 알고리즘의 토대로 사용된다.  
    - LRU 근사 페이지 교체 알고리즘 중 부가적 참조 비트 알고리즘(Additional Reference Bits Algorithm)은 일정한 주기로 길이가 있는 참조 비트를 기록하는 알고리즘이다.   
    예를 들어 매 100밀리초마다 타이머 인터럽트를 걸어서 그 사이에 참조된 페이지의 최상위 비트를 셋팅하는 식이다. 하위 비트는 버린다. 가장 작은 정수 값의 참조 비트를 갖는 페이지를 교체한다.  
    - 2차 기회 알고리즘의 기본은 FIFO 알고리즘이다. 그러나 페이지가 선택될 때마나 참조 비트를 확인하여 참조 비트가 0이면 페이지를 교체하고 1이면 해당 페이지에 한 번 더 기회를 준다.  
    해당 페이지는 참조 비트가 0으로 셋팅되고 도착 시각이 현재 시각으로 갱신된다.  
    2차 기회 알고리즘을 구현하는 하나의 방법은 순환 큐를 이용하는 것이다.  
    - 참조 비트와 변경 비트를 순서쌍으로 생각하여 2차 기회 알고리즘을 개선할 수 있다.  
    (참조 비트, 변경 비트) 의 경우 (0, 0) < (0, 1) < (1, 0) < (1, 1) 의 순서로 등급을 설정해 가장 낮은 등급의 페이지를 교체하는 것이다.  
    - 계수-기반 페이지 교체 알고리즘은 각 페이지의 참조 횟수를 사용하는 알고리즘으로 LFU 알고리즘과 MFU 알고리즘이 존재하지만 최적 페지이 교체 알고리즘을 근사하지 못하므로 잘 쓰이지 않는다.  
    - LFU(Least Frequently Used) 알고리즘은 참소 횟수가 가장 적은 페이지를 교체하는 방법이다.  
    - MFU(Most Frequently Used) 알고리즘은 가장 작은 참조 횟수를 가진 페이지가 가장 최근에 메모리에 적재되었을 것이라는 가정 하에 가장 참조 횟수가 높은 페이지를 교체하는 방법이다.  
    - 페이지-버퍼링 알고리즘(Page-Buffering Algorithm)은 다른 페이지 교체 알고리즘과 병행해서 쓰일 수 있는 알고리즘으로, 시스템이 가용 프레임 풀을 보유하고 있다.    
    페이지 부재가 발생하면 다른 알고리즘을 활용하여 교체될 프레임을 찾고,  
    교체될 프레임을 디스크에 저장하기 전에 우선 가용 프레임에 새로운 페이지를 먼저 읽어들이고,  
    교체될 프레임이 디스크에 다 기록되면 해당 프레임을 가용 프레임에 추가하는 알고리즘이다.  
    이 개념의 확장으로 변경된 페이지 리스트를 유지하는 방법이 있는데, 페이징 장치가 유휴 상태일 때마다 변경된 페이지들을 선택하여 디스크에 쓴 후에 페이지의 변경 비트를 0으로 되돌려 놓는 방식이다.  
    - 몇몇 경우 응용 프로그램이 운영체제의 가상 메모리를 통해 데이터에 접근할 때 운영체제가 버퍼링 기능을 제공하는 것이 그렇지 않은 경우보다 성능이 떨어지는 경우가 있다. 
    응용 스스로 메모리 관리와 I/O 버퍼링을 제공하는 데이터베이스 응용이 하나의 예이다.  
    - 다른 예로 데이터 웨어하우스의 경우 연속적인 대량의 읽기 작업 후에 계산과 쓰기 작업을 실행하는데, 이런 경우 MFU가 LRU보다 더 효율적일 수 있다.  
    이러한 문제 때문에 몇몇 운영체제는 특별한 프로그램들에 디스크 파티션을 단순한 논리적인 블록들의 순차적 배열로 사용할 수 있게 해주는 기능을 제공하는에, 이 배열을 Raw disk 라고 부르며 I/O는 Raw I/O라고 한다.  
    - 각 프로세스는 최소한 몇 페이지의 프레임은 할당 받아야 한다. 왜냐하면 각 프로세스에 할당되는 프레임 수가 줄어들면 페이지 부재율이 높아져 성능이 저하되기 때문이다.  
    - 균등 할당이란 각 프로세스에 동일한 개수의 프레임을 할당하는 것이다. 각 프로그램마다의 용량의 차이가 존재하므로 좋은 방법은 아니다.    
    - 비례 할당이란 각 프로세스의 특정 값에 비례하여 프레임을 할당하는 방법이다. 대표적으로 용량에 비례하여 할당할 수 있다.    
    - 프로세스 우선 순위를 고려하기 위해 우선 순위에 비례하여 프레임을 할당하거나 용량과 우선 순위를 고려하여 프레임을 할당할 수 있다.  
    - 페이지 교체에서 전역 교체란 교체할 프레임을 다른 프로세스의 프레임에서 찾는 것이며 지역 교체란 본인 프로세스의 프레임 중에서 교체할 프레임을 찾는 것이다.  
    전역 교체의 한 가지 문제점은 한 프로세스가 그 자신의 페이지 부재율을 조절할 수 없다는 것이다.  
    반면 지역 교체의 문제점은 잘 사용되지 않는 프레임이 다른 프로세스에 제공되지 않아 성능 저하가 발생한다는 점이다.  
    일반적으로 전역 교체가 널리 쓰이며 더 좋은 시스템 처리량을 보여준다.  
    - 복수의 CPU를 가진 시스템에서 종종 특정 CPU는 주 메모리의 특정 영역에 더 빠르게 접근할 수 있다.  
    - 메모리 접근 시간이 현저하게 차이가 나는 시스템을 비균등 메모리 접근(NUMA, Non-Uniform Memory Access) 시스템이라고 한다.  
    어느 페이지를 어느 프레임에 할당하느냐 하는 정책이 NUMA 성능에 큰 영향을 미친다.  
    - 프로세스에 할당된 페이지 수가 적어 과도한 페이지 교체가 일어나는 상황을 쓰레싱(Thrashing)이라고 한다.  
    - 쓰레싱이 발생하면 CPU 이용률이 떨어지고, CPU 스케쥴러는 CPU 이용률을 높이기 위해 다중 프로그래밍 정도를 높인다. 결과적으로 CPU 이용률은 악화되는 악순환이 발생한다.  
    - 쓰레싱은 지역 교체 알고리즘이나 우선순위 교체 알고리즘을 사용하면 제한할 수 있지만 모든 문제를 해결한 것은 아니다.  
    - 프로세스가 필요로 하는 프레임 수를 확인하기 위해 작업 집합 방법을 활용할 수 있다.  
    - 작업 집합 모델(Working-Set Model)은 n번의 페이지 참조 동안 참조된 페이지 집합을 확인하여 작업 집합의 개수를 확인하는 것이다. 각 프로세스의 프레임은 작업 집합 크기만큼 할당된다.    
    n이 너무 작으면 지역을 포함하지 못하고, 너무 크면 여러 지역성을 과도하게 갖고 있을 것이므로 적당한 참조 횟수를 설정하여야 한다.  
    작업 집합을 추적하는 것이 어렵다는 것이 이 모델의 단점이다. 고정 간격 타이머 인터럽트를 활용하여 근사할 수 있다.  
    - 페이지 부재 빈도(PFF, Page-Fault Frequency)는 작업 직합 모델보다 더 직접적으로 쓰레싱을 조절한다.  
    페이지 부재율의 상한과 하한을 정해서 만약 상한을 넘으면 그 프로세스에 더 많은 프레임을 할당하고, 하한에 미치지 못하면 그 프로세스로부터 프레임을 뺏어 온다.  
    직접적으로 부재율을 측정하고 제어함으로써 쓰레싱을 막을 수 있다.  
    작업 집합 모델과 마찬가지로 일부 프로세스를 스왑하여 보류할 수도 있다.  
    - 일반적으로 페이지 부재율은 새 지역의 페이지들을 요구 페이징 할 때에 정점을 찍는다.  
    - 메모리 사상 파일(Memory Mapped Files)는 가상 주소 공간의 일부가 논리적으로 파일과 관련되게 하는 것으로 입출력 실행 시 성능 향상을 제공한다.  
    - 파일의 메모리 사상은 하나의 디스크 블록을 메모리의 한 페이지 또는 페이지 집합으로 사상함으로써 이루어진다.  
    - 메모리에 사상된 파일에 대한 쓰기는 디스크에 즉시(동기적으로) 반영되지 않을 수 있다.  
    - 메모리 사상 파일은 프로세스가 파일을 닫으면 모든 메모리 사상 데이터를 디스크에 쓰고 가상 메모리에서 제거된다.  
    - 메모리 사상 I/O란 특정 메모리 영역을 장치 레지스터로 사상할 수 있도록 유보해두는 것이다.  
    - 커널은 사용자 모드 프로세스에게 할당해주기 위한 페이지 리스트와는 구분되는 별도의 풀에서 할당받는다.  
    그렇게 하는 첫 번째 이유는 커널이 다양한 크기의 자료 구조를 메모리에 할당 받기 때문이다.  
    또한 가상 메모리 인터페이스를 통하지 않고 물리 메모리에 직접 접근하는 특정 하드웨어 장티는 물리적으로 연속적인 메모리를 필요로 하는 경우가 있기 때문이다.  
    - 버디 시스템(buddy system)은 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당하느 것이다. 메모리는 2의 거듭제곱 단위로 할당된다.  
    장점 중 하나는 서로 인저한 버디들이 손쉽게 병합될 수 있다는 것이다.  
    단점은 2위 거듭제곱 형태로 할당하므로 세그먼트 내의 단편화가 발생한다는 점이다.  
    - 슬랩 할당은 캐시가 생성되면 free라고 표시된 몇 개의 객체들을 캐시에 할당하고, 커널 자료 구조를 위한 객체가 필요하다면 free 객체 중 하나를 할당하고, 할당된 객체를 used라고 표시한다.  
    슬랩흔 하나의 페이지 또는 여러 개의 페이지로 구성될 수 있다.  
    Linux 에서 슬랩은 Partial, Empty, Used 의 세 가지 상태로 구성되며, Partial < Empty < Full 순으로 슬랩을 체우게 된다.  
    슬랩 할당기를 사용하면 단편화에 의해 낭비되는 메모리가 없고, 메모리 요청이 요청이 빠르게 처리된다는 장점이 있다. 반면  메모리 할당과 해제는 오래 걸린다.  
    - 프리 페이징은 여러 개의 페이지를 동시에 프레임에 올리는 방법으로, 페이지 부재가 빈번하게 경우 잘 활용될 수 있다.  
    - 페이지 크기는 페이지 테이블을 작게 유지하기 위해서는 크게, 내부 단편화를 줄이고 메모리 이용률을 높이기 위해서는 작게 유지해야 한다.  
    - 명확한 답은 없지만 시대적으로 페이지 크기가 커져가는 추세이다.  
    - TLB 범위란 TLB로부터 액세스 할 수 있는 메모리의 크기이고, TLB 항목 수 * 페이지 크기와 그 크기가 같다.  
    - 여러 크기의 페이지를 지원하기 위해서는 하드웨어가 아니라 운영체제가 TLB를 관리해야 한다.  
    - 스택은 항상 top에서만 참조되므로 지역성이 높은 반면 해시 테이블은 참조를 분산시키므로 지역성이 나쁘다.  
    - 요구 페이징을 할 때 I/O 등 이슈로 페이지 중 일부는 고정해햐 하는 경우가 존재한다.  
    방법 중 하나로 사용자 공간에서는 입출력이 발생하지 않고 입출력은 시스템 메모리와 입줄력 장치 사이에서만 행해지도록 한느 것이다.  
    다른 해결책은 페이지를 메모리에 잠금하는 것이다. 잠금 비트를 각 프레임마다 두어서 셋팅 한다 입출력이 완료될 때 페이지 잠금이 해제된다.  
    잠금 비트는 그 외에도 최소한 한 번이라도 사용될 때까지 페이지 교체가 불가능하게 한다거나 할 수 있다.  
    - Windows XP는 클러스터링 방식을 결합한 요구 페이징 가상 메모리를 사용한다.  
    페이지 부재가 발생하면 여러 개의 페이지를 함께 가져온다.  
    프로세스가 처음 생성될 때 작업 집합의 상한과 하한을 설정한다. 상한치를 넘어서서 페이지 부재가 발생하면 지역 교체를 하고, 
    시스템 가용 공간이 임계치보다 낮아지면 시스템이 자동으로 자동 작업 직합 조절 전술을 수행한다.  
    - Solaris 에서 스레드가 페이지 부재를 일으키면 커널은 자신이 관리하고 있는 가용 페이지 리스트로부터 페이지를 확보해 전달한다.  
    따라서 운영체제 커널은 항상 충분한 가용 공간을 갖고 있어야 한다.  

#### 10장) 파일 시스템
    - 파일은 보조 저장장치에 기록된 관련 정보의 명명된 집합으로 정의할 수 있다. 사용자 관점에서 파일은 논리적 보조 저장장치의 가장 작은 할당 단위이다.  
    - 파일은 운영체제마다 다르지마 전형적으로 이름, 식별자(통상 하나의 숫자로 시스템이 읽는 파일 이름), 타입, 위치, 크기, 보호(사용자별 권한 등), 시간, 날짜, 사용자 정보 등의 속성을 갖는다.  
    - 파일 연산으로 파일 생성, 파일 쓰기, 파일 읽기, 파일 안에서의 위치 재설정, 파일 삭제, 파일 절단이 있다.  
    파일 생성을 하기 위해서 파일 시스템 내애서 공간을 찾아야 하며, 생성된 파일에 대한 항목이 디렉터리에 만들어져야 한다.  
    파일 쓰기를 위해서 디렉터리를 탐색하고, 파일 내의 다음 쓰기가 일어날 위치를 가리키는 쓰기 포인터를 유지하여야 한다.  
    파일 읽기를 위해서 파일의 이름과 파일이 읽혀 들어갈 메모리 블록의 위치를 명시하는 시스템 호출을 사용한다. 시스템은 다음 읽기가 일어날 위치를 가리키는 읽기 포인터를 유지하여야 한다.  
    대부분의 시스템은 하나의 현재 파일 위치 포인터를 갖고 읽기와 쓰기 모두 이 포인터를 사용함으로써 시스템 복잡성을 감소시킨다.  
    파일 안에서의 위치 재설정은 현재 파일 위치를 주어진 값으로 설정한다. 파일 탐색(seek)으로도 알려져 있다.  
    파일 삭제를 위해 지명된 파일을 디렉토리에서 찾는다. 파일을 발견하면 해당 파일이 차지하고 있는 공간을 방출하고 디렉토리 항목에서 삭제한다.  
    파일 절단은 사용자가 파일의 내용은 지우고 속성은 그대로 남기기를 원할 때 사용한다. 파일의 길이가 0으로 설정되며 파일이 갖고 있던 공간은 해제된다.  
    - 운영체제는 모든 열린 파일에 대한 정보를 갖는 열린 파일 테이블을 유지한다.  
    - 보통 운영체제는 프로세스 별 테이블과 범 시스템 테이블을 사용하여 열린 파일 테이블을 관리한다.  
    - 범 시스템 테이블에는 프로세스에 독립적인 정보와 오픈 계수가 기록된다. close() 는 이 계수를 감소시키고, 계수가 0이 되면 테이블에서 제거된다.  
    - 열린 파일과 관련된 정보로는 각 프로세스 별 파일 포인터, 오픈 계수, 파일 디스크 위치, 접근 권한 등이 있다.  
    - 파일 잠금으로 공유 잠금과 배타적 잠금이 있다. 공유 잠금은 여러 프로세스가 동시에 잠금을 획득할 수 있고, 배타적 잠금은 한 프로세스만 잠금을 획들할 수 있다.  
    - 운영체제는 강제적 또는 권고적으로 파일 잠금 방법을 제공할 수 있다.  
    - 운영체제가 파일 타입을 인식하고 지원할 것인지 결정하는 것은 운영체제 설계 시 중요한 사항 중 하나이다.  
    - 흔히 잘 알려진 방법은 파일 이름을 마침표로 구분되는 이름과 확장자 두 부분으로 나누는 것이다.  
    - 시스템은 확장자를 사용하여 파일의 유형과 그 파일이 할 수 있는 연산의 유형을 표시한다. 예를 들어 .exe 확장자를 갖는 파일은 실행 가능한 파일이다.  
    - 확장자는 필수적인 것은 아니다.  
    - 파일 타입을 사용하여 파일 내부 구조 형태를 짐작할 수 있다.  
    - UNIX는 파일을 단순히 8비트 바이트들의 단순한 집합으로 보기 때문에 운영체제가 이를 해석하지 않는다.  
    이러한 구조는 파일 사용의 융통성을 극대화하는 대신 시스템 차원의 지원을 받기 힘들다. 이에 따라 각 응용 프로그램이 각자의 파일에 대한 적절한 해석과 운용을 책임져야 한다.  
    - 모든 디스크 I/O는 한 블록 단위(물리적인 레코드)로 실행되며 모든 디스크 블록은 동일한 크기를 가진다.  
    물리 레코드의 길이가 원하는 논리 레코드의 길이와 일치하지 않는 것이 일반적인데, 이런 경우 여러 논리 레코드를 하나의 물리 레코드에 팩킹(packing)하는 것이 이 차이를 해결하는 일반적인 해결책이다.  
    - 예를 들어 UNIX의 경우 논리 레코드 크기가 1바이트인 반면, 디스크 블록의 크기는 512바이트이므로 필요에 따라 블록을 팩킹하거나 언팩킹한다.  
    - 파일은 일련의 블록으로 이루어진 것이며, 모든 I/O는 블록 단위로 실행된다. 논리 레코드와 물리 블록과의 변환은 소프트웨어의 문제이다.  
    - 블록 단위로 처리하기 때문에 발생하는 블록 내의 쓸모없는 공간을 내부 단편(Internal Fragmentation) 이라고 한다.  
    - 순차 접근(Sequential Access)이란 파일의 정보가 레코드 순서대로 처리되는 접근이다. 편집기나 컴파일러는 보통 이러한 형식으로 파일에 접근한다.  
    - 직접 접근(Direct Access 또는 상대 접근)에서 파일은 고정 길이의 논리 레코드로 구성되고 특별한 순서 없이 빠르게 레코드를 읽고 쓸 수 있다.  
    직접 접근은 파일의 디스크 모델에 기반을 두며 이는 디스크가 무작위 파일 블록에 임의적 접근을 허용하기 때문이다.  
    직접 접근 파일은 대규모의 정보를 즉각적으로 접근하는 데에 유용하며, 대규모 데이터베이스가 이러한 유형의 한 예이다.    
    통상 사용자가 운영체제에게 전달하는 블록 번호는 0, 1, ... 과 같은 상대 블록 번호이며, 실제 물리 블록 주소로의 변환이 필요하다.  
    상대 블록 번호를 사용하기 위해서 운영체제가 파일이 어디에 저장되어야 하는지를 결정하는 것을 할당 문제라고 한다.  
    - 모든 운영체제가 직접 접근 파일과 순차 접근 파일 모두를 제공하는 것은 아니다.  
    - 직접 접근 파일을 순차 접근 파일처럼 사용하기는 쉬우나, 순차 접근 파일을 직접 접근 파일처럼 사용하는 것은 비효율적이다.  
    - 직접 접근 파일에 기반을 두고 다른 여러 가지 파일 접근 방법을 제공할 수 있는데, 이러한 방법은 일반적으로 파일에 대한 색인(indexx)을 구축해야 한다.  
    - 파일 시스템을 포함하고 있는 임의의 개체를 볼륨(volume)이라고 한다. 볼륨은 장치의 부분 집합, 전체 장치 또는 RAID 집합으로 연결된 다수의 장치일 수 있다. 각 볼륨은 논리적인 가상 디스크로 취급될 수 있다.  
    - 파일 시스템을 포함하고 있는 각 볼륨은 시스템에 존재하는 파일에 대한 정보 역시 갖고 있어야 한다. 이 정보는 디바이스 디렉터리(device directory) 또는 콘텐츠 볼륨 테이블(volume tables of contents)의 항목들에 저장된다.  
    - 디렉터리는 파일 이름을 해당 디렉터리 항목으로 변환해주는 심벌 테이블(symbol table)로 볼 수 있다.  
    - 디렉토리에서 파일 찾기, 파일 생성, 파일 삭제, 디렉터리 나열, 파일 재명명, 파일 시스템 순회 등의 연산을 수행할 수 있다.  
    - 가장 간단한 디렉터리 구조로 1단계 디렉터리(Single level directory)가 있다. 디렉터리 계층이 없고 모든 파일이 디렉터리 밑에 존재하기 때문에 이해가 쉽다.  
    그러나 파일이 많아지거나 다수의 사용자가 사용하는 시스템에서는 심각한 제약을 갖고 있다.  
    - 2단계 디렉터리(Two level directory) 구조에서 각 사용자는 자신만의 사용자 파일 디렉터리(UFD, User File Directory)를 가진다.  
    사용자 작업이 시작되거나 사용자가 시스템에 로그인하면 시스템의 마스터 파일 데릭터리(MFD, Master File Directory)가 먼저 탐생되다.  
    사용자가 특정 파일을 참조하면 사용자의 UFD 에서만 탐색을 수행한다. 필요에 따라 사용자 디렉터리 자체를 만들고 없앨 수 있어야 한다.  
    사용자들이 완벽히 독립적인 경우에 이 격리는 장점이 되지만, 협력적 잡업이 필요해 다른 사용자의 파일에 접근해야 하는 경우에는 단점이 될 수 있다.  
    - 트리 구조 디렉터리는 2단계 디렉터리 구조의 확장으로 사용자가 자신의 서브디렉터리를 만들어서 파일을 구성할 수 있게 한다. 가장 일반적으로 사용되는 디렉터리 구조이다.  
    디렉터리는 파일이지만 특별하게 취급된다. 디렉터리의 각 항목은 한 비트를 사용하여 그 항목이 나타내는 파일이 일반 파일인지 디렉터리 파일인지 구분한다.  
    통상적으로 각 프로세스는 현재 디렉터리를 갖고 있다. 파일을 참조하면 현재 디렉터리가 먼저 검색된다.  
    - 트리 구조에서 정해야 하는 정책 중 하나는 디렉터리 삭제를 어떻게 할 것인가이다. 만약 디렉터리가 비어있다면 지우면 되지만 제거 대상 디렉터리가 비어 있지 않을 경우 정책을 정해야 한다.  
    - 비순환 그래프 디렉터리는 사이클을 생성하지 않으면 서브디렉터리와 파일들을 공유할 수 있도록 허용한다.  
    공유 파일은 여러가지 방법으로 구현 가능하다. 많은 UNIX 시스템에서 볼 수 있는 보편적인 방법은 링크(link)라 불리는 새로운 디렉터리 항목을 만드는 것이다. 링크는 다른 파일이나 디렉터리를 가리키는 포인터이다.  
    공유 파일을 구현하는 또 다른 방법은 공유하는 디렉터리들이 공유 파일에 대한 모든 정보를 복사해서 갖고 있는 방법이다.  
    비순환 그래프 디렉터리 구조에서 파일 이름이 다르더라고 동일한 파일을 가리킬 수 있다.  
    또한 공유 파일에 할당된 공간은 언제 반납되어 재사용할 수 있는가를 고려해야 한다.  
    심벌릭 링크로 공유를 구현하는 시스템에서는 링크가 삭제되면 원본 파일에 아무 영향이 없고 단지 링크만 제거된다. 원본 파일을 삭제할 경우 링크는 실행되었을 때 처리한다.  
    삭제하는 또 다른 방법은 모든 참조가 지워질 때까지 원본 파일을 보존하는 것이다. 이 방법을 구현하기 위해서는 파일에 대한 마지막 참조가 삭제되었는지 결정할 수 있는 방법이 필요하다.  
    비순환 그래프의 장점은 그래프를 순회하고 파일에 대한 참조의 존재 여부를 결정하는 알고리즘이 비교적 간다하다는 것이다.  
    - 각 볼륨들은 마운트(mount) 되어야 파일 시스템 지명 공간 안에서 이용 가능하다. 운영체제가 디바이스 이름과 마운트 포인트를 전달받아 마운트한다.  
    일반적으로 마운트 포인트는 비어있는 디렉터리이다.  
    - 운영체제가 여러 사용자를 수용할 때 파일 공유, 지명과 보호가 더욱 중요해진다. 대부분의 시스템은 파일/디렉터리 소유자와 그룹이라는 개념을 사용하는 형태로 발전해왔다.  
    파일의 그룹 속성은 파일에 대한 접근을 공유할 수 있는 사용자들의 부분집합을 정의한다.  
    - 원격 파일 시스템은 처음에는 FTP 같은 프로그램을 통해 기계 간에 파일을 직접 전송하다가, 
    로컬 기계에서 원격 디렉터리에 접근할 수 있는 분산 파일 시스템(DFS, Distributed File System), 마지막으로 www의 사용으로 발전되었다.  
    www는 어떤 면에서는 첫 번째 방법으로의 회귀라고 할 수 있다.  
    FTP는 익명 또는 인증형 접근 모두에 사용할 수 있다.  
    DFS는 로컬 기계와 원격 파일 사이에 보다 더 긴밀한 통합을 하며, 이러한 통합은 복잡성을 증가시킨다.  
    - 원격 파일 시스템은 컴퓨터가 하나 이상의 원격 시스템으로부터 하나 이상의 파일 시스템을 마운트하는 것을 허용한다. 이런 경우 파일을 갖고 있는 컴퓨터를 서버라고 하고 파일에 접근하기를 원하는 컴퓨터를 클라이언트라고 한다.  
    클라이언트 신원 확인은 어렵다. 클라이언트는 네트워크 이름이나 IP 주소 같은 다른 식별자로 명시 가능하지만, 도용(Spoofing)되거나 모방(Imitation)될 수 있다.  
    안전한 해결 방안은 암호화된 키를 통하여 클라이언트를 보안 인증하는 것이다.  
    - 클라이언트-서버 시스템을 쉽게 관리하기 위해 분산 정보 시스템 또는 분산 네이밍 서비스가 원격 컴퓨팅을 위해 필요한 정보에 단일화된 접근을 제공한다.  
    그중 하나인 도메인 네임 서비스(DNS)는 WWW를 포함하는 전체 인터넷의 호스트 이름을 네트워크 주소로 변환하는 서비스를 제공한다.  
    Microsoft의 공통 인터넷 파일 시스템(CIFS, Common Internet File System)의 경우 서버가 요청된 파일 시스템에 접근을 허용할지 거부할지를 결정하기 위하여 네트워크 로그인을 사용하며, 네트워크 로그인은 사용자 인증 정보와 네트워크 정보를 결합하여 생성한다.  
    산업계는 안전한 분산 지명 기법인 경량 디렉터리 접근 프로토콜(LDAP, Lightweight Directory-Access Protocol)을 이용하는 추세다.  
    - 로컬 파일 시스템은 디스크 고장, 메타데이터 오염 또는 호스트 어댑터 고장 등 여러가지 이유로 고장이 발생할 수 있다.  
    원격 파일 시스템은 더 많은 고장 모드를 가진다. 네트워크 시스템의 복잡성과 원격 시스템 간에 요구되는 상호작용 때문에 더 많은 문제가 원격 파일 시스템의 제대로 된 연산을 방해한다.  
    이런 고장 시맨틱은 원격 파일 시스템 프로토콜의 일부로서 정의되고 구현된다.  
    - 고장으로부터 복구를 구현하기 위해 어떤 종류의 상태 정보가 클라이언트와 서버 모두에 유지될 수 있다.  
    만약 서버와 클라이언트가 현재의 활동과 열린 파일을 알고 있다면 고장으로부터 복구될 수 있다.  
    - 일관성 의미는 파일 공유를 지원하는 파일 시스템을 평가하는 데 있어 중요한 기준을 말한다.    
    - 열기와 닫기 연산 사이의 일련의 접근은 하나의 파일 세션을 생성한다.  
    - UNIX 파일 시스템은 열린 파일에 대한 사용자의 쓰기는 동일한 파일을 연 다른 사용자에게 즉시 보이고, 사용자들이 파일 내의 현재 위치 포인터를 공유하는 공유 모드가 있는 일관성 의미를 사용한다.  
    - 앤드류 파일 시스템은 열린 파일에 대한 사용자의 쓰기가 동일한 파일을 연 다른 사용자에게 즉시 보이지 않고, 파일에 대한 변경은 세션이 종료된 후 나중에 시작되는 파일 세션에서만 보인다.  
    - 불변 공유 파일은 파일이 파일 생성자에 의해 공유된다고 선언되면 더 이상 변경될 수 없는 파일이다.  
    - 정보가 컴퓨터에 저장되어 있을 때 물리적인 손상(신뢰성)과 부적절한 접근(보호)로부터 안전하게 유지되길 바란다. 신뢰성은 일반적으로 파일 복사본에 의해 제공된다.  
    - 파일을 보호할 필요는 파일에 접근할 수 있는 능력에 직접적으로 기인한다. 다른 사용자의 파일에 접근을 허용하지 않는 시스템은 보호가 필요하지 않다.  
    - 보호 기법은 실행 가능한 파일 접근 타입을 제한함으로써 통제된 접근을 제공한다.  
    - 보호를 위한 가장 일반적인 방법은 접근 허용 여부를 사용자의 신원에 의거하는 것이다.  
    신원에 의거한 접근을 구현하는 가장 일반적인 방법은 각 파일과 디렉터리에 접근 제어 리스트(ACL, Access-Control List)를 연관해두는 것이다.  
    접근 리스트의 주요 문제점은 리스트의 길이이다. 특히 시스템의 사용자 리스트를 미리 알 수 없고, 디렉터리 항목이 가변 크기가 되어야 한다.  
    따라서 이에 변형하여 사용자를 소유자, 그룹, 모든 사람의 세 가지 부류로 분류하는 것과 ACL을 결합하여 접근을 제어하는 것이 일반적이다.  
    - 소유자, 그룹, 모든 사용자 분류와 ACL의 권한이 상충할 때에 우선권에 대한 고려가 되어야 한다. 일반적으로 ACL이 보다 특수한 케이스이므로 ACL을 우선한다.  
    - 보호 문제를 해결하기 위해 사용할 수 있는 또 다른 방법은 파일마다 암호를 연결시키는 것이다.  

#### 11장) 파일 시스템 구현
    - 메모리와 디스크 간의 입출력 전송은 블록 단위로 실행된다. 각 블록은 하나 이상의 섹터를 갖고, 섹터는 32바이트부터 4,096바이트까지 다양하지만 통상 512바이트이다.  
    - 파일 시스템을 설계할 때 사용자에게 어떻게 보여야 할지와 논리 파일 시스템을 물리 2차 저장장치로 맵핑하는 알고리즘과 자료구조에 대한 구현을 고려해야 한다.  
    - 제일 낮은 층인 입출력 제어(I/O control) 층은 장치 드라이버와 인터럽트 핸들러로 이루어져 있고 메모리와 디스크 시스템 간의 정보 전송을 담당한다.  
    - 기본 파일 시스템 층은 적절한 장치 드라이버에게 디스크 상의 물리 블록을 읽고 쓰드록 일반적인 명령을 내리는 층이다. 각 디스크 블록은 숫자로 표시된 디스크 주소에 의하여 식별된다.  
    - 캐시는 종종 성능 향상을 시키기 위해 파일 시스템 메타데이터를 저장하는 데에 사용된다. 최적 성능을 위해 캐시 내용 관리는 필수적이다.  
    - 파일-구성 모듈(File-organization module) 층은 물리 블록 뿐만 아니라 파일과 파일의 논리 블록도 알고 있다. 논리 블록 주소를 물리 블록 주소로 변환할 수 있다.  
    - 논리 파일 시스템(Logical File System) 층은 메타데이터 정보를 관리한다.  
    - 파일 구조는 파일 제어 블록을 통해 유지된다. 파일 제어 블록(FCB, File Control Block)는 소유, 허가와 파일 위치 등의 정보를 갖고 있다.  
    - 계층화는 더 많은 운영체제 오버헤드를 야기하여 성능을 저하시킨다.  
    - 부트 제어 블록(Boot Control Block)은 시스템이 볼륨으로부터 운영체제를 부트시키기 위해 필요한 정보를 갖고 있다. 디스크가 운영체제를 갖고 있지 않다면 부트 제어 블록은 비어있을 것이다.  
    부트 제어 블록은 일반적으로 볼륨의 첫 번째 블록이다. UFS에서는 부트 블록, NTFS에서는 파티션 부트 섹터라고 부른다.  
    - 볼륨 제어 블록(Volume Control Block)은 볼륨의 블록의 수, 블록의 크기, 가용 블록의 수와 포인터, 가용 FCB 수와 포인터 같은 상세한 볼륨 정보를 가진다.  
    UFS에서는 수퍼 블록(Super Block), NTFS에서는 마스터 파일 테이블(Master File Table)이라 불린다.  
    - 디렉터리 구조는 파일 시스템마다 존재하며 파일을 조직하는 데에 사용된다.  
    - 파일별 FCB는 자세한 파일 정보를 가지고 있다. FCB는 디렉터리 항목과의 연결을 위한 고유 식별 번호를 갖고 있다.  
    - 메모리 내의 정보는 파일 시스템 관리와 캐싱을 통한 성능 향상을 위해 사용된다. 이 정보들은 마운트 시점에 적재되고, 파일 시스템 동작 중에 갱신되며 마운트 해제 시에 제거된다.  
    - 범 시스템 열린 파일 테이블은 다른 정보와 더불어 모든 열린 각 파일의 FCB 복사본을 갖고 있다.  
    - 프로세스 별 열린 파일 테이블은 다른 정보 뿐 아니라 범 시스템 오픈 파일 테이블 내의 해당 항목에 대한 포인터를 포함한다.  
    - 버퍼는 파일 시스템이 디스크로부터 읽혀지거나 써질 때 파일 시스템 블록을 저장한다.  
    - UNIX를 포함한 몇몇 운영체제는 디렉터리를 파일을 처리하는 방식과 정확히 같은 방식으로 처리한다.  
    - Windows NT 등의 시스템은 파일과 디렉터리를 위한 개별 시스템 호출을 구현하고, 디렉터리와 파일을 다른 개체로 취급한다.  
    - 현대의 운영체제는 동시에 여러 타입의 파일 시스템을 지원해야만 한다. 세부적인 구현 사항으로부터 기본 시스템 호출 기능을 격리시키기 위해 자료구조와 프로시져가 사용된다.  
    이는 세 가지 주요한 계층으로 구성된다. 첫 번째 계층은 열기, 읽기, 쓰기와 닫기 호출과 파일 디스크립터에 기반을 둔 파일 시스템 인터페이스이다.    
    두 번째 계층은 가상 파일 시스템(VFS, Virtual File System)이라고 한다. VFS를 명확하게 정의함으로써 파일 시스템의 일반적 연산을 구현과 분리시키고, VFS는 파일을 네트워크 전체에서 고유하게 표현할 수 있는 방법을 제공한다.  
    VFS는 vnode라 불리는 파일 표현 구조에 기반을 둔다. vnode는 네트워크 전체에서 유일한 파일에 대한 수치 지정자(designator)를 포함하고 있다.  
    - Linux VFS 에서 정의한 네 가지의 기본 객체 타입은 innode 객체(파일), file 객체(오픈 파일), superblcok 객체(전체 파일 시스템)와 dentry 객체(디렉터리 항목)이다.  
    - 디렉터리를 구현하는 가장 간단한 방법은 파일 이름과 데이터 블록을 가리키는 포인터들의 선형 리스트를 사용하는 것이다. 쉽지만 실행시간이 길다. B-Tree 가 도움이 될 수 있다.  
    - 또 다른 디렉터리 구조로 해시 테이블을 사용한다. 충돌에 대한 대비가 필요하지만, 삽입과 삭제가 쉽게 행해진다.  
    해시 테이블의 심각한 문제점은 일반적으로 해시 테이블이 고정된 크기를 갖는다는 점과 해시 테이블의 크기에 따라 해시 함수도 제한을 받는다는 점이다.  
    대안으로 체인 오버플로우 해시 테이블을 사용할 수 있다.  
    - 연속 할당 방식은 각 파일이 디스크 내에서 반드시 연속적인 공간을 차지하도록 할당한다.  
    - 디스크 주소들은 디스크 상에서 선형 순서를 정의한다. 이러한 순서를 따를 경우 오직 한 작업만이 디스크에 접근한다고 가정하고, 블록 b 다음에 블록 b+1에 접근한다면 통상 헤드 이동을 필요로 하지 않는다.  
    연속 할당 기법에서 한 가지 어려운 점은 새로운 파일을 위한 가용 공간을 찾는 일이다.  
    최초 적합과 최적 적합이 할당 공간을 선택하는 가장 일반적인 전략이다. 이들 알고리즘은 모두 외부 단편화의 문제가 있다.  
    만약 너무 작은 공간을 예약했다면 파일이 커질 수 없다. 특히 최적 적합 방법으로 공간을 할당했다면 문제가 두드러진다. 이에 대한 해결 방법 첫 번째는 오류를 발생시키는 것이다. 다른 방법은 다른 공간을 찾아 파일을 복사하는 것이다.  
    단점을 최소화하기 위해 많은 운영체제가 변형된 연속 할당 기법을 사용한다. 이 기법은 어느 정도 연속된 공간만 초기에 할당하고 이후 그 양이 충분하지 않을 때 또 다른 연속된 공간을 extend 라고 부르는 단위로 할당한다.  
    - 연결 할당은 연속 할당의 모든 문제를 해결한다. 연결 할당에서 파일은 디스크 블록의 연결 리스트이고 디스크 블록은 디스크의 어느 곳에도 산재할 수 있다.  
    새 파일을 생성하려면 단순히 디렉터리 내의 새로운 항목을 만들면 된다. 연결 할당의 경우 각 디렉터리 항목은 파일의 첫 디스크 블록을 가리키는 포인터를 갖고 있다.  
    이 포인터는 처음에는 빈 파일을 표시하기 위해 nil(리스트의 끝을 나타내는 포인터 값) 으로 초기화되고 크기 필드 역시 0으로 설정된다.  
    가용 블록이 존재하는 한 파일은 계속해서 커질 수 있으며 디스크 공간을 밀집화할 필요도 없다.  
    - 연결 할당의 단점은 순차 접근 파일에만 효과적이라는 것이다. 다른 위치로 가기 위해 파일의 처음부터 다시 포인터를 따라가야 한다.  
    또 다른 단점은 포인터를 위한 공간이 필요하다는 것이다. 이 문제의 보통 해결 방법은 여러 블록들을 하나의 클러스터로 구성하여 클러스터 단위로 할당하는 것이다.  
    또 다른 문제점은 신뢰성 문제이다. 포인터가 없어지거나 망가지면 해당 블록을 찾을 수 없다. 한 가지 부분적인 해결책은 이중 연결 리스트를 사용하는 것이고, 다른 해결책은 각 블록마다 파일 이름과 상대 블록 번호를 저장하는 것이다.  
    연결 할당의 가장 중요한 변형은 파일 할당 테이블(FAT, FIle Allocation Table)을 사용하는 것이다. 각 볼륨의 시작부분 일부가 FAT로 사용된다.  
    FAT 는 각 디스크 블록마다 한 개의 항목을 갖고 있고 이 항목은 디스크 블록 번호를 인덱스로 삼아 찾는다. 그 블록 번호가 인덱싱하는 FAT 테이블 항목은 파일의 다음 블록 번호를 가리킨다.  
    - FAT 할당 기법은 FAT가 캐시되지 않으면 상당한 수의 디스크 헤드 탐색을 유발할 수 있다.  
    - 색인 할당에서 각 파일들은 디스크 블록 주소를 모아 놓은 배열인 색인 블록을 가진다. 색인 블록의 i번째 항목은 파일의 i번째 블록을 가리킨다. 디렉터리는 색인 블록의 주소를 갖고 있다.  
    색인 할당은 외부 단편화 없이 직접 접근을 제공한다. 디스크 가용 블록이 어느 것이라도 크기 확장 요청을 만족시킬 수 있기 때문이다.  
    그러나 색인 할당은 공간 낭비가 문제점이다. 인덱스 블록의 포인터 오버헤드는 연결 할당의 포인터 오버헤드보타 큰 것이 일반적이다.  
    - 색인 블록이 얼마나 커야 하는지 결정해야 한다. 각 파일들은 하나의 색인 블록을 가져야 하므로 색인 블록의 크기는 가능한 한 작은 것이 좋다.  
    그러나 색인 블록이 너무 작다면 큰 파일들에 대해서 충분한 포인터 공간을 가질 수 없다.  
    이를 해결하기 위해 연결 기법, 다중 수중 색인, 결합 기법 등이 쓰인다.  
    연결 기법은 파일의 크기가 크면 여러 개의 색인 블록들을 연결시킨다. 한 색인 블록이 파일의 이름을 나타내는 헤더와 첫 100개의 디스크 블록 주소를 포함할 수 있다. 다음 주소는 작은 파일의 경우 nil, 큰 파일의 경우 다른 인덱스 블록에 대한 포인터가 된다.  
    다중 수준 색인은 1차 단계 인덱스 블록이 2차 단계 인덱스 블록 집합을 가리키고, 2차 단계 인덱스 블록이 파일 블록을 가리키게 하는 방식이다.  
    결합기법은 인덱스 블록의 첫 15개 포인터를 파일의 인덱스에 유지시킨다. 이 포인터의 처음 12개는 직접 블록을 가리킨다. 12블록을 넘지 않는 작은 파일의 데이터는 별도의 인덱스 블록이 필요하지 않다.  
    그러나 큰 경우에 다음 3개 포인터는 간접 블록을 가리킨다. 이 포인터들 중 첫 번째 포인터는 단일 간접 블록을 가리킨다. 데이터가 저장되어 있는 블록을 가리키는 인덱스 블록이다.  
    두 번째 포인터는 이중 간접 블록을 가리킨다. 단일 간접 블록의 포인터들을 저장하는 블록을 가리킨다.  
    세 번재 포인터는 삼중 간접 블록을 가리킨다. 이중 간접 블록의 포인터들을 저장하는 블록을 가리킨다.  
    - 몇몇 시스템은 연속 할당을 사용하여 직접 접근 파일을, 연결 할당을 사용하여 순차 접근 파일을 접근할 수 있도록 지원한다.  
    - 가용 공간 리스트는 흔히 비트맵 또는 비트 벡터 형태로 구현된다. 이 방법의 큰 이점은 첫 번째 가용 블록 또는 n개의 연속된 가용 블록들을 찾는 일이 간단하고 효율적이라는 점이다.  
    불행하게도 비트 벡터는 전체 벡터가 주 메모리에 유지되고 복구를 위하여 때떄로 디스크에 쓰이지 않으면 비효율적이다.  
    - 가용 공간을 관리하는 다른 방법은 모든 가용 디스크 블록을 함께 연결하는 것이다. 첫 번째 가용 블록을 가리키는 포인터는 디스크의 특별한 위치에 저장하고 메모리에 캐싱한다.  
    가용 리스트 방식의 변형으로 첫 번째 가용 블록 내에 n개의 블록 주소를 저장하는 방법이 있다. 이중 처음 n-1개는 실제로 비어있는 블록의 주소이다. 그러나 마지막 1개는 자신과 마찬가지로 n-1개의 빈 블록 주소를 가지고 있는 가용 블록을 가리킨다.  
    또 다른 변형으로 일반적으로 여러 개의 연속적인 블록이 동시에 할당되고 반환된다는 이점을 이용하는 것으로, 연속 할당 알고리즘이나 클러스터링을 통해 공간을 할당할 경우 유용하다.  
    모든 블록을 일일이 추적할 필요 없이 연속된 가용 블록의 첫 번째 블록 주소와 연속된 블록 개수만 유지하면 보다 효율적이다.  
    - Sun의 ZFS 파일 시스템은 대규모 파일, 디렉터리, 심지어 파일 시스템을 포함하기 위하여 설계되었다.  
    - 디스크 공간의 효율적인 사용은 사용 중인 디스크 할당 및 디렉터리 알고리즘에 의해 심각하게 좌우된다. 성능 개선은 innode들을 가급적 데이터 블록 부근에 위치하도록 함으로써 디스크의 탐색 시간을 줄인 것에 기인한다.  
    또한 효율을 위해 고려해야 할 사항으로 파일의 디렉터리 항목 내에 저장되어야 할 정보의 유형이 있다.  
    - 파일 시스템 알고리즘이 결정된 후라도 여전히 시스템 성능을 향상시킬 수 있는 방법들이 있다.  
    디스크 컨트롤러들은 한 트랙의 내용을 전부 저장할 수 있을 만큼 충분한 크기의 온보드 캐시를 갖고 있다.  
    어떤 시스템은 주 메모리 내에서 별도의 구역을 버퍼 캐시용으로 유지한다.  
    다른 시스템은 파일 데이터를 페이지 캐시를 사용하여 캐시한다. 페이지 캐시는 가상 메모리 기법을 사용하여 파일 데이터를 파일 시스템 지향의 블록으로서가 아니라 페이지로써 캐시한다. 이 기법은 통합 가상 메모리(Unified Virtual Memory)로 알려져 있다.  
    - UNIX와 LINUX는 통합 버퍼 캐시(Unified Buffer Cache)를 제공한다. 일반적으로 가상 메모리 시스템은 버퍼 캐시와 인터페이스할 수 없기 때문에 버퍼 캐시에 있는 내용을 페이지 캐시로 옮겨야 하는 이중 캐싱 문제를 야기한다. 통합 버퍼 캐시는 이를 해결한 버퍼 캐시이다.  
    - 입출력 성능에 영향을 미칠 수 있는 또 다른 문제는 파일 시스템의 쓰기 연산이 동기적 혹은 비동기적으로 실행되느냐 하는 것이다.  
    거의 대부분 비동기식으로 쓰이나 메타데이터 스기 작업은 통상 동기적으로 실행된다.  
    - 일부 시스템에선느 파일의 접근 타입에 따라 다른 교체 알고리즘을 사용함으로써 페이지 캐시를 최적화한다.  
    - 순차 접근은 바로-제거(free-behind) 와 미리-읽기(read-ahead) 로 알려진 기술로 최적화한다. 바로 제거는 버퍼에서 다음 페이지가 요청되자마자 현재 페이지를 제거하는 것이며, 미리 읽기는 요구된 페이지와 몇 개의 뒤이은 페이지를 캐싱하는 것이다.  
    - 다중 프로그래밍에서도 트랙 캐시에서 메인 메모리로 적은 크기의 전송을 많이 할 경우 수반되는 높은 지연 시간과 오버헤드를 생각하면 미리 읽기는 충분한 이득을 준다.  
    - 파일 생성 같은 대표적인 연산은 디스크 상의 파일 시스템 내부의 많은 자료 구조들에 대한 변경을 포함한다. 이러햔 변경을 크래시에 의해 방해 받을 수 있고, 이들 구조 사이의 일관성이 깨지는 결과를 초래한다.  
    - 파일 시스템은 오염을 처리하기 위해서 파일 시스템 자료 구조와 알고리즘에 따라 다양한 방법들을 갖고 있다.  
    - 파일 시스템은 문제를 검출하고 교정할 수 있어야 한다. 검출을 위해서 각 파일 시스템의 모든 메타데이터에 대한 검사를 통하여 파일 시스템의 일관성을 확인하거나 부정할 수 있다.  
    불행하게도 이 검사는 몇 분에서 몇 시간이 소요되며 시스템이 부트될 때마다 실행되어야 한다.  
    대체 방안으로 파일 시스템 메타데이터 안에 자신의 상태를 기록할 수 있다. 메타데이터를 변경하려고 할 때 이 상태 비트는 메타데이터가 변경 중 상태라는 것을 표시하고 갱신이 성공적으로 완료되면 해당 비트를 소거한다.  
    그러나 상태 비트가 1로 남아있으면 일관성 검사를 수행한다.  
    - 일관성 검사기는 디렉터리 구조에 있는 데이터와 디스크에 있는 데이터 블록을 비교하고 불일치가 발견되면 그것을 정정하려고 시도한다.  
    - 파일 시스템 메타데이터 갱신에 로그 기반 복구 기술을 적용할 수 있다. NTFS와 Veritas 파일 시스템 모두 이 기술을 사용한다.  
    모든 메타데이터 변경은 로그에 순차적으로 기록된다. 확약된 트랜잭션 전부가 완료되면 로그 파일로부터 제거된다.  
    시스템이 크래시되면 로그 파일에 0개 이상의 트랜잭션이 있을 것이다. 유일한 문제는 트랜잭션이 중단(abort)되었을 때 발생한다. 그 트랜잭션은 시스템이 크래시하기 전에 확약되지 않은 것이다.  
    디스크 메타데이터를 갱신할 때 로그를 사용하는 부수적인 이득은 디스크 데이터 구죠에 직접 적용하는 것보다 갱신이 더 빠르다는 것이다.  
    이러한 성능 향상의 이유는 임의 입출력에 비해 순차 입출력이 빠르다는 데에서 찾을 수 있다.  
    - 일관성 검사 이외의 또 다른 해결 방안이 WAFL 파일 시스템과 ZFS 파일 시스템에 채택되었다. 이 시스템들은 옛날 데이터를 새 데이터로 절대 덮어쓰지 않는다.  
    - 전형적인 백업 과정은 첫째 날에 전체 백업을 하고, 둘째 날에 변경된 내용만 저장하는 점증적 백업을 한다. 이후 n일까지 점증적 백업을 한 후 n+1일에 다시 전체 백업을 실행한다.  
    이러한 백업 사이클의 추가 장점은 사이클 동안 뜻하지 않게 삭제한 파일도 복원할 수 있다는 점이다.  
    - 네트워크 파일 시스템(NFS)는 이제 흔히 사용되기 때문에 특별하지 않다. NFS는 클라이언트 시스템의 전체적인 디렉터리 구조 및 인터페이스와 통합되어 있다.  
    - NFS는 LAN(또는 WAN)을 거쳐 원격 파일에 접근하기 위한 소프트웨어 시스템의 구현과 명세 모두를 말한다.  
    - 일부 NFS 구현에서 연속 마운트를 허용한다. 즉 한 파일 시스템이 원격 마운트된 파일 시스템을 다시 원격 마운트할 수 있다.  
    원격 파일 시스템을 마운트해도 마운트된 시스템에 마운트되어 있는 다른 파일 시스템에 접근할 수 없다. 그러므로 이행성(Transitivity)를 갖지 않는다.  
    만일 공유되는 디렉터리를 네트워크 상의 모든 기계들의 사용자 홈 디렉터리에 마운트한다면 사용자는 어느 곳에서나 자신의 홈 환경을 유지할 수 있다. 이러한 특성은 사용자 이동성(User Mobility)를 허용한다.  
    NFS 명세는 마운트 기법에 의해 제공되는 서비스와 실제 원격 파일 접근(Remote File Access) 서비스를 구분한다. 따라서 두 가지의 다른 프로토콜이 명세되어 있다. 마운트 프로토콜과 NFS 프로토콜로 불리는 것이 그것들이다.  
    - 마운트 프로토콜은 서비스와 클라이언트 사이에 최초의 논리적 연결을 생성하기 위해서 사용된다.  
    마운트 요청은 적절한 RPC로 맵핑되고, 지명된 서버 기계 상에서 실행되는 마운트 서버로 전달된다.  
    - NFS 프로토콜은 원격 파일 연산을 위한 원격 프로시저 호출 집합을 제공한다. 이중 open 과 close 연산은 의도적으로 제외되었다.  
    NFS 서비스의 주요 특징은 무상태성이다. 서버는 하나의 접근과 다른 접근 사이에 클라이언트에 대한 정보를 유지하지 않는다.  
    적절한 동작을 위해 유일한 파일 식별자와 파일 내부의 절대적인 변위와 같은 모든 인자들을 제공해야 한다.  
    - 서버의 무상태성과 RPC 동기성이 갖는 부가적인 의미는 결과가 클라이언트에 반환되기 전에 변경된 자료가 서버의 디스크에 기록되어야 한다는 것이다.  
    - 하나의 NFS 쓰기 프로시저 호출은 원자성이 보장되며 같은 파일에 대한 다른 쓰기 호출과 혼합되지 않는다.  
    - 그러나 NFS 프로토콜은 병행성 제어 기법(Concurrency Control Mechanism)을 제공하지 않는다.
    
#### 12장) 2차 저장장치 구조
    - 자기디스크는 현대의 컴퓨터 시스템을 위해 대량의 보조 저장장치를 제공한다.  
    - 각 디스크의 플래터는 CD처럼 생긴 원형 평판 모양이다. 읽기, 쓰기 헤드는 모든 플래터의 각 표면 바로 위에서 움직인다.  
    헤드는 모든 헤드를 한꺼번에 이동시키는 디스크 암에 부착되어 있다. 플래터의 표면은 원형의 트랙으로 논리적으로 나뉘고, 이것은 다시 섹터로 나뉜다.  
    동일한 암 위치에 있는 트랙의 집합은 하나의 실린더를 형성한다.  
    - 임의 접근 시간이라고도 하는 위치 잡기 시간은 원하는 실린더로 디스크 암이 움직이는 탐색시간과 원하는 섹터가 디스크 헤드로 회전하는 데 필요한 시간인 회전 지연(Rotational Latency)로 구성된다.  
    - 디스크 헤드는 아주 얇은 공기 쿠션으로 떠 있기 때문에 디스크 표면에 헤드가 접촉할 위험이 있다. 헤드가 자기 표면을 손상시키는 사고를 헤드 크래시라고 한다.  
    헤드 크래시는 수리할 수 없으며 전체 디스크를 반드시 교체해야 한다.  
    - 다양한 측정방식 때문에 공개되는 디스크 성능 수치는 실제 성능 수치와 다르다. 공개된 전송률은 유효 전송률보다 항당 낮다.  
    공개된 전송률은 디스크 헤드가 자기 매체로부터 읽어 들이는 비트들의 단위 시간 당 비율일 것이다. 그러나 이것은 운영체제에 전달되는 블록들의 비율과는 다르다.  
    - 디스크는 플래터를 빼내어 이동 가능하게 만들 수도 있다. 플로피 디스크는 가격이 가장 저렴한 이동 가능한 자기 디스크이다.  
    - 디스크 드라이브는 입출력 버스(I/O Bus)라고 하는 회선들의 집합에 의해 컴퓨터에 부착되어 있다. EIDE, ATA, SATA, USB, FC, SCSI 버스를 포함해 여러 종류의 버스가 이용 가능하다.  
    - 버스 상에서 데이터 전송은 제어기(Controller)라고 하는 특별한 전자 처리기에 의해 실행된다. 호스트 제어기는 버스의 컴퓨터 쪽 끝에 있다.  
    - 자기 테이브가 상대적으로 영구적이고 많은 양의 데이터를 저장할 수 있지만 주 메모리 및 자기 디스크와 비교해보았을 때 접근 시간이 느리다. 자기디스크 대비 약 1000배 느리다.  
    - 현대의 디스크들은 크기가 일정한 논리 블록들의 일차원 배열처럼 취급된다. 논리 블록은 정보를 전송하는 최소 단위이다. 논리 블록은 보통 512B 이지만 몇몇 디스크는 저수준 포맷을 통해 1,024B 와 같은 블록 크기를 가질 수도 있다.  
    - 논리 블록들의 일차원 배열은 순차적으로 디스크 섹터로 맵핑된다. 섹터 0은 가장 첫 번째 실린더의 첫 번째 트랙의 첫 번째 섹터가 된다.  
    그 다음 순서가 되는 블록들은 차례대로 트랙을 차지하고, 실린더의 나머지 트랙을 거친 후 차츰 안쪽 실린더로 진행된다.  
    - 대부분의 디스크에 존재하는 손상된 섹터로 인해 이러한 주소 변환이 어려운데, 맵핑이 다른 위치의 여분의 섹터로 대체함으로써 이 사실을 숨긴다.  
    - 일부 디스크는 트랙 당 섹터의 수가 일정하지 않다.  
    고정 선형 속도(CLV, Constant Linear Velocity)를 이용하는 장치에서는 트랙 당 비트의 밀도가 일정하지 않다. 트랙이 디스크 중심으로부터 멀어질수록 트랙은 길이가 길어져 더 많은 섹터를 가질 수 있게 된다.  
    따라서 현대의 디스크는 실린더들을 몇 개의 구역으로 나눈다. 한 구역 안에서의 트랙 당 섹터 수는 일정하지만 구역 간에 차이가 난다.  
    드라이브는 헤드가 바깥쪽에서 안쪽 트랙으로 이동하면서 헤드 아래를 통과하는 데이터 율을 동일하게 유지하기 위해 회전 속도를 늘린다.  
    - 이와 반대로 디스크 회전 속도를 동일하게 유지하고 바깥쪽 트랙으로 갈수록 비트의 밀도를 줄여 데이터 율을 일정하게 유지할 수 있다. 이 방법은 하드디스크에 사용되며 고정각속도(CAV, Constant Angular Velocity)라고 한다.  
    - 컴퓨터는 I/O포트 또는 분산 파일 시스템 내의 원격 호스트를 이용하여 디스크 저장 장치에 접근한다.  
    - SCSI는 버스 아키텍처이다. SCSI의 물리적 매체는 보통 많은 수의 컨덕터를 갖는 리본 케이블을 사용한다.  
    - FC는 높은 속도를 지원하는 직렬 아키텍쳐이다. 이 아키텍쳐는 광섬유 또는 4개의 컨덕터를 갖는 동축케이블을 사용한다.  
    - 네트워크에 부착된 저장장치(NAS)는 데이터 네트워크를 통해 원격으로 접근되는 전용 저장장치이다.  
    - 네트워크에 부착된 저장 시스템의 단점 중 하나가 저장장치의 입출력 연산 시 데이터 네트워크의 대역폭을 소비하는 점이고, 이로 인해 네트워크 통신의 지연을 증가시키는 것이다.  
    - 서버와 클라이언트 통신이 서버와 저장장치틀 간의 통신과 대역폭을 놓고 경쟁하게 된다.  
    SAN(Storage Area Network)는 그림과 같이 서버들과 저장장치 유닛들을 연결하는 사유 네트워크이다.  
    - 디스크 접근 시간은 탐색시간과 회전 지연으로 이루어진다. 디스크 대역폭은 단위 시간 당 전송되는 총 바이트 수이다.  
    - 효율적인 스케쥴링은 접근 시간과 대역폭을 모두 향상시킬 수 있다.  
    - 선입 선처리 스케쥴링(FCFS Scheduling)은 요청이 들어온 순서대로 처리하는 방법이다. 탐색 시간이 오래 걸려 느리다.  
    - 최소 탐색시간 우선 스케쥴링(SSTF Scheduling)은 현재 위치로부터 가장 가까운 위치를 대상으로 하는 요청을 선택한다.  
    최소 탐색시간 우선 알고리즘은 CPU 스케쥴링에서의 최소 작업 우선 스케쥴링과 유사하다. 그러나 여기서는 몇 개의 디스크 요청들이 매우 오래 기다리게 되는 기아(Stravation) 상태가 발생할 수 있다.  
    - SCAN 알고리즘에서는 디스크 암이 디스크 한 끝에서 시작하여 다른 끝으로 이동하며 가는 길에 있는 요청을 모두 처리한다.  
    엘리베이터의 동작과 유사하다고 하여 엘리베이터 알고리즘이라고도 불린다.  
    - C-SCAN(Circular SCAN) 스케쥴링은 SCAN 스케쥴링과 유사하나 한쪽 끝에 다다르면 시작점으로 돌아와 다시 반대쪽으로 읽어나간다는 것이 다르다.  
    - LOCK 스케쥴링은 SCAN 스케쥴링의 변형으로 한쪽 방향으로 읽어나가다가 더 이상 그 쪽에 대기 중인 요청이 없다면 반대 방향으로 선회하는 것이다. C-LOCK도 C-SCAN에서 이를 적용한 것이다.  
    - 성능에 있어 디렉터리와 색인 블록의 위치 또한 중요하다. 모든 파일은 일단 열려야 사용할 수 있으므로 색인 블록과 디렉터리가 빈번히 요청될 것이므로 디렉터리가 중간 정도 실린더에 있다면 좋을 것이다.  
    - 스케쥴링은 탐색 시간만을 고려하였는데, 이는 운영체제가 회전 지연을 고려하기 어렵기 때문이다.  
    - 새로운 디스크는 아무런 정보도 없는 비어있는 판이다. 정보 저장을 위해 섹터를 나눠야 하며 이 과정을 저수준 포맷팅 또는 물리적 포맷팅이라고 한다.  
    - 대부분의 하드 디스크는 공장에서 이미 저수준 포맷팅 되어 나온다.  
    - 디스크에 파일을 저장하기 전에 운영체제는 디스크에 운영체제의 자료구조를 기록할 필요가 있으며, 이것은 두 단계로 나뉘어진다.  
    첫 번째 단계는 파티션을 나누튼 것이다. 두 번째 단계는 논리적 포맷팅, 즉 파일 시스템을 만드는 것이다.  
    - 효율성을 위해 대부분의 파일 시스템들은 블록들을 클러스터라고 하는 큰 묶음으로 그룹화한다.  
    디스크 I/O는 블록 단위로 실행되나 파일 시스템의 I/O는 클러스터 단위로 실행된다.  
    입출력은 순차 접근(Sequential Access)를 많이 하고 무작위 접근을 적게하는 특성을 보이기 때문이다.  
    - 전원을 키거나 재부팅할 때 시스템을 시작시키는 프로그램이 필요하며 이러한 최초의 부트스트랩 프로그램은 비교적 단순하다.  
    부트스트랩은 여러 하드웨어를 초기화한다. 그 다음 운영체제가 어디에 저장되어 있는지 알아내고 그것을 메모리에 올려놓고 시작시킨다.  
    - 대부분 ROM 안에 부트스트랩 프로그램을 저장한다. 한 가지 문제점은 ROM에 덮어쓰기를 할 수 없으므로 ROM에는 부트스트랩 프로그램 본체를 디스크로부터 적재하는 일만 하는 아주 작은 부트스트랩 로더 프로그램만 저장한다.  
    - 부트 파티션을 갖고 있는 디스크는 부트 디스크 또는 시스템 디스크라고 한다.  
    - 손상된 블록들은 디스크와 제어기에 따라 다양한 방법으로 처리할 수 있다.  
    - MS-DOS 포맷 명령은 논리적 포맷을 하는데, 만약 포맷 중 손상된 블록을 발견하면 그 블록을 더 이상 사용하지 못하도록 FAT 테이블에 표시해둔다.  
    - SCSI디스크는 손상된 디스크 블록 리스트를 유지한다. 리스트는 갱신되며, 저수준 포맷팅은 운영체제에게 보이지 않는 예비 섹터를 남겨 놓는다.  
    제어기는 이러한 에비 섹터를 손상된 섹터와 교체시킨다. 섹터 옮기기(Forwarding) 또는 섹터 남기기(Sparing)으로 알려져 있다.  
    - 예비 섹터를 관리하는 다른 방안으로 일부 제어기는 섹터 밀어내기(Sector Slipping)에 의해 손상된 섹터를 처리할 수 있도록 한다.  
    - 스왑 공간 관리는 운영체제가 실행해야 하는 하위 수준의 작업니다.  
    - 스왑 공간은 Anonymous 메모리 페이지들을 위한 공간으로서의 역할만 한다.  
    - 시스템이 많은 수의 디스크를 갖고 있고, 병렬적으로 운영된다면 데이터 쓰기와 읽기 비율을 향상시킬 수 있따.  
    RAID(Redundant Array of Inexpensive Disk)라 불리는 다양한 디스크 구성 기술은 일반적으로 성능과 신뢰성을 해결하는 데에 역점을 두고 있다.  
    - 신뢰성 문제를 해결하는 방법은 중복을 허용하는 것이다. 디스크 고장이 발생했을 경우 분실된 정보를 재구축하기 위해 이 정보를 사용한다.  
    중복을 도입하는 가장 간단한 방법은 모든 디스크에 복사본을 만드는 것이다. 이를 미러링(Mirroring)이라고 한다.  
    미러드 볼륨의 고장 평균시간은 단일 디스크의 고장 평균 시간과 손상된 디스크를 교체하고 다시 데이터를 저장하는 데 소요되는 평균 수리 시간에 영향을 받는다.  
    그러나 디스크 고장이 독립적이지 않다는 것을 인지해야 한다.  
    두 블록이 완전히 쓰이기 전에 전원 고장이 발생한다면 두 블록은 일관적이지 않은 상태가 된다. 이에 대한 첫 번째 해결책은 첫 번째 디스크에 먼저 작업을 마치고 두 번째 디스크에 작업을 하는 것이다.  
    다른 방법은 비휘발성 메모리(NVRAM, Nonvolatile RAM) 캐시를 RAID 배열에 두는 것이다.  
    - RAID 에서 데이터 스트라이핑(Data striping)을 사용하여 전송 비율을 향상시킬 수 있다. 가장 간단한 형식으로 데이터 스트라이핑은 여러 디스크에 각 바이트의 비트를 나누 저장함으로써 구현된다.  
    이러한 스트라이핑을 비트 레벨 스트라이핑이라고 한다.  
    - 미러링은 높은 신뢰성을 제공하지만 비용이 크다. 스트라이핑은 높은 전송률을 제공하지만 신뢰성을 향상시킬 수 없다. 패리티(Parity) 비트와 디스크 스트라이핑을 결합하여 적은 비용으로 중복을 허용하는 많은 기법이 제안되었다.  
    RAID Level 0 은 블록 레벨로 스트라이핑 하는 디스크 구성을 말하며, 미러링이나 패리티 비트 같은 어떤 중복 정보도 갖고 있지 않은 것을 말한다.  
    RAID Level 1 은 디스크 미러링을 사용한다.  
    RAID Level 2 은 메모리 스타일 오류 정정 코드 구조(Memory Style Error-Correcting-Code(ECC) Organization)으로 알려져 있는데, 패리티 비트를 활용한다.  
    RAID Level 3 는 bit-interleaved parity organization 이라 불리며, 메모리 시스템과 달리 한 섹터가 정확히 읽혔는지를 디스크 컨트롤러가 탐지할 수 있다는 사실을 이용하여 Level 2 기능을 향상시킨 것이다.  
    RAID Level 4 는 bit-interleaved parity organization 이라 불리며, RAID 0 처럼 블록 단위 스트라이핑을 사용한다. 각 액세스 전송률은 낮지만 병렬로 실행되므로 높은 입출력을 제공한다.  
    RAID Level 5 는 block-interleaved distributed parity 라고 불리며, 데이터와 패리티틀 모든 디스크에 분산시킨다.  
    RAID Level 6 는 P + Q 중복 기법이라고 불리기도 하는데, RAID 5 와 유사하지만 여러 디스크 오류에 대비하기 위해 추가 중복 정보를 저장한다. 패리티 비트를 사용하는 대신 Read-Solomon Codes와 같은 에러 교정 코드가 사용된다.  
    RAID Level 0 + 1 과 1 + 0: RAID 0 + 1 은 RAID 0 과 RAID 1 을 조합합 것이다. 
    - RAID는 커널 혹은 시스템 소프트웨어 계층 내에서 볼륨 관리 소프트웨어로써 구현될 수 있고, 이 경우 패리티 RAID는 느리므로 RAID 0 + 1 또는 1 + 0 이 사용된다.  
    - RAID는 HBA(Host Bus Adapter) 하드웨어에 의해 구현될 수 있다. 이 방법은 비용이 적게 들지만 융통성이 없다.  
    - RAID는 저장 장치 배열 하드웨어에 의해 구현될 수 있다.  
    - RAID 는 디스크의 가상 디바이스들을 통해 SAN 의 내부연결 계층에 구현될 수 있다.  
    - RAID는 운영체제나 사용자에게 데이터가 가용하다는 것을 항상 보장하지는 않는다. RAID는 물리적 매체의 오류는 보호하지만 다른 하드웨어나 소프트웨어 버그는 보호하지 못한다.  
    - RAID 구현과 연관된 또 다른 이슈는 유연성 부족이다.  
    - 안정적인 저장장치라 함은 저장된 후 정보 손실이 절대 없는 저장 장치라는 뜻이다. 이를 위해 각자 독립적으로 고장 나는 여러 대의 저장장치에 복사본을 만들어 두어야 한다.  
    또한 갱신 작업을 새로 설계하여 저장 장치를 갱신하는 동안에 고장이 발생하더라도 모든 복사본이 손상되는 일이 없어야 한다. 회복할 때는 모든 복사본 값이 일관성 있어야 하고 올바른 값이어야 한다.  
    - 3차 저장장치의 주요 특성 중 하나는 가격이 저렴하다는 것이다. 또한 플로피디스크, CD, USB 등 이동식 매체로 만들어진다.  
    - 3차 저장장치 속도는 대역폭과 지연의 두 가지 측면이 있다. 대역폭은 초당 전송되는 바이트 수로 측정한다. 지속 대역폭은 대단위 전송 동안 평균 데이터 율을 말한다.  
    유효 대역폭은 seek() 와 locate() 연산 실행 시간을 포함하는 I/O시간과 주크박스 내의 카트리지 교체 시간 등 전체 시간의 평균을 계산한 것이다.  
    속도를 결정하는 두 번째 측면은 접근 지연이다.  

#### 13장) 입출력 시스템
    - 하드웨어 장치는 포트라 불리는 연결점을 통해 컴퓨터와 접속된다.  
    - 하나 이상의 장치들이 공동으로 여러 선을 사용한다면 이러한 선을 버스라고 부른다. 버스의 정의는 어떻게 메세지를 주고 받을지 정한 프로토콜까지 포함한다.  
    - A 가 B 에 연결되고, B 가 C 에 연결되고, C 가 컴퓨터 포트에 연결되어 있다면 이를 데이지 체인(Daisy Chain)이라고 한다.  
    - 프로세서-메모리 서브시스템을 고속 장치에 연결하는 PCI 버스와 키보드, USB 포트처럼 상대적으로 느린 장치들을 연결하는 확장 버스가 존재한다.  
    - 컴퓨터의 주요 부품을 연결하는 데 사용되는 다른 일반적인 버스에는 최대 4.3GB 처리량의 PCI-X, 최대 16GB 처리량의 PCI Express(PCIe), 최대 20GB 처리량의 HyperTransport 등이 있다.  
    - 제어기는 포트나 버스나 입출력 장치를 제어하는 전자 회로의 집합체이다.  
    - SCSI 버스 제어기처럼 복잡한 일을 처리하는 제어기의 경우 비교적 큰 보드 모양으로 나오기도 한다.  
    - 어떤 입출력 장치는 제어기를 내장하고 있다. 예를 들어 디스크 안에 전자회로 보드가 있는데 이것이 디스크 제어기이다.  
    - 모든 제어기는 레지스터를 갖고 있다. 본체의 프로세서는 이들 제어기의 레지스터에 비트 패턴을 쓰거나 읽음으로써 입출력을 수행한다.  
    이러한 통신을 수행하는 한 방법은 특별한 입출력 명령어를 사용하여 어떤 입출력 포트로 전달하도록 지정하는 것이다.  
    다른 방법은 장치 제어 레지스터를 프로세서의 주소 공간으로 맵핑한다. 이러한 방식이 메모리 사상 입출력 방식이다. 각 주변장치 레지스터는 메모리 주소와 일대일 대응한다.  
    - PC는 일부 장치를 제어하기 위해 입출력 명령을 사용하고, 다른 장치를 제어하기 위해 메모리 사상 I/O 를 하기도 한다.  
    - 입출력 포트는 보통 상태(status), 제어(control), 입력(data-in) 과 출력(data-out) 의 네 개의 레지스터로 구성된다.  
    입력 레지스터는 호스트가 입력을 얻기 위해 읽기를 실행한다.  
    출력 레지스터는 호스트가 데이터를 출력하기 위해 쓰기를 실행한다.  
    상태 레지스터는 호스트가 읽는 용도이며, 현재 명령이 완료되었는지, 읽어도 되는지 등 상태를 보고한다.  
    제어 레지스터는 호스트가 입출력 명령을 내리거나 장치의 모드를 변경하기 위해서 쓰기를 실행하는 대상이다.  
    - 호스트와 입출력 장치는 바쁜 대기, 즉 폴링을 할 수 있다.  
    - CPU 하드웨어는 인터럽트 요청 라인이라고 불리는 선을 하나 갖는데, CPU는 매 명령어를 끝내고 다음 명령어를 실행하기 전에 늘 이 선을 검사한다. 만약 신호를 보내면 인터럽트 핸들러 루틴으로 이동한다.  
    현대 운영체제에서는 임계 영역을 실행하는 동안 인터럽트 처리를 연기하는 능력이 필요하며,  
    어떤 장치가 인터럽트를 일으켰는지 조사하기 위해 적절한 인터럽트 핸들러롤 이동하는 효율적인 방법과,  
    높은 우선순위와 낮은 우선순위 인터럽트를 구별하여 긴급한 정도에 따라 우선적으로 응답하기 위해 다수준 인터럽트가 필요하다.  
    현대 컴퓨터는 이들 세 가지 요소들을 CPU와 인터럽트 제어기 하드웨어를 통하여 제공하고 있다.  
    - 대부분 CPU는 두 종류의 인터럽트 요청 라인을 갖는다.  
    하나는 회복 불가능한 메모리 에러와 같은 이벤트를 처리하기 위한 마스크 불가 인터럽트이다. 다른 하나는 마스크 가능 인터럽트이다.  
    - 인터럽트 기법은 보통 주소라고 하는 하나의 정수를 받아들이는데, 이 정수는 특정 인터럽트 핸들러 루틴을 선택하기 위해 사용된다.  
    대부분의 아키텍쳐에서 이 주소는 인터럽트 벡터라고 하는 테이블의 오프셋으로 사용된다. 그러나 컴퓨터는 인터럽트 벡터 내에 있는 주소들보다 더 많은 수의 장치를 갖고 있다.  
    이러한 문제를 해결하기 위해 인터럽트 사슬화(Chaining) 기술을 사용한다.  
    또한 인터럽트 매커니즘은 인터럽트 우선순위 수준의 구현을 가능하게 한다.  
    - 인터럽트는 비동기적으로 일어나는 사건을 처리하고 커널 내의 수퍼바이저 루틴으로 트랩하기 위한 방도로 사용된다.  
    - 디스크와 같은 많은 데이터를 입출력하는 장치를 위해 비싼 범용 프로세서가 매번 바이트 전송을 제어하게 하는 것은 낭비이다.  
    CPU가 상태 비트를 반복적으로 검사하면서 1바이트씩 옮기는 입출력 방식을 PIO(Programming I/O) 라고 한다.  
    많은 컴퓨터가 CPU의 PIO 작업 중 일부를 DMA 제어기라고 불리는 특수 프로세서에 위임함으로써 CPU의 일을 줄여준다.  
    DMA는 CPU의 도움 없이 자신이 직접 버스를 통해 DMA 명령 블록을 액세스하여 입출력을 실행한다.  
    DMA 제어기와 장치 제어기 간의 핸드셰이킹은 DMA-request 와 DMA-acknowlenge 라고 불리는 두 개의 선을 통해 실행된다.  
    전송이 끝나면 DMA 제어기는 CPU에게 인터럽트를 건다.  
    DMA가 메모리 버스를 점유 중이면 비록 CPU는 주캐시와 보조캐시에 있는 데이터는 접근할 수 있지만 주 메모리에 있는 데이터는 접근하지 못한다.  
    이러한 사이클 스틸링(Cycle stealing)은 CPU 속도를 저하시키지만 입출력 작업을 DMA로 넘기는 것은 전체적으로 시스템 성능을 향상시킨다.  
    어떤 컴퓨터는 DMA 를 할 때 물리 주소를 사용하지만 다른 컴퓨터는 직접 가상 주소 접근(DVMA, Direct Virtual Memory Access) 를 사용하기도 한다.  
    문자 스트림 장치는 바이트를 하나씩 전송하지만 블록 장치는 블록 단위로 전송한다.  
    동기식 장치는 일정한 응답 시간을 갖지만 비동기식 장치는 응답 시간이 예측 불가능하다.  
    공유 가능한 장치는 몇 개의 프로세스나 스레드에 의해 동시에 사용될 수 있으나 전용 장치는 하나의 프로세스만 사용할 수 있다.  
    입출력 장치마다 동작 속도가 나뉜다.  
    어떤 장치는 읽기/쓰기를 모두 허용하지만 다른 장치는 둘 중 하나만 허용한다.  
    - 블록 장치 인터페이스는 디스크나 이와 유사한 블록 지향 장치를 사용하기 위해 필요한 모든 요소를 제공하고 있다.  
    일반적으로 읽기, 쓰기와 탐색 명령을 제공한다.  
    - 키보드는 문자 스트림 인터페이스를 통해 접근되는 장치의 예이아. 이러한 인터페이스의 시스템 호출은 응용프로그램에게 한 글자씩을 보내거나 받아 오는 명령을 제공한다.  
    이러한 인터페이스는 키보드나 마우스, 모뎀과 같은 장치에 적하하다. 이러한 장치들은 공통적으로 언제 어떠한 데이터가 입력될지 사전에 예측하는 것이 불가능하다.  
    - UNIX나 Windows NT를 포함한 많은 운영체제에서 사용하는 인터페이스는 네트워크 소켓(Socket) 인터페이스이다.  
    소켓 인터페이스에서의 시스템 호출은 응용 프로그램으로 하여금 소켓을 생성하고, 로컬 소켓을 원격 주소와 연결해준다.  
    연결이 되었으면 패킷을 주고받도록 한다. select()를 호출하면 어느 소켓들이 수신 대기 중인 패킷을 갖고 있는지, 어느 소켓들이 전송될 패킷을 더 받아들일 여유 공간을 갖고 있는지에 대한 정보를 반환해 준다.  
    따라서 select()를 사용하면 풀링(바쁜 대기)할 필요가 없어진다.  
    - 경과한 시간을 재고 특정 오퍼레이션을 실행시키는 하드웨어를 프로그램 가능 인터벌 타이머라고 한다.  
    많은 컴퓨터에서 하드웨어 클록의 틱에 의해 생성되는 인터럽트율은 초당 18에서 60틱 사이이다. 이 정도의 정밀도는 현대 컴퓨터가 초당 수천만 개의 명령어를 처리할 수 있는 것에 비해서는 비교적 낮은 것이다.  
    - 비봉쇄형 시스템 호출의 대안으로 비동기식 시스템 호출이 있다. 비봉쇄형 읽기의 경우 그 시점에 갖고 올 수 있는 데이터를 갖고 즉각 복귀한다.  
    반면 비동기식 읽기 시스템 호출은 입력이 완전히 끝난 후 완전한 데이터를 전송해 줄 것을 요청한다. 비봉쇄형의 좋은 예가 네트워크 소켓의 select() 시스템 호출이다.  
    - 운영체제 개발자들은 각각의 장치마다 대기 큐를 유지함으로써 스케쥴링을 구현하고 있다.  
    - 버퍼는 두 장치 사이 또는 장치와 응용 프로그램 사이에 데이터가 전송되는 동안 임시로 저장하는 데이터 영역을 말한다.  
    버퍼가 필요한 이유 첫 번째는 생산자와 소비자 사이에 속도가 다르기 때문이다. 두 번째는 데이터 전송 크기가 다른 장치들 사이의 완충을 제공할 때이다. 마지막으로 응용 프로그램의 복사 시맨틱을 지원하기 위함이다.  
    - 캐시는 자주 사용될 자료의 복사본을 저장하는 빠른 메모리 영역이다.  
    - 스풀은 인터리브하게 동작될 수 없는 프린터 같은 장치를 위해 출력 데이터를 보관하는 버퍼이다.  
    - 테이프나 프린터같은 몇몇 장치는 여러 응용 프로그램의 입출력 요구를 멀티플렉스 할 수 없다. 스풀링이 이를 조절할 수 있는 하나의 방법이다.  
    - 일반적으로 입출력 시스템 호출은 성공/실패를 나타내는 한 비트 정보를 반환한다. UNIX 운영체제는 반환값 외에도 errno 라고 부르는 변수를 사용한다.  
    몇몇 하드웨어는 보다 자세한 에러 정보를 제공한다. 그러나 이런 상세 정보는 응용 프로그램까지 전달되지 않는다.  
    예를 들어 SCSI 장치에 문제가 생기면 프로토콜에 의해 sense key 형태로 보고되지만, 이왜에서 추가적인 sense code 와 더욱 자세한 정보를 위해 sense code qualifier 가 존재한다.  
    - 모든 입출력 명령은 특권 명령으로 정의한다. 사용자가 직접 호출할 수 없고 운영체제가 입출력을 대신 실행하도록 시스템 호출을 실행한다.  
    - 봉쇄형 읽기 요청을 처리하는 전체 윤곽은 다음과 같다.  
    1) 한 프로세스가 열린 파일의 파일 디스크럽터에거 봉쇄형 read() 시스템 호출을 요청한다.  
    2) 커널 안에 있는 시스템 호출 코드는 인자를 검사한다. 버퍼 캐시에 들어있다면 자료를 반환하고 입출력 요구는 끝난다.  
    3) 버퍼에 존재하지 않는다면 물리적인 입출력이 필요하다. 실행 큐에서 장치 대기 큐로 옯겨지고 입출력 요청이 스케쥴링 된다.  
    4) 장치 구동기는 입출력 자료를 위해 커널 버퍼를 확보하고 입출력을 스케줄한다. 장치 구동기는 장치 제어기의 제어 레지스터에 명령을 써보낸다.  
    5) 장치 제어기가 장치를 작동하여 데이터가 입력된다.  
    6) DMA 제어기는 전송이 완료되면 인터럽트를 발생시킨다.  
    7) 인터럽트 벡터 테이블을 통해 해당 인터럽트 핸들러가 인터럽트를 받고 장치 구동기에 신호를 보내며 인터럽트로부터 되돌아온다.  
    8) 신호를 받은 장치 구동기는 어떤 입출력이 완료되었는지 확인하고, 커널 입출력 서브시스템에게 그 요구가 완료되었음을 알려준다.  
    9) 커널은 자신의 버퍼로부터 요구된 프로세스의 버퍼로 데이터를 옮기고 그 프로세스를 봉쇄 큐에서 준비완료 큐로 옮긴다.  
    10) 준비완료 큐로 보내진 작업은 준비완료 상태로 변하여 언젠가 스케줄러가 해당 작업을 스케쥴할 것이다.  
    - 인터럽트 처리는 부담이 많이 되는 작업니다. 바쁜 대기에서 낭비되는 사이클이 적다면 프로그램 I/O가 인터럽트보다 더 효율적일 수 있다.  
    
#### 14장) 보호
    - 현대의 보호 개념은 자원을 공유하는 복잡한 시스템의 신뢰성을 증가시키기 위해 발전되어 왔다.  
    - 보호 지향 시스템은 인가된 사용자와 그렇지 않은 사용자를 구별할 수 있는 수단을 제공한다.  
    - 컴퓨터 시스템에서 보호의 역할은 자원 사용을 지배하는 정책을 시행하기 위한 기법을 제공하는 것이다.  
    - 중요한 원칙 중 하나는 기법과 정책을 분리하는 것이다.  
    - 보호의 원칙에는 최소 권한의 원칙이 있다. 최소 권한의 원칙은 프로그램, 사용자, 심지어 태스크를 실행하는데 필요한 만큼의 권한을 부여하는 법칙이다.  
    - 최소 권한의 원칙을 따르는 운영체제는 실패나 손상된 구성요소가 최소한의 피해만 입히거나 허락하도록 구조, 프로그램, 시스템 호출 및 자료구조를 구현해야 한다.  
    - 모든 특권적인 함수 접근에 대해 감사 기록(audit trail)을 생성한다. 프로그래머나 시스템 관리자 또는 법 집행기관은 감사 기록을 이용하여 시스템의 모든 보호와 보안 활동을 추적할 수 있다.  
    - 어떤 시스템은 역할 기반 접근 제어(RBAC, Role Based Access Control)을 구현하였다.  
    - 어느 때든 프로세스는 자신의 일을 완료하기 위하여 현재 필요로 하는 자원들만을 접근할 수 있어야 한다. 이러한 요구를 통상 need-to-know 원칙이라 부르며, 피해의 양을 제한하는 데에 유용하다.  
    - 프로세스는 하나의 보호 영역 내에서 동작하낟.  
    - 객체에 대한 연산을 실행할 수 있는 권한을 접근 권한(Access Right)라고 한다.  
    - 만일 프로세스와 영영 간의 연관이 동적이라면 프로세스로 하여금 한 영역에서 다른 영역으로 전환하게 하는 기법(Domain Switching)이 존재한다.    
    - 영역은 각 사용자가 하나의 영역이 될 수 있으며, 또는 각 프로세스가 하나의 영역이 될 수 있다. 또한 각 프로시져가 하나의 영역이 될 수 있다.  
    - 영역을 전환하는 것은 사용자의 신원을 일시적으로 변경하는 것과 같다.  
    - 보호 모델은 추상적으로 접근 행렬이라 불리는 하나의 행렬로 볼 수 있다.  
    영역 D_i 내에서 실행되는 프로세스는 i행에 지정된 객체들만을 접근 행렬의 항에 의해 허용된 대로만 접근할 수 있음을 보장해야 한다.  
    프로세스는 하나의 영역으로부터 다른 영역으로 전환될 수 있어야 한다. D_i 로부터 영역 D_j 로의 영역 전환은 접근 권한 전환이 access(i, j) 에 포함되어 있을 때만 허용한다.  
    - 일반적으로 접근 행렬은 희소 행렬, 즉 항의 대부분이 공백인 행렬이다.  
    - 접근 행렬을 구현하기 위한 방법으로 전역 테이블, 객체를 위한 접근 리스트, 영역을 위한 자격 리스트, 락-키 기법이 있다.  
    전역 테이블은 영역, 객체, 권한 집합의 세 부분으로 이루어진 가장 단순한 테이블이다. 테이블이 매우 크기 때문에 주 메모리에 보관할 수 없으며 따라서 추가적인 입출력을 필요로 한다. 가상 메모리 기법이 종종 사용된다.  
    객체를 위한 접근 리스트는 객체 별로 영역, 권한 집합의 순서쌍의 리스트를 생성한다.  
    영역을 위한 자격 리스트는 객체, 권한 집합의 순서쌍의 리스트를 생성한다. 자격 리스트는 영역과 연관되어 있으나 그 영역에서 실행 중인 프로세스가 직접 접근할 수는 없다.  
    락-키 기법은 접근 리스트와 자격 리스트의 절충안이다.  
    - 접근 리스트는 사용자의 요구에 직접 해당된다. 그러나 각 영역에 대한 접근 권한 집합을 결정하기 어렵다.  
    - 자격 리스트는 사용자의 요구에 해당하지 않는다. 그러나 어느 특정 프로세스에 대한 정보를 국지화하는 데 유용하다.  
    - 락-키 기법은 앞의 두 기법의 절충안이다.  
    - 대부분의 시스템은 접근 리스트와 자격의 조합을 사용한다. 프로세스가 객체를 처음 접근하려고 시도할 때 접근 리스트가 탐색된다. 만약 접근이 거부되면 예외 상황이 발생하고 그렇지 않으면 자격이 생성되어 프로세스에 부착된다.  
    - 접근 권한 취소에 대하여 다음과 같은 여러 질문이 발생할 수 있다.  
    즉시 대 지연: 취소가 즉시 발생될 것인가 지연될 것인가, 만일 지연된다면 언제 취소될지 알 수 있는가?  
    선택적 대 일반적: 객체에 대한 접근 권한이 취소될 때 그 객체에 대한 접근 권한을 갖고 있는 모든 사용자에게 영향을 미칠 것인가? 또는 사용자를 지정할 수 있는가?  
    부분적 대 전체적: 객체에 연관된 권한의 일부분을 취소할 수 있는가?  
    일시적 대 영구적: 접근이 영구적으로 취소될 수 있는가?  
    접근 리스트 기법에서 취소는 쉽다. 취소할 접근 권한을 탐색하여 리스트에서 제거한다.  
    그러나 자격은 훨씬 더 어려운 취소 문제를 제시한다. 자격은 시스템 전체에 걸쳐 분포되어 있으므로 자격을 취소하려면 먼저 그것을 찾아야 한다.  
    - 권한에 대한 취소를 구현하기 위한 기법에는 아래의 기법을 포함하여 다수의 다른 기법이 있다.  
    - 재획득(Reacquisition): 주기적으로 자격들이 각 영역에서 제거된다.  
    - 후방포인터(back-pointer): 각 객체마다 연관된 모든 자격을 가리키는 포인터 리스트를 유지한다.  
    - 간접(Indirection): 각 자격은 전역 테이블의 유일한 항을 가리키며 그 항은 다시 객체를 가리킨다. 취소는 전역 테이블을 탐색하여 원하는 항을 찾아 제거함으로써 구현된다.  
    - 키(Keys): 키는 각 자격에 연관될 수 있는 유일한 비트 패턴이다. 자격이 만들어질 때 정의되며, 자격을 소유한 프로세스에 의하여 변경되거나 검사될 수 없다.  
    - 프로그래밍 언어에 의한 보호 명세는 자원의 할당과 이용에 대한 정책을 높은 수준에서 기술할 수 있게 한다.  
    

#### 15장) 보안
    - 보안이란 시스템과 자료의 무결성이 유지될 확신의 척도를 말한다. 보호보다 훨씬 광범위한 개념이다.  
    
#### 16장) 분산 운영체제
#### 17장) 분산 파일 시스템
#### 18장) 분산 동기화
#### 19장) 실시간 시스템
#### 20장) 멀티미디어 시스템
#### 21장) Linux 시스템
#### 22장) 윈도우즈 XP
#### 23장) 영향력 있는 운영체제
