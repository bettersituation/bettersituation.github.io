---
layout: post
topic: computer-science
title: 운영체제
---

이전 책을 읽으면서 우리가 프로그래밍 하는 모든 것은 운영체제 위에서 실행됨을 알게 되었다.  
그래서 운영체제에 대해 보다 더 알고 싶은 마음이 생겨 운영체제를 다루는 책을 한 권 읽어보았다.  
내가 읽은 책은 Operating System Concepts 으로 소위 공룡책으로 알려진 유명한 책이다.  
읽었다고 하기도 민망할만큼 겉핥기 식으로 읽었지만 그래도 리뷰를 남겨본다.  
글은 목차 별로 나누어 작성한다.  


#### 1장) 서론
    - 운영체제를 바라보는 관점 및 구분과 기초적인 지식을 설명한다. 패스
    
#### 2장) 시스템 구조
    - 운영체제의 대표적인 서비스로 사용자 인터페이스, 프로그램 실행, 입출력 연산, 파일 시스템 조작, 통신, 오류탐지, 
    자원 할당, 자원 관리, 보호 및 보안 등이 있다.  
    - 운영체제를 설계할 때 가장 중요한 원칙 중 하나가 바로 메커니즘과 정책을 분리하는 것이다. 매커니즘은 범용적인 것이 선호된다.  
    - 운영체제는 주로 C/C++ 과 같은 고급언어로 작성되어 있는데, 자주 제기되던 단점은 속도가 느리다는 것이다. 
    그러나 컴퓨터 사양 향상으로 이는 더 이상 문제가 아니다.
    - 운영체제의 구조로는 간단한 구조, 계층적 구조, 마이크로 커널, 모듈 구조 등이 있다.  
    - 간단한 구조는 초기 OS 에서 많이 나타난다. 기능이 예상 범위보다 추가됨에 따라 품질이 저하되는 현상이 있다.  
    - 계층적 구조는 각 층이 직전 층의 API 만을 사용하여 구현된다. 
    어려운 점 중 하나는 각 층마다의 적절한 정의 및 추상화이며, 속도가 느릴 수 있는 단점이 있다.  
    - 마이크로 커널은 최소한의 동작만을 커널 모드로 수행하고, 그 외의 동작은 사용자 공간에서 수행하도록 하는 것이다.
    확장은 용이하지만 가중된 시스템 동작 때문에 오버헤드가 발생하여 성능이 감소한다.  
    - 모듈 구조는 Linux 및 Max OS X 등에서 사용하는 구조로 각 기능을 모듈화하여 구현한다.  
    - 가상기계의 기본적인 아이디어는 한 컴퓨터의 하드웨어를 추상화하여 다수의 다른 실행환경을 제공하는 것이다.  
    - 대표적인 가상기계로는 VMWare, JVM(Java Virtual Machine) 등이 있다.  
    - 커널 고장은 종종 충돌(Crash)라고 불리고, 충돌 덤프에 저장된다.  
    - 컴퓨터가 전원이 켜지면 명령 레지스터는 미리 지정된 메모리 위치를 가리킨다. 이 위치에 운영체제를 로드하기 위한
    매우 작은 부트스트랩 로더가 존재하고, 해당 로더가 실행되며 운영체제가 실행된다.  
    
#### 3장) 프로세스
    - 프로세스 상태는 new(생성 중), running, waiting, ready, terminated 로 나뉜다.
    ready 는 모든 준비가 되어 실행 준비 직전의 상태를 뜻하고 waiting 은 I/O 등에 의하여 대기하고 있는 상태를 뜻한다.
    - 각 프로세스는 PCB(Process Control Block) 에 의해 표현된다.
    PCB의 정보로는 프로세스 상태, 번호, 프로그램 카운터, open file 리스트, 스케쥴링 정보, 메모리 및 레지스터 관련 정보 등이 있다.
    프로세스 카운터는 프로세스가 다음에 실행할 명령어의 주소를 나타낸다.
    - 스레드란 프로세스 내에서의 태스크를 나눠 각각의 태스크가 동시에 수행할 수 있도록 하는 태스크의 개념이다.
    - 스케쥴러는 프로세스의 실행 순서를 결정하기 위해 필요하며 장기, 중기, 단기로 나뉜다. 대부분의 현대 OS 는 단기~중기 스케쥴러를 사용한다.  
    - 문맥 교환(Context Switching) 이란 현재 프로세스의 상태를 저장하고 다른 프로세스를 실행하는 것을 말한다.
    문맥 교환 시간 동안 CPU 는 아무 것도 하지 못하기 때문에 이는 순수한 오버헤드이며, 문맥 교환 시간은 하드웨어 자원에 크게 의존한다.  
    - 프로세스에 대한 대표적 연산으로 생성과 종료가 있다.
    - 프로세스 간 통신(IPC, Interprocess Communication) 를 구성하는 이유로는 정보 공유, 계산 가속화, 모듈성, 편의성 등이 있다.
    구현 방법으로 크게 공유 메모리 사용과 메시징 전달 방법이 있다.
    - 공유 메모리의 경우 유한 버퍼와 무한 버퍼 이슈가 있다. 유한 버퍼일 경우 생산자는 소비자가 소비할 때까지 생산하지 않는다.
    - 메시징 전달 방법은 간접/직접, 동기식/비동기식, 자동/명시적 버퍼링으로 나뉜다.
    - 간접 통신에서 메시지는 port 로 송신되어 소비된다. 
    - 동기식/비동기식은 봉쇄형/비봉쇄형이라고도 표현되며 메시지 송신 수신에 따라 동기식/비동기식으로 처리하는지에 대한 이슈이다.
    - 버퍼는 무용량(이 경우 수신자가 메시지를 수신할 때까지 기다려야 함), 유한 용량, 무한 용량으로 나뉜다.
    - IPC 기법을 활용하여 클라이언트-서버 시스템의 통신에도 사용할 수 있다. 통신 전략은 크게 소켓, RPC 및 파이프 통신으로 나뉜다.
    - 소켓 통신은 양측의 주소와 포트 번호를 필요로 한다. telnet, http, ftp 등 서비스를 구현하는 서버는 특정 포트로부터 메시지를 기다리고 있는 것이다.
    소켓은 다시 TCP(연결 기반 소켓)와 UDP(비연결성 소켓)으로 나뉜다.
    - RPC 는 네트워크에 연결되어 있는 두 시스템 사이의 통신에 사용하기 위하여 프로시저 호출을 추상화하기 위한 방편으로 설계되었다.
    - 대부분의 RPC 시스템은 기종 중립적인 데이터 표현 방식을 정의한다. 대표적인 예가 XDR(external data representation) 이다.
    - RPC를 사용하기 위해 포트 번호를 바인딩해야 하는데, 서버의 포트 번호를 확인하기 위하여 
    사전에 전송 포트를 미리 고정하거나 또는  
    미리 정의되어 있는 고정 RPC 포트를 사용해 서비스 사용 포트 정보를 전송하여 바인딩한다. 이를 랑데부용 디먼(Match Maker)라고 한다.
    - 파이프는 양방향/단방향, 반이중/전이중(양방향 동시 전송 가능 유무), 부모-자식 관계 등 필요 유무, 네트워크 통신 유무로 나뉜다.
    
#### 4장) 다중 스레드 프로그래밍
    - 다중 스레드의 장점으로 응답성, 자원 공유, 경제성, 규모 가변셩이 있다.
    - 다중 코어를 잘 활용하기 위하여 설계자는 작업 나누기, 부하의 균형, 데이터 분리, 데이터 종속성, 시험 및 디버깅에 대한 어려움을 극복해야 한다.
    - 사용자가 생성한 다중 스레드 모델은 커널과의 관계도 고려해야 한다. 다대일 모델, 일대일 모델, 다대다 모델이 있다.
    - 다대일 모델의 경우 다중 스레드를 해도 한 번에 하나의 스레드만 커널에 접근할 수 있기 때문에 병렬로 작동할 수 없다.
    - 일대일 모델은 사용자 스레드가 생성될 때마다 커널 스레드가 생성되어야 하므로 그 수가 커지면 오버헤드가 발생한다. 보통 시스템에 의해 지원 스레드 수가 제한된다.
    - 다대다 모델은 위 두가지 단점을 어느정도 해결했다.
    - 다중 스레드를 구현할 때 (1) Fork() 및 Exec() 시스템 호출 (2) 스레드 취소(비동기식/지연 취소) (3) 신호 처리  
    (4) 스레드 풀 (5) 스레드별 데이터 (6) 스케쥴러 액티베이션(다대다 모델 사용 시 사용자 스레드와 커널 스레드를 맵핑하는 방법) 등을 고려해야 한다.  
    - (6) 스케쥴러 액티베이션을 위해 LWP라 불리는 경량 자료구조가 필요하며, 커널이 응용에 특정 사건을 알려주는 것을 업콜이라고 한다.  
    
#### 5장) CPU 스케쥴링
    - CPU 스케쥴링의 목적은 CPU 이용률을 최대화 하는데에 있다.
    - 프로세스는 CPU-입츌력 버스트 사이클(CPU-I/O Burst Cycle) 로 구성되고, 일반적/통계적으로 CPU 버스트 소요 시간은 지수 분포를 따른다.  
    - 비선점 스케쥴링에서는 일단 CPU가 한 프로세스에 할당되면 프로세스가 종료/대기 상태로 전환될 때까지 CPU를 점유한다.
    - 선점 스케쥴링은 공유 자료에 접근하는 데에 비용을 유발한다. 예를 들어 A 가 자료를 수정하다 B가 실행되면 비일관적인 자료가 나타나는데 이를 해결할 방법이 필요하다.
    - 디스패처(Dispatcher) 는 CPU 제어를 단기 스케쥴러가 선택한 프로세스에 할당한는 모듈이다.
    - 디스패처(Dispatcher) 는 문맥 교환, 사용자 모드 전환, 프로세스 재개 시 특정 위치로 jump 하는 일 등을 한다.  
    - 스케쥴링 기준으로 CPU 이용률, 처리량(단위시간 당 완료 프로세스 개수), 총처리 시간, 대기시간, 응답시간 등이 있다.
    - CPU 스케쥴링으로 선입 선처리 스케쥴링(FCFS, Frist-Come First-Served) 이 쓰일 수 있다.
    모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양보하기 기다리는 것을 호위 효과(Convoy Effect) 라고 한다.  
    - CPU 스케쥴링으로 최단 작업 우선 스케쥴링(SJF, Shortest-Job Frist) 이 쓰일 수 있다.  
    이는 프로세스 전체 길이가 아니라 다음 CPU버스트가 가장 짧은 프로세스에 할당하는 방법이다.  
    실질적으로 CPU 요청 길이를 파악하는 것이 어렵다. 주로 장기 스케쥴링에 쓰인다.  
    단기 스케쥴링에서는 지수평균으로 다음 CPU 버스트 길이를 근사하여 사용한다.  
    - 우선순위 스케쥴링(Priority Scheduling) 은 범용적 스케쥴링으로, SJF 같은 경우 CPU 버스트에 따른 우선순위 스케쥴링이라고 할 수 있다.  
    우선순위 스케쥴링의 문제점은 새롭게 생성되는 프로세스의 우선순위가 기존 프로세스의 우선순위보다 높아 무기한 봉쇄, 다른 말로는 기아 상태에 빠질 수 있다는 점이다.    
    한 가지 해결 방법은 프로세스의 우선순의를 시간이 지남에 따라 점진적으로 높이는 방법이다.  
    - 라운드 로빈 스케쥴링(RR, Round Robin Scheduling) 은 원형 큐로 구현된 준비완료 큐를 돌면서 각 프로세스에 주어진 시간만큼만 CPU를 할당하는 것이다. 시간 할당량에 따라 성능이 좌우된다.  
    - 다단계 큐 스케쥴링(Multilevel Queue Scheduling) 은 준비완료 큐를 별도의 큐로 분류한다. 프로세스 특성에 따라 큐에 종속되며, 각 큐는 자신의 알로리즘에 따라 스케쥴링된다.   
    큐 사이의 스케쥴링은 일반적으로 고정 우선순위의 선점형 스케쥴링으로 구현된다.  
    - 다단계 피드백 큐 스케쥴링(Multilevel Feedback Queue Scheduling) 는 다단계 큐 스케쥴링과 유사하나 프로세스의 우선순위가 바뀔 수 있다는 점이 다르다. 각 프로세스의 CPU 버스트에 따라 큐 사이를 이동한다.
    - 멀티쓰레딩에서 다대다 모델, 다대일 모델을 사용할 경우 프로세스에 속한 사용자 스레드들 사이에서 경쟁이 발생한다. 이른 프로세스 경쟁 범위(Process Contention Scope) 라고 한다.  
    - CPU 상에서 어느 커널 스레드를 스케쥴할 것이지 결정하는 것은 시스템 경쟁 범위(System Contention Scope) 에서 발생하는 것이다.  
    - 다중처리기(Multi-Core 등) 에서 스케쥴링 할 때에 비대칭 다중처리, 대칭 다중처리 방법이 있다.
    - 비대칭 다중처리는 주 서버인 하나의 처리기가 스케쥴링 결정과 입출력 처리, 그리고 다른 시스템 활동을 처리하는 것이다. 구현이 간단하다.  
    - 대칭 다중처리(SMP, Symmetric multiprocessing) 는 공용 준비완료 큐와 사유 준비완료 큐를 갖고 각 처리기가 독자적으로 스케쥴링된다. 두 처리기가 같은 프로세스를 선택하지 않고 프로세스가 사라지지 않는다는 것을 보장해야 한다.  
    - 가장 최근에 접근된 데이터가 캐시를 채우게 된다. 따라서 프로세스를 재시작할 때 이전에 실행한 처리기에서 다시 처리하는 것이 효율적이다. 이러한 성질을 처리기 친화성이라고 한다.  
    노력하지만 보장하지 않을 때를 약한 친화성, 보장되는 경우를 강한 친화성이라고 표현한다.  
    - 부하 균등화(Load balancing)은 SMP 시스템에서 각 처리기의 부하가 고르게 분배되도록 하는 것이다. pull 이주와 push 이주가 있다.  
    Pull 이주는 쉬고 있는 처리기가 바쁜 처리기의 프로세스를 갖고 오는 것이고, Push 이주는 특정 태스크가 각 처리기가 과부화 상태인지 확인하여 과부화 상태인 처리기의 프로세스를 다른 처리기에 이주시키는 것이다.  
    - 스케쥴링 알고리즘 분석 방법으로 특정 시나리오의 결과를 확인하는 결정론적 모델링, 분포를 근사하여 샘플링하는 큐잉 모델, 모의실험 등이 있다.  
    스케쥴링 알고리즘이 안정 상태에 있다면 큐의 길이가 일정할 것이다. 따라서 평균 큐 길이(n) = 평균 도착률(a) * 단위시간 동안 발생한 새로운 프로세스(W) 가 성립한다. 이를 Little's Formula 라고 한다.  
    
#### 6장) 프로세스 동기화
    - 동시에 여러 개의 프로세스가 동일한 자료에 접근하여 조작하고, 그 실행 결과가 접근이 발생한 순서에 의존하는 상황을 경쟁상황(Race Condition)이라고 한다.  
    - 각 프로세스는 임계 영역(Critical Section) 이라 부르는 코드 부분이 존재하고, 가장 큰 특징은 특정 프로세스가 자신의 임계영역에서 실행되는 동안 다른 프로세스가 자신의 임계영역에 접근할 수 없다는 것이다.  
    - 각 프로세스는 자신의 임계영역에 접근하기 위해 진입 허가를 요청해야 하는데, 이러한 요청을 구현하는 코드를 진입 영역(Entry Section)이라고 한다.  
    - 임계영역 뒤에 퇴출 영역이 따라올 수 있고, 그 외 모든 부분을 나머지 영영이라고 부른다.  
    - 임계 영역 접근은 상호 배제(Mutual Exclusion), 진행(Progress), 한정된 대기(Bounded wating) 의 세 가지 조건을 충족해야 한다.  
    상호 배제란 특정 프로세스가 임계영역에서 실행되는 동안 다른 프로세스는 자신의 임계영역에 접근할 수 없다는 성질이다.  
    진행이란 현재 임계영역에서 실행되는 프로세스가 없다면 현재 나머지 부분에서 실행 중이지 않은 프로세스만 임계영역에 접근할 수 있는 가능성이 존재하며, 이 선택이 무기한 연기될 수 없다는 성질이다.  
    한정된 대기란 프로세스가 자신의 임계 영역으로 진입하려는 요청을 한 후부터 그 요청이 허용될 떄까지 다른 프로세스가 자신의 임계 영역에 접근 허용되는 횟수가 제한되어 있어야 한다는 성질이다.  
    - 비선점형 커널은 한 순간에 커널 안에서 실행 중인 프로세스가 하나 밖에 없기 때문에 커널 자료구조에 대한 경쟁 조건을 염려할 필요가 없다.  
    - 선점형 커널은 실시간 프로세스가 현재 커널에서 실행 중인 프로세스를 선점할 수 있기 때문에 실시간 프로그래밍에 더 적합하다.  
    - 임계 영역에 대한 고전적인 소프트웨어 기반 해결책 중 하나가 피터슨의 해결안(Peterson's Solution)이다. 
    그러나 현대 컴퓨터 구조가 load/store 같은 기본적인 기계어를 실행하는 방식이므로 이러한 구조에서 피터슨의 해결안이 올바르게 작동한다고 보장할 수 없다.  
    피터슨의 해결안은 임계 영역과 나머지 영역을 번갈아 가며 실행하는 두 개의 프로세스(Pi, Pj)를 가정한다.
    ```
    int turn;
    boolean flag[2];
    do 
    {
        flag[i] = TRUE;
        turn = j;
        while (flag[j] && turn == j); 무한 루프
        임계 영역
        flag[i] = False;
        나머지 영역
    } while (TRUE);
    ```
    - 일반적으로 임계 영역에 대한 임의의 해결책은 락(lock)이라는 간단한 도구를 사용하여 해결할 수 있다.  
    - 단일처리기 환경에서 공유 변수가 변경되는 동안 인러턻트 발생을 혀용하지 않음으로써 임계영역 문제를 간단히 해결할 수 있다.  
    - 원래 값을 반환하고 현재 값을 변경(true) 하는 작동이 원자적으로, 또는 두 개 값을 교환하는 swap 이 원자적으로 실행된다면 동기화된 하드웨어로 임계 영역 문제가 간단히 해결된다.  
    - 다중처리기 환경에서는 인터럽트 불능화에 상당한 시간이 소요되어 사용할 수 없다.  
    - 하드웨어 기반 해결책을 응용 프로그래머가 사용하기에 복잡하므로 세마포(Semaphore)라고 하는 동기화 도구를 이용할 수 있다.    
    세마포는 정수 변수로서 초기화를 제외하고 원자적 연산으로 wait()과 signal() 로만 접근 가능하다.  
    - 운영체제는 종종 카운팅과 이진 세마포를 구분한다. 카운팅 세마포의 값은 제한 없는 영역을 가진다. 이진 세마포의 값은 0 과 1 사의의 값만 가능하다. 이진 세마포는 mutex 락이라고도 불린다.  
    카운팅 세마포는 유한한 개수를 가진 자원에 대한 접근을 제어하는 데에 사용될 수 있다. 세마포는 가용한 자원의 개수로 초기화된다.  
    각 자원을 사용하려는 프로세스는 세마포에 wait() 연산을 실행하며, 이 때 세마포 값은 감소된다.  
    프로세스가 자원을 방출할 때 signal() 연산이 수행되고 세마포 값이 증가한다. 세마포 값이 0이면 모든 자원이 사용 중임을 나타낸다.  
    프로세스는 세마포 값이 0보다 클 때까지 봉쇄된다.  
    - 세마포 정의의 주된 단점은 바쁜 대기(Busy Waiting)을 해야 한다는 점이다. 이렇듯 프로세스가 락을 기다리는 동안 회전하기 때문에 이런 타입의 세마포를 스핀락(Spinlock)이라고 부르기도 한다.  
    문맥 교환이 필요하지 않다는 점에서 락이 짧은 시간 동안만 소유될 것으로 예상될 결우 스핀락이 유용하다.  
    - 바쁜 대기 대신에 봉쇄를 할 수 있는데, 봉쇄 연산은 프로세스를 세마포에 연관된 대기 큐에 넣고, 프로세스의 상태를 대기 상태로 전환한다.  
    - 다중처리기 환경에서 임계 영역 문제를 해결하기 위해 spinlocks 와 같은 다른 락킹 비법을 제공해야 한다.  
    - 교착상태(Deadlock)와 기아(Stravation) 문제가 발생하지 않도록 고려해야 한다. 무기한 봉쇄(Indefinite Blocking)는 세마포와 연관된 큐가 LIFO를 따를 때에 발생할 수 있다.  
    - 우선순위 역전(Priority Inversion)이란 높은 순위의 프로세스가 대기 중인 상황에서 중간 순위의 프로세스가 실행 가능 상태로 변경됨으로써 낮은 순위의 프로세스를 선점하는 것을 말한다.    
    우선순위 상속 프로토콜을 사용하여 이 문제를 해결할 수 있다.  
    - 고전적인 동기화 문제들로 유한 버퍼 문제, Readers-Writers 문제(쓰는 도중에 읽으면 엉뚱한 데이터를 읽으므로), 식사하는 철학자들 문제(모든 프로세스가 각각 하나의 자원을 점유하고 있고, 프로세스를 완료하기 위해 다른 프로세스가 점유한 자원을 요구할 때)가 있다.  
    - 프로그래머가 세마포를 잘못 사용하면 문제가 발생할 수 있는 여지가 많으므로 모니터(Monitor)라는 고급 언어 구조물이 도입되었다.  
    - 모니터 구조물은 모니터 안에 있는 프로세스 중 항상 하나의 프로세스만 활성화되도록 보장한다.  
    - 하나의 논리적 기능을 실행하는 명령어의 집합을 트랜잭션이라고 하고, 원자성(Atomicity)가 보장되어야 한다.  
    - 철회된 트랜잭션이 이미 접근한 데이터를 변경했을 수도 있기 때문에 시스템이 원자성을 보장하기 위해 롤백(roll back)을 책임지고 해야 한다.  
    - 트랜잭션 메모리는 스레드-안전 동시실행 응용 개발을 위한 락, 세마포 등 외의 대체 전략을 제공한다.  
    - 원자성을 보장하는 간단한 방법 중 하나는 트랜잭션에 의해 접근된 데이터에 가해지는 모든 변경내역을 안전 저장장치에 기록하는 것이다.  
    이런 형태의 기록을 얻기 위해 가장 많이 사용되는 기법이 로그 우선 쓰기(Write-Ahead Logging)이다.  
    각 로그 레코드는 트랜잭션 이름, 데이터 항목 이름, 이전 값, 새 값의 정보를 가진다.  
    - 로그에 검사점(Checkpoint)를 추가하여 로그 우선 쓰기의 성능을 향상할 수 있다. 
    - 트랜잭션을 병렬로 실행시키면 그 결과는 모든 트랜잭션을 차례대로 순차적으로 실행시킨 것과 같아야 한다. 이러한 성질을 직렬가능성(Serializability)라고 한다.  
    - 일련의 비충돌(Nonconflicting) 연산들을 서로 swap 함으로써 직렬 스케쥴로 변환할 수 있다면 이를 충돌 직렬가능(Conflict Serializable)하다고 한다.  
    - 직렬 가능성을 보장하는 한 가지 방법은 각 데이터 항목마다 락을 두고, 각 트랜잭션이 일정한 락킹 프로토콜에 맞추어 락을 획득하고 반납하도록 규정하는 것이다.  
    락은 다양항 모드가 있을 수 있으며, 보통 공유(Shared) 와 독점(Exclusive) 가 필요하다.  
    - 두 단계 락킹 프로토콜(Two Stage Locking Protocol) 은 직렬 가능성을 보장해주는 프로토콜 중 하나이다. 각 트랜잭션이 락과 언락을 두 단계를 실행할 것을 요구한다.  
    확장 단계에서는 트랜잭션이 락을 새로 얻을 수 있지만 얻었던 락을 반납해서는 안된다.  
    수축 단계에서는 얻었던 락을 반납할 수 있지만 새로운 락을 얻어서는 안된다.  
    - 직렬 가능한 순서를 결정하는 또 다른 방법은 미리 순서를 선택하는 방법이다. 이 방법 중 가장 많이 사용되는 방법은 타임스탬프 순서 기법(timestamp ordering scheme)이다.  
    - 타임스탬프 순서 기법은 트랜잭션이 실행되기 전에 각 트랜잭션마다 타임스탬프를 부여하고 트랜잭션이 이 순서에 따라 수행되는 것이다.
    - 타임스탬프를 구현하는 방법으로 시스템 클록(system clock)을 사용할 수 있다. 즉 타임스탬프가 트랜잭션이 시스템에 도착했을 때의 시스템 클록 값으로 입력되는 것이다.  
    - 또 다른 방법으로 논리적인 카운터를 사용할 수 있다. 즉 타임스탬프가 트랜잭션이 시스템에 도착했을 때의 논리적인 카운터 값으로 기록된다.  
    
#### 7장) 교착상태
    - 정상적인 작동 중 프로세스는 요쳥->사용->방출 의 순서로만 자원을 사용할 수 있다.
    - 자원의 요청과 방출은 시스템 호출로, 프로세스나 스레드가 커널이 관리하는 자원을 사용할 때매다 매번 운영체제는 프로세스가 자원을 요청했는지와 할당받았는지 확인하다.  
    시스템은 각 자원이 어느 프로세스에 할당되었는지 기록한다.  
    - 교착상태에 빠진 프로세스들은 결코 끝날 수 없으며, 자원이 묶여 있어 다른 작업을 시작하는 것도 불가능하다.  
    - 교착상태는 상호배제(최소 하나의 자원이 비공유 모드로 점유된 상태), 점유하며 대기(프로세스가 최소 하나의 자원을 점유한 채 다른 자원을 얻기 위하여 대기), 
    비선점(프로세스가 자원을 선점할 수 없음), 순환대기(P0 가 P1이 점유한 자원을 요청하고, ..., Pn이 P0이 점유한 자원을 요청하는 순환상태에 있어야 함) 의 네 가지 조건이 성립되어야 발생한다.  
    - 교착상태를 보다 정확하게 기술하기 위해 자원 할당 그래프를 활용할 수 있다. 정점은 각 프로세스와 자원의 집합을 의미한다.  
    프로세스로부터 자원으로 향하는 간선은 요청을 뜻하며, 자원에서 프로세스로 향하는 간선은 점유를 뜻한다.  
    그래프가 사이클을 포함하지 않으면 교착상태가 아님을 보일 수 있다. 반면 사이클이 존재할 경우 교착상태가 존재할 수 있다. 만약 각 자원의 인스턴스가 하나라면 사이클은 교착상태임을 의미한다.  
    - 교착상태 처리 방법으로 교착상태가 발생하지 않도록 보장하거나, 교착상태가 되면 회복시키거나 문제를 무시하고 교착상태가 발생하지 않은 척하는 방법이 있다.  
    문제를 무시하고 교착상태가 발생하지 않은 척 하는 방법이 Unix 및 Windows 를 포함한 대부분의 운영체제가 사용하는 방법이다. 이 경우 문제를 해결하는 것은 프로그래머의 몫이다.  
    - 교착상태를 탐지하고 복구하는 알고리즘이 없다면 시스템은 교착상태에 이를 수 있고, 그럼에도 교착상태가 발생한 것을 인식하지 못할 수 있다.  
    결국 시스템은 작동을 정지하고, 수작업으로 다시 시작할 필요가 있다. 대부분의 운영체제에서 이 방법을 사용하고 있다.  
    - 교착상태를 만드는 네 가지 조건 중 일부를 회피함으로써 교착상태를 예방할 수 있다.  
    - 상호배제: 공유가능한 자원은 배타적 접근을 요구하지 않으므로 해당 문제가 없다. 그러나 일반적으로 상호 배제 조건을 인정하지 않음으로써 예방하는 것은 불가능하다.  
    - 점유하며 대기: 한 가지 프로토콜은 각 프로세스가 실행되기 전에 반드시 자신의 모든 자원을 요청하여 할당받게 하는 것이다.  
    다른 프로토콜로 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원을 요철할 수 있도록 하는 것이다. 이 때 자원의 추가 요청은 기존 자원을 전부 방출하고 재요청하는 식으로 수행된다.  
    이 두 프로토콜의 단점으로 많은 자원들이 할당된 후 오래 사용되지 않아 이용률이 낮을 수 있다는 점과 필요한 자원 중 하나가 항상 다른 프로세스에 할당되어 기아 상태가 가능하다는 점이 있다.  
    - 비선점: 만일 어떤 자원을 점유하고 있는 프로세스가 즉시 할당할 수 없는 다른 자원을 요청하면 현재 점유되어 있는 자원들을 선점한다. 즉 묵시적으로 방출한다.  
    다른 대안으로 한 프로세스가 자원을 요청하면 사용 가능한지 검사하고, 사용 가능하면 할당한다.  
    사용 불가능하다면 그 자원들이 추가 자원을 기다리고 있는 다른 프로세스에 할당되어있는지 검사하고, 만약 그렇다면 해당 자원을 선점해 요청 프로세스에 할당하고 그렇지 않다면 대기한다.  
    대기하는 동안 그 프로세스의 자원들 중 일부는 다른 프로세스로부터 요청받아 선점될 수 있다.  
    이 프로토콜은 CPU레지스터나 메모리처럼 그 상태가 쉽게 저장되고 복원될 수 있는 자원에 종종 적용된다. 프린터나 테이프 드라이브같은 자원에는 적용할 수 없다.  
    - 순환대기: 한 가지 방법은 모든 자원에 전체적인 순서를 부여하여 각 프로세스가 열거된 순서대로 오름차순으로 자원을 요청하도록 하는 것이다.  
    대안으로 프로세스가 현재 선점한 자원보다 낮은 순위의 자원을 요청할 때 요청 자원보다 높은 순위의 자원을 방출하도록 요구할 수 있다.  
    순서나 계층 구조를 정하는 것 자체만으로 교착상태를 예방할 수 없다. 순서를 지키는 프로그램을 작성해야 한다.  
    락이 동적으로 획득될 수 있다면 락 순서를 부여한다고 해서 교착상태가 예방되지 않는다는 것에 주의해야 한다.  
    - 교착상태가 발생하지 않도록 한 위 방법의 문제점은 장치의 이용률이 저하되고 시스템 처리율이 감소된다는 것이다.  
    - 교착상태를 회피하는 다른 방법은 자원이 어떻게 요청될지에 대한 추가 정보를 제공하도록 하는 것이다. 각 프로세스의 요청과 방출에 대한 완전한 순서를 파악할 수 있다면 각 요청에 대해 교착상태를 회피하기 위해 대기 여부를 결정할 수 있다.  
    - 이 방법 중 가장 단순한 방법은 각 프로세스가 자신이 필요로 하는 자원의 종류와 최대 개수를 선언하는 것이다.  
    - 안전 상태란 시스템이 어떤 순서로든 프로세스들이 요청하는 모든 자원을 교착상태 없이 차례로 모두 할당해 줄 수 있는 상태이다.  
    - 시스템이 불안전하다는 것은 앞으로 교착상태로 가게 될 수도 있다는 가능성을 의미한다.  
    - 회피 알고리즘이 교착상태를 회피하는 기본 원칙은 시스템이 안전 상태에 머물도록 하는 것이다.  
    - 만약 각 자원 타입마다 하나의 인스턴스를 갖는다면 교착상태 회피를 위해 자원 할당 그래프의 변형을 사용할 수 있다.  
    프로세스가 자원을 요청할 때에 사이클 탐지 알고리즘을 활용해 해당 요청이 사이클을 만들지 않을 때에만 요청을 허용할 수 있다.  
    - 은행원 알고리즘은 자원 타입마다 여러 개의 인스턴스가 있을 때 사용 가능하지만 자원 할당 그래프보다 효율성이 떨어진다.  
    - 은행원 알고리즘은 안전성 알고리즘와 자원 할당 알고리즘으로 구성된다.  
    - 만약 시스템이 교착상태 예방이나 교착상태 방지 알고리즘을 사용하지 않는다면 교착상태가 발생할 수 있다. 이런 환경에서 시스템은 시스템의 상태를 검사하는 알고리즘과 교착상태로부터 회복하는 알고리즘을 반드시 지원해야 한다.  
    - 각 자원 타입의 인스턴스가 한 개씩 있는 경우 대기 그래프(wait-for graph)라고 하는 자원할당 그래프의 변형을 사용해 교착상태 탐지 알고리즘을 정의할 수 있다.  
    - 각 자원 타입마다 여러 개의 인스턴스가 존재하는 경우 은행원 알고리즘 유사한 알고리즘을 사용해 탐지할 수 있다.  
    - 교착상태 탐지 알고리즘을 언제 실행하는가 하는 것은 교착상태 발생 빈도와 교착상태에 연관된 프로세스의 평균 갯수에 의존한다.  
    일반적으로 교착상태가 자주 일어난다면 탐지 알고리즘도 자주 실행해야 한다.
    - 교착상태가 탐지되었다면 해결해야 한다. 첫 째 해결방법은 운영자에서 통지해 운영자가 해결하는 방법이고, 다른 방법은 교착상태를 야기시킨 한 개 이상의 프로세스를 중지시키는 것이다. 마지막 방법은 자원을 선점하는 것이다.  
    - 프로세스를 중지시키는 방법은 교착 상태의 프로세스를 모두 중지하거나 차례대록 한 프로세스씩 중지하는 방법이 있다.  
    프로세스를 중저시키는 것은 비용이 크므로 비용이 최소인 프로세스를 중지시키는 것을 고려해야 한다. 프로세스의 우선순위 및 진척도 등 여러 요인에 따라 비용이 결정된다.  
    - 자원 선점을 이용해 교착상태를 제거하려면 교착상태가 깨질 때까지 자원을 선점해야 한다. 이 때 어느 자원을 어느 프로세스로부터 선점할 것이지 비용을 고려하여 결정해야 하며,  
    선점된 자원을 점유했던 프로세스를 어떻게 안전한 상태로 롤백할 것인지, 기아 상태가 발생하지 않는 것을 어떻게 보장할 것인지 고려해야 한다.
    
#### 8장) 메모리 관리 전략
    - 명령어 실행은 먼저 메모리로부터 한 명령어를 가져오는 데에서 시작한다.  
    - 주 메모리와 프로세서 레지스터 자체에 내장되어 있는 레지스터들은 CPU가 직접 접근할 수 있는 유일한 저장장치이다.  
    - CPU에 내장되어 있는 레지스터들은 일반적으로 CPU 클록의 1사이클 내에 접근 가능하다.  
    - 반면 주 메모리의 접근을 완료하기 위해서는 많은 사이클이 소요되며, CPU가 필요한 데이터가 없어서 명령어를 실행하지 못하고 지연(stall)되는 현상이 발생한다.  
    - CPU와 주 메모리 사이에 존재하는 캐시(Cache)라고 메모리 버퍼가 속도의 차이를 완화시키기 위해 사용된다.  
    - 각각의 프로세스는 독립된 메모리 공간을 가진다.   
    이러한 보호 기법은 특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 기준(base)와 상환(limit)이라 불리는 두 개의 레지스터를 활용해 구현한다.  
    기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 적재된다.  
    - 사용자 모드에서 실행되는 프로그램에 의해 운영체제의 메모리 공간이나 다른 프로그램의 메모리 공간에 대한 접근이 일어나면 치명적인 에러로 간주되어 트랩(trap)을 발생시킨다.  
    - 주소 할당 방법으로 컴파일 시간 바인딩, 적재 시간 바인딩, 실행 시간 바인딩이 있다.  
    컴파일 시간 바인딩이란 컴파일 될 때에 절대 주소를 결졍하는 것이다. MS-DOS 의 .COM 양식 프로그램이 컴파일 시간에 바인딩하는 절대 코드의 예이다.  
    적재 시간 바인딩이란 프로그램이 메모리에 실제로 적재될 때 절대 주소가 생성되는 것이다.  
    실행 시간 바인딩은 만약 프로세스가 실행되는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 이동 가능한 것을 말한다. 이를 가능하게 하려면 특별한 하드웨어를 이용해야 한다.  
    - CPU가 생성하는 주소를 일반적으로 논리 주소라 하며, 메모리가 취급하게 되는 주소(MAR, 메모리 주소 레지스터)는 일반적으로 물리 주소라고 한다.  
    컴파일 시간 바인딩과 적재 주소 바인딩의 경우 논리 주소와 물리 주소가 같다. 반면 실행 시간 바인딩은 물리 주소와 논리 주소가 다르다. 이러한 경우 논리 주소를 가상 주소라고 한다.  
    - 프로그램 실행 중에 이와 같은 가상 주소를 물리 주소로 바꾸어야 하는데 이 변환 작업은 하드웨어 장치인 메모리 관리기(MMU, Memory Management Unit)에 의해 실행된다.  
    - 동적 적재란 각 프로세스의 특정 루틴이 실제 호출되기 전까지 메모리에 올라오지 않고 재배치 가능한 상태로 디스크에 대기하는 것이다.  
    동적 적재의 장점은 사용되지 않는 루틴들이 미리 적재되지 않아서 메모리 공간 이용률이 높아진다는 점이다.  
    동적 적재는 프로그래머가 직접 구현해야 하며, 동적 적재를 구현하는 운영체제의 라이브러리 루틴을 활용할 수 있다.  
    - 동적 연결이란 동적 적재와 유사하게 연결(Linking)이 실행 시기까지 미루어지는 것이다.  
    동적 연결에서는 라이브러리를 부르는 곳마다 스텁(stub)이 생긴다. 스텁은 작은 코드 조각으로 메모리에 존재하는 메모리를 찾는 방법 또는 메모리에 없을 경우 라이브러리를 적재하는 방법을 알려준다.  
    예를 들어 printf() 라이브러리를 10 개의 프로세스에서 사용한다고 하더라도 해당 라이브러리 코드는 하나만 있어도 된다.  
    동적 적재와는 달리 동적 연결은 일반적으로 운영체제의 도움이 필요하다.  
    - 필요한 경우 프로세스는 실행 도중 보조 메모리로 교체되어 나갔다가 다시 메모리로 되돌아올 수 있는데 이를 스왑(Swap)이라고 한다.  
    예를 들어 라운드 로빈 스케쥴링을 사용할 경우 프로세스가 시간 할당량을 모두 소비했을 때 그 프로세스를 스왑시킬 수 있다.  
    만약 바인딩이 컴파일 시간 바인딩이나 적재 시간 바인딩이라면 절대주소가 결정되었기 때문에 스왑되어 나간 프로세스가 다시 돌아오기 위해서는 똑같은 메모리 위치로 돌아와야 한다.  
    실행 시간 바인딩이라면 임의의 주소로 되돌아올 수 있다.  
    - 새로운 프로세스 또는 되돌아오는 프로세스의 메모리를 확보하기 위해 기존 프로세스를 스왑하려고 할 때, 기존 프로세스가 입출력을 기다리고 있다면 프로세스를 스왑할 수 없다.  
    이를 구현하는 방법은 입출력이 종료되지 않은 프로세스를 스왑하지 말거나 입출력을 항상 운영체제의 버퍼와만 하도록 하는 방법이 있다. 운영체제와 프로세스 사이의 전송은 스왑되어 들어온 상태에서 하면 된다.  
    - 이러한 표준 스와핑 방식은 스와핑 시간이 오래 걸려서 현재 거의 사용되지 않는다.  
    - 보통 여러 프로세스가 동시에 메모리에 올라와 있는 것이 바람직하기 때문에 메모리에 올라오기 위해 입력 큐에 대기하고 있는 프로세스들에 메모리를 어떻게 할당하는 것이 좋을지 고려해야 한다. 연속 메모리 할당 시스템에서 각 프로세스는 연속된 메모리 공간을 차지한다.  
    - 가장 간단한 메모리 할당 방법은 메모리를 고정된 크기로 분할하는 것이다. 이 때 분할의 개수가 다중 프로그래밍의 정도를 결정한다.  
    이런 고정 분할 기법을 일반화시킨 형태로 MVT라고 부르며, 주로 배치 환경에서 사용된다.  
    - 가변 분할 기법에서 운영체제는 메모리의 어떤 부분이 사용되고 있는지 파악할 수 있는 테이블을 유지한다.  
    - 동적 메모리 할당 문제란 일련의 자유 공간 리스트에서 크기 n바이트인 블록 요청을 어떻게 만족할지 결정하는 문제이다.  
    최초 적합(First-Fit), 최적 적합(Best-Fit)과 최악 적합(Worst-Fit)이 가장 일반적인 기법이다.  
    최초 적합은 요청을 만족시키는 충분히 큰 첫 번째 사용 가능한 공간에 할당하는 것이다.  
    최적 적합은 충분히 큰 공간들 중 가장 작은 공간에 할당하는 것이다.  
    최악 적합은 가장 큰 공간에 할당하는 것이다. 이 때 프로세스가 들어가고도 충분한 크기의 공간이 존재하므로 다른 프로세스 역시 사용될 수 있다.  
    - 외부 단편화란 프로세스가 메모리에 적재되고 제거되는 일이 반복되다보면 각 자유 공간이 너무 작은 조각이 되어버려 가용 공간을 모두 합치면 충분한 공간이 되지만 각각의 공간은 너무 작아 사용되지 못하는 상황을 말한다.  
    일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수 배로만 해주게 되는데, 이러한 경우에도 각각의 내부적 공간에 남는 공간이 발생할 수 있다. 이러한 것을 내부 단편화라고 한다.  
    - 외부 단편화 문제를 해결하는 한 가지 방법은 압축이다. 이는 메모리의 모든 내용을 한 군데로 몰고 모든 자유 공간을 다른 곳으로 모아서 큰 블록을 만드는 것이다. 그러나 이 방법은 비용이 많이 든다.  
    - 외부 단편화 문제를 해결하는 다른 방법은 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 것이다. 이 해결책을 구현하는 방법으로 페이징과 세그먼테이션, 또는 두 개의 결합이 사용될 수 있다.  
    - 페이징은 물리 메모리를 프레임(Frame)이라 불리는 고정 크기의 블록으로 나누고, 논리 메모리는 페이지(Page)라고 불리는 같은 크기의 블록으로 나눈 후, 프로세스가 실행될 때 각 페이지가 가용한 프레임에 적재되는 식이다.  
    - 페이징을 위한 하드웨어가 존재하고, CPU의 각 주소는 페이지 번호와 페이지 변위 두 개의 부분으로 나뉜다. 페이지 번호는 페이지 테이블을 액세스할 때 사용되며 페이지 테이블은 주 메모리에 존재하는 페이지의 기준 주소를 갖고 있다.  
    - 만약 논리 주소 공간의 크기가 2^m 이고, 페이지가 2^n 크기라면 상위 m-n 비트는 페이지 번호를 나타내고 하위 n 비트는 페이지 변위를 나타낸다.  
    - 페이징을 사용하면 외부 단편화가 발생하지 않는 반면 내부 단편화가 발생한다.    
    내부 단편화를 고려했을 때 페이지 크기가 작은 것이 선호되나 페이지 크기가 작아지면 페이지 테이블의 크기가 커지게 되고, 이 테이블이 차지하는 공간이 낭비된다.  
    - 페이징의 가장 중요한 특징은 메모리에 대한 사용자 인식과 실제 물리 메모리를 명확하게 분리한다는 사실이다.  
    - 만약 사용자가 시스템 호출을 호출하여 매개변수로 어떤 주소를 전달했을 때 제대로 사상하여 해당 주소로 찾아가기 위해 운영체제는 각 프로세스에 대해 페이지 테이블의 복사본을 유지해야 한다.  
    또한 프로세스가 CPU를 할당받았을 때 페이지 테이블을 설정하는 데에 CPU디스패처가 사용된다. 따라서 페이징은 문맥 교환 시간을 증가시킨다.  
    - 대부분의 운영체제는 각 프로세스마다 하나의 페이지 테이블을 할당한다. 페이지 테이블을 가리키는 포인터는 PCB에 저장된다.  
    - 가장 간단한 페이지 테이블은 전용 레지스터의 집합으로 구현될 수 있다. 이들 레지스터는 고속 논리 회로로 설계된다. 그러나 대부분의 경우 페이지 테이블이 크므로 이는 실현 가능하지 않다.    
    따라서 대부분의 컴퓨터는 페이지 테이블을 주 메모리에 저장하고 페이지 테이블 기준 레지스터(PTBR, Page Table Base Register)로 하여 페이지 테이블을 가리키도록 한다. 이 방식의 문제점은 사용자의 메모리 접근 시간이 오래 걸린다는 것이다.  
    이 문제를 해결하는 표준 방법은 TLB(Translation Look-aside Buffers)라고 불리는 특수한 소형 하드웨어 캐시를 사용하는 것이다.  
    TLB에 페이지를 찾아달라는 요청이 들어오면 찾고자 하는 페이지를 동시에 여러 개의 내부 키와 비교한다. 페이지 번호가 발견되면 대응하는 프레임 번호를 알려준다.    
    만약 페이지 번호가 연관 레지스터 TLB에서 찾아지지 않으면 주 메모리에 있는 페이지 테이블에서 찾아 사용하고 이 정보를 TLB에 추가한다.  
    만약 TLB가 가득 차 있으면 교체 작업을 해야 하는데 교체 정책은 LRU부터 무작위 교체까지 다양한 정책이 사용된다.  
    어떤 TLB는 각 항목에 ASIDs(Address-Space Identifers)를 저장하기도 한다. ASID는 그 TLB항목이 어느 프로세스에 속한 것인지 알려주며, 그 프로세스의 주소 공간을 보호하기 위해서 사용된다.  
    - 페이지 번호가 TLB에서 발견되는 비율을 적중률(hit ratio)라고 부른다.  
    - 페이지화된 환경에서 메모리의 보호는 각 프레임과 연관된 보호 비트에 의해 구현된다. 읽기 전용 페이지에 대해 쓰기를 시도하면 운영체제에게 하드웨어 트랩 또는 메모리 보호 위한이 전달된다.  
    - 페이지 테이블의 각 엔트리에는 유효/무효 비트가 하나 더 존재한다. 유효로 설정되면 프로세스의 합법적 페이지임을 나타낸다.  
    - 페이징의 또 다른 장점은 공통 코드를 공유할 수 있다는 점이다. 어떤 웅영체제는 메모리 공유를 공유 페이지를 사용하여 구현하기도 한다.  
    - 메모리 크기가 m, 페이지 크기가 n이라면 페이지 테이블은 2^m-n 의 항목으로 구성된다. 이렇게 할 경우 페이지 테이블의 크기가 커지게 되는데, 한 가지 간단한 방법은 페이지 테이블을 여러 개의 작은 조각으로 나누는 것이다.  
    - 해결 방법 중 하나로 2단계 페이징 기법을 사용하는 것이 있다.  
    - 주소 공간이 32비트보다 코지면 가상 주소를 해시값으로 사용하는 해시 페이지 테이블을 많이 쓴다. 해시 페이지 테이블의 각 항목은 연결 리스트를 갖고 있고 각 원소는 가상 페이지 번호, 맵핑되는 페지이 프레임 번호와 다음 원소를 가리키는 포인터를 갖고 있다.  
    - 해시 페이지 테이블 알고리즘은 가상 주소의 가장 페이지 번호를 해싱하고, 해당 해시 값의 연결 리스트의 첫 번째 원소와 가상 페이지 번호를 비교한다.  
    일치하면 그에 대응하는 페이지 프레임 번호를 사용하여 물리 주소를 얻는다. 만약 일치하지 않으면 연결 리스트의 다음 원소를 탐색해가며 일치하는 가상 페이지 번호를 찾는다.  
    - 해시 페이지 테이블의 변형으로 클러스터 페이지 테이블이 제안되었다. 클러스터 페이지 테이블은 메모리 액세스가 비연속적이면서 전체 주소 공간에 넓게 흩어져 있는 경우에 유용하다.  
    - 보통 프로세스는 각자 하나씩 페이지 테이블을 가진다. 이러한 기법의 단점 중 하나는 페이지 테이블의 크기이다. 이 문제를 해결하는 한 방법이 역 페이지 테이블이다.  
    역 페이지 테이블에서는 물리 메모리 프레임마다 한 항목씩 할당한다. 각 항목은 프레임에 올라와 있는 페이지의 가상 주소와 프로세스 ID로 구성된다.  
    이렇게 하면 시스템에 단 하나의 페이지 테이블만 존재하게 되어 메모리에서 훨씬 작은 공간을 점유한다.  
    반면 주소변환 시간이 더 오래 걸릴 수 있다. 역 페이지 테이블은 물리 주소에 따라 정렬되어 있지만 탐색은 가상 주소를 기준으로 하기 때문이다.  
    이를 해결하기 위해 해시 테이블을 사용할 수 있고, 이 역시도 TLB를 사용하여 성능 향상을 꾀할 수 있다.  
    한편 역 페이지 테이블을 사용하는 경우 메모리 공유가 더 어렵다. 메모리 공유는 보통 하나의 물리 영역에 사상되는 여러 개의 가상주소를 갖기 때문이다.  
    - 세그먼테이션은 사용자 관점의 메모리를 그대로 지원하는 메모리 관리 기법이다. 논리 주소 공간을 세그먼트의 집합으로 정의하고 각 세그먼트는 이름과 길이를 갖는다.  
    예를 들어 C컴파일러는 코드, 전역 변수, 힙, 스택과 표준 C 라이브러리를 위한 세그먼트를 생성한다.  
    - 사용자는 2차원 주소로 객체를 지정할 수 있지만(n번째 세그먼트, 18번째 바이트) 실제 물리 메모리는 바이트들의 1차원 배열이다. 따라서 사용자가 지정한 2차원 주소는 1차원 물리 주소로 사상되어야 한다.  
    이 사상은 세그먼트 테이블에 의해 이루어진다. 세그먼트 테이블의 각 항목은 세그먼트 기준과 세그먼트 한계로 구성된다.  
    - 펜티엄 시스템에서 CPU는 세그먼테이션 유닛에게 보내질 논리 주소를 만들고, 세그먼테이션 유닛은 각각의 논리 주소를 선형 주소로 변환한다. 선형 주소는 다시 페이지 유닛으로 보내진다.  
    

#### 9장) 가상 메모리
#### 10장) 파일 시스템
#### 11장) 파일 시스템 구현
#### 12장) 2차 저장장치 구조
#### 13장) 입출력 시스템
#### 14장) 보호
#### 15장) 보안
#### 16장) 분산 운영체제
#### 17장) 분산 파일 시스템
#### 18장) 분산 동기화
#### 19장) 실시간 시스템
#### 20장) 멀티미디어 시스템
#### 21장) Linux 시스템
#### 22장) 윈도우즈 XP
#### 23장) 영향력 있는 운영체제
