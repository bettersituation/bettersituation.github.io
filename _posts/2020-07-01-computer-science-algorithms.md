---
layout: post
topic: computer-science
title: 알고리즘
---

자료구조를 학습한 후 알고리즘을 공부하리라 다짐했었다.  
6 월에 자료구조를 마친 후 이제 알고리즘을 학습해보려고 한다.  
알고리즘 역시 참고할 수 있는 자료가 많고 그 컨셉이 다양한데,  
각 책마다 문제풀이에 집중하거나 이론에 집중하는 등 그 컨셉이 다르다.  


여자친구에게 의견을 구해보니 일단 이론적인 것을 학습한 후  
문제풀이는 리트코드 등의 온라인 사이트를 이용하는 것이 좋을 것 같다 하여 그렇게 하기로 했다.  

읽을 책은 한빛 교재 시리즈 중 하나인 "쉽게 배우는 알고리즘 - 관계 중심의 사고법" 이라는 책이다.  
목차를 대충대충 살펴보니 자료구조와 겹치는 부분이 많았다.  
사실 상 자료구조의 심화버젼이라고 해도 될 정도였다.  

정리할 내용이 많을 듯 싶다. 운영체제 정리와 다르게 그림, 의사코드 및 수식 등이 많이 등장할 듯 하다.  
책에서 소개하는 알고리즘에 대해 실제 코드를 구현해보면 좋겠지만 그렇게 하면 너무 오래 걸릴 듯 하다..  
그러므로 운영체제와 마찬가지로 챕터 별로 중요한 내용만 추려서 정리할 것이다.  

---

### 1. 알고리즘 설계와 분석의 기초

- 알고리즘의 중요성과 표기법에 대해 다루는 챕터
- 표기법 및 그 뜻은 아래와 같다.

$$
\text{1.} \; O(f(x)) = \{ g : \lim_{n \rightarrow \infty} \frac{g(x)}{f(x)} < \infty \} \quad \text{(점근적 상한)} \\
\text{2.} \; \Omega(f(x)) =  \{ g : \lim_{n \rightarrow \infty} \frac{f(x)}{g(x)} < \infty \} \quad \text{(점근적 하한)} \\
\text{3.} \; \Theta(f(x)) = O(f(x)) \cap \Omega(f(x)) \\
\text{4.} \; o(f(x)) = \{ g : \lim_{n \rightarrow \infty} \frac{g(x)}{f(x)} = 0 \} \quad \text{(여유있는 상한)} \\
\text{5.} \; \omega(f(x)) =  \{ g : \lim_{n \rightarrow \infty} \frac{f(x)}{g(x)} = 0 \} \quad \text{(여유있는 하한)} \\
$$

- 여담으로 보통 빅-오를 세타로 표기하는 경우가 많은 듯..

---

### 2. 점화식과 점근적 복잡도 분석

- 점화식으로 표현된 시간 복잡도를 단일식으로 표현하는 방법을 배운다.  
- 반복 대치, 추정 후 증명, 마스터 정리 세 가지 방법이 있다.  
- 반복 대치는 식을 반복하여 계산하는 방법이다. 예를 들어 T(n) <= T(n/2) + n 이라고 하면 
T(n) <= T(n/2) + n <= n + n/2 + T(n/4) <= ... = O(n * log2 n]) 이 성립한다.  
- 추정 후 증명은 말 그대로 추정 후 증명하는 방법이다. 수학적 귀납법 등이 증명에 사용된다.  
- 마스터 정리는 T(n) = aT(n/b) + f(n) 의 형식으로 표현되는 재귀식의 복잡도를 알 수 있는 정리이다.  
- n^(logb a) = h(n) 이라고 하면
- h(n) 이 더 복잡하면 h(n) 이, f(n) 이 더 복잡하면 f(n) 이 수행시간을, 똑같으면 logn * h(n) (또는 동일하게 f(n)) 이 수행시간을 지배한다는 정리이다.

---

### 3. 정렬

- 선택정렬의 의사코드는 아래와 같다.
```
1. 배열의 길이가 n 인 배열에서 최대값을 찾는다.  
2. 배열의 마지막 위치에 있는 값과 최대값의 위치를 바꾼다.    
3. 배열의 길이가 n - 1 이라고 가정하여 위 가정을 반복한다.  
```

- 버블정렬의 의사코드는 아래와 같다.
```
1. 첫 번째와 두 번째 원소를 비교하여 첫 번째 원소가 크면 위치를 변경한다.  
2. 두 번째와 세 번째 원소를 비교하여 두 번째 원소가 크면 위치를 변경한다.  
...
위 과정을 거치면 제일 마지막에 최대값이 위치하게 된다.  
위 과정을 배열의 길이가 n 일 때 했다고 가정하면 이후 배열의 길이가 n - 1 이라 가정하여 위 가정을 반복한다.
```

- 삽입정렬의 의사코드는 아래와 같다.
```
첫 번째 원소는 무조건 정렬되어 있다.
두 번째 원소를 비교하여 정렬한다.
세 번째 원소와 위 두 개 값이 정렬된 배열을 비교하여 정렬한다.
네 번째 원소와 위 세 개 값이 정렬된 배열을 비교하여 정렬한다.
...
위 과정을 반복한다.
```

- 병합정렬의 의사코드는 아래와 같다.
```
배열을 위치를 기준으로 반으로 나눈다.
왼쪽 배열을 병합정렬을 사용하여 정렬한다.
오른쪽 배열을 병합정렬을 사용하여 정렬한다.
왼쪽 배열과 오른쪽 배열을 삽입 정렬을 응용하여 정렬한다.
```

- 퀵정렬의 의사코드는 아래와 같다.
```
1. 배열에 있는 임의의 값을 기준으로 왼쪽에 위치한 원소는 기준값보다 작도록,  
오른쪽에 위치한 값은 기준값보다 크도록 불완전하게 정렬한다.
2. 왼쪽 배열을 1. 의 과정을 반복하여 완벽한 정렬을 만든다.  
3. 오른쪽 배열을 1. 의 과정을 반복하여 완벽한 정렬을 만든다.
```

- 힙정렬의 의사코드는 아래와 같다.
```
1. 배열의 원소를 차례대로 힙에 삽입한다.  
2. 힙에서 차례대로 원소를 빼내어 배열에 채운다.  
(힙은 특별한 트리 중 하나로 루트 노드에 High Priority 를 갖는 원소가 위치한다.)
```

- 결정트리를 활용하면 두 원소 간의 비교가 필요한 정렬은 최소 O(n*log n) 의 시간복잡도가 필요함을 증명할 수 있다.  

- 기수정렬의 의사코드는 아래와 같다.  
```
1. 각 원소의 길이가 같고 그 가능성이 제한된 배열이 존재할 때 (ex. 네자리 수만으로 배열이 구성되어 있을 때)
2. 가장 적은 영향을 미치는 원소 내 위치를 기준으로 bucket 를 만들어 정렬한다. (ex. 1의 자리수로 배열한다.)
3. 차례대로 큰 영향을 미치는 원소 내 위치를 기준으로 bucket 을 만들어 정렬을 수행한다.
```

- 계수정렬의 의사코드는 아래와 같다.
```
1. 각 원소의 존재 가능한 값이 제한되어 있을 때  
2. counter 를 만들어서 배열을 순회하여 원소의 개수를 구한다.  
3. counter 에서 차례대로 빼냄으로써 정렬을 수행한다.
```

- 위 두 정렬은 원소의 형태에 제한을 함으로써 O(n) 의 성능을 낼 수 있는 특수한 정렬 중 하나이다.  

---

### 4. 선택 알고리즘

- k 번 째로 작은 원소를 탐색하기 위해 퀵 정렬을 응용하여 임의의 기준값을 바탕으로 배열의 원소를 줄여가면서 탐색할 수 있다.  
- 최악의 경우에 O(n^2) 이 소요되나 평균적으로 O(n) 이 소요된다.  
- linear select 를 사용하면 최악의 경우에도 선형시간이 보장되지만 오버헤드가 클 수 있다.  
- linear select 가 선형시간이 보장되는 이유는 M 을 기준으로  
왼쪽 배열과 오른쪽 배열의 비율이 차이가 나봤자 최대 1:3 이라는 것이 보장되기 때문이다.
```
Linear Select
1. 원소의 총 수가 5개 이하이면 원하는 원소를 찾고 알고리즘을 끝낸다.  
2. 배열을 배열의 길이가 5개로 이루어진 sub 배열들로 나누어 각 배열의 중앙값을 구한다.  
3. 중앙값들의 중앙값을 Linear Select 를 호출하여 구하고 이를 M 이라고 한다.
4. M 을 기준으로 퀵정렬과 유사하게 배열을 분할하고, 적합합 그룹을 기준으로 Linear Select 를 호출한다.
```
---

### 5. 검색트리

- 다양한 검색트리에 대해서 배우는 챕터이다.
- 각 트리마다의 특성과 삽입, 삭제하는 의사코드를 다 적기에는 어려우므로 그 컨셉만 기술하도록 하겠다.


- 이진검색트리란 검색트리의 기본이 되는 트리로 아래와 같은 특성을 갖는다.
```
1) 최상위 루트 노드가 있고, 각 노드는 최대 두 개의 자식 노드를 갖는다.  
2) 임의의 노드의 키 값은 자신의 왼쪽 서브트리의 임의의 키값보다 크고, 오른쪽 서브트리의 임의의 키값보다 작다.
3) 왼쪽 서브트리와 오른쪽 서브트리도 이진검색트리의 특성을 만족한다.
```
- 이진검색트리는 최선의 경우에 O(log n) 의 성능을 갖게 되나,  
삽입 및 삭제 순서에 따라 노드가 일렬로 배치되어 O(n) 의 성능을 갖게될 가능성이 존재한다.


- 레드블랙트리는 이진트리를 응용한 트리로 아래와 같은 특성을 갖는다.
```
1) 각 노드는 블랙 또는 레드의 색상을 갖는다.
2) 루트는 블랙이다.
3) 모든 리프(NIL) 은 블랙이다.
4) 노드가 레드이면 그 노드의 자식은 반드시 블랙이다.
5) 루트 노드에서 임의의 리프 노드에 이르는 경로에서 만나는 블랙 노드의 수는 모두 같다.
** 레드블랙트리에서의 리프 노드는 다른 트리에서와 다르게 NIL 로 가정한다.
```
![](/assets/img/computer_science_algorithms/red-black-tree.png)


- 레드노드가 연이어 나올 수 없고, 리프노드까지 갈 때에 마주치는 블랙노드 수가 같다는 특성 때문에 레드블랙트리의 높이는 완전이진트리의 높이의 두 배를 넘지 못한다.  
- 삽입할 때에 이진트리와 같은 방법으로 삽입한 후 삽입 노드에 레드 색상을 부여한다.  
레드 색상을 부여하면 임의의 리프 노드까지 이르는 경로에서 마주치는 블랙 노드의 수가 같다는 조건을 충족한다.  
한편 부모노드가 레드 색상이면 조건을 위반하게 되어 이 문제를 해결하기 위해 부모의 부모 노드까지 고려하여 이 문제를 해결한다.  
- 삭제할 때에 이진트리와 같은 방법으로 리프 노드와 해당 노드의 값을 바꾼 후 리프 노드를 삭제한다.  
삭제하는 리프 노드가 레드 색상이면 조건을 모두 충족시키므로 문제가 없지만,  
블랙 노드라면 임의의 리프 노드까지 이르는 경로에서 마주치는 블랙 노드의 수가 같다는 조건이 위반되어 이를 해결하기 위해 이 문제를 해결하기 위해 부모의 부모 노드까지 고려하여 이 문제를 해결한다.  


- B Tree 는 디스크에 저장된 정보에 대하여 접근할 때 주로 사용되는 트리이다.
- 디스크에 접근하는 알고리즘에서 그 성능은 디스크 접근 횟수에 크게 좌우되므로 접근 횟수를 줄이는 것이 성능에 좋은 영향을 미친다.
- DB Index 등에서 응용된다.  
- B Tree 는 균형잡힌 다진검색트리로 다음의 성질을 만족한다.  
```
1) 루트를 제외한 모든 노드는 [k/2] ~ k 개의 키를 갖는다.
2) 모든 리프 노드는 같은 깊이를 갖는다.
```
- 다른 트리와 다르게 아래처럼 키 값을 경계점으로 하여 서브트리가 연결되어 있다.  
![](/assets/img/computer_science_algorithms/B-tree.png)


- 삽입할 때에 해당 위치를 찾고 그 공간에 여유가 있으면 삽입하며 완료된다.  
- 공간에 여유가 없으면 형제 노드를 살펴보고 형제 노드에 키를 넘기며 완료된다.  
- 형제 노드에 여유가 없으면 노드를 두 개로 분리한다. 이러한 오버플로우는 부모 노드에서 발생할 수 있는데 이 역시 재귀적으로 해결한다.  
- 삭제할 때에 이진검색트리와 마찬가지로 삭제 노드를 찾아 리프 노드와 값을 바꾼 후 리프 노드를 삭제한다.  
- 삭제 후 언더플로우가 생기면 병합 과정을 거쳐 해결한다.


- 아래부터는 복수 개의 키 값을 갖는 레코드로 구성되는 트리이다.  


- KD-트리란 이진 검색트리를 확장한 것으로 k개의 필드로 이루어진 키를 사용한다.
- 각 레벨을 하나의 차원만을 다루고, 필드 별로 순회하며 트리를 구성하게 된다.  
- 예를 들어 레코드가 (x, y, z) 의 3차원으로 구성되어 있다면 첫 번째에서는 x 를 기준으로 분기하고, 두 번째에서는 y 를, 세 번째에서는 z 를, 네 번째에서는 다시 x 를 사용하여 분기를 수행한다.  
- 검색과 삽입은 이진검색트리를 단순히 확장한 것이라고 볼 수 있다.
- 반면 삭제할 때에는 각 레별 별로 분기의 기준이 되는 필드가 다르므로 이를 적절히 고려하여 분기를 재조정해야 한다.
- 반면 특정 필드의 최소값을 찾는 문제는 이진트리보다 복잡하다. 왜냐하면 각 레벨 별로 분기에 사용되는 필드가 달라 다수의 경로를 탐색해야 하기 때문이다.


- KDB-트리란 다차원 검색을 다룰 수 있도록 B Tree 를 확장한 것이다. 기본적으로 B Tree 를 확장한 것이므로 B tree 의 성질을 충족한다.
- B Tree 는 각 노드가 키 값에 의해 분기하지만 KDB 트리는 각 노드가 영역에 의해서 분기한다.  
- KDB 트리의 노드는 다음의 두 종류가 있다.  
```
영역 노드: 복수 개의 (영역, 페이지 번호) 쌍으로 구성된다. 모든 내부 노드는 영역 노드이다.
키 노드: 복수 개의 (키, 페이지 번호) 쌍으로 구성된다. 모든 리프 노드는 키 노드이다.
```
- k 차원의 키를 사용한다면 영역은 (<min1 , max1 >, <min2 , max2 >, ..., <min k, max k>) 처럼 나뉜다.
- 영역 노드 간에 영역이 겹치는 경우는 없다.
- KDB 트리에서의 키 검색은 루트 노드부터 시작해서 해당 키가 포함되는 영역을 따라 리프 노드까지 내려가면 되므로 간단하다.
- KDB 트리에서는 영역으로 노드를 나누므로 영역 검색도 가능하다.
- 삽입과 삭제는 B-Tree 와 유사하다. 해당 키가 포함되는 영역에 키를 삽입한 후 오버플로우가 발생하면 영역을 적절히 분할한다.
- 내부 노드는 모두 영역 노드이므로 직접적인 삭제가 발생할 수 없다. 즉 삭제는 리프노드에서 발생하고, 언더플로우가 발생하면 영역을 적절히 병합한다.


- R-트리란 KDB-Tree 와 마찬가지로 다차원 검색을 다룰 수 있도록 B-Tree 를 확장한 것이다. 기본적으로 B Tree 를 확장한 것이므로 B tree 의 성질을 충족한다.
- KDB 트리와 다른 점은 KDB 트리는 영역 노드를 구성할 때에 전체 영역(각 필드별 최소값과 최대값) 을 기준으로 영역을 분할하는데,  
R 트리는 레코드의 키 값을 고려하여 영역을 구성한다. 예를 들어 키가 (x, y) 일 때에 x 와 y 가 거의 일직선 상에 놓여있다면 반대 일직선 상에 위치한 영역에 대해서는 해당하는 영역 노드를 구성하지 않는다.  
R 트리를 구성하는 영역은 KDB 트리와 다르게 disjoint 하지 않아 검색 경로가 유일하지 않을 수 있다.  
- 이러한 문제를 개선하여 각 영역이 겹치지 않도록 R Tree 를 확장한 것이 R* Tree 이다.
- 삽입과 삭제는 B Tree, KDB Tree 와 유사한 컨셉으로 진행된다.


- 검색트리는 아니지만 유사한 컨셉을 갖는 그리드 파일이라는 개념이 존재하여 이를 소개하도록 한다.
- 그리드파일은 KDB 트리와 마찬가지로 각 영역을 분할하여 레코드를 저장한다.
- 각 영역은 경계점을 기준으로 구분되며 삽입 및 삭제 시 적절히 영역을 분할 및 병합한다.
- 각 영역은 그 크기에 따라 같은 페이지에 저장되어 있을 수도 있다.
- 데이터 접근을 위해 일차배열 스케일링에 대한 접근과 해당 페이지로의 접근만 하면 되므로 두 번의 디스크 접근으로 데이터에 접근할 수 있다는 장점이 있다.

---

### 6. 해시 테이블

- 해시 테이블은 원소끼리 비교해 자리를 찾는 것이 아니라 자신의 값이 저장되는 자리를 바로 결정한다.
- 해시 테이블에 원소가 차 있는 비율을 적재율(Load Factor) 라고 하고, 이는 해시 테이블의 성능에 중요한 영향을 미친다.
- 두 원소의 해시값이 동일한 경우 같은 자리에 삽입하려고 하는 상황이 발생하고, 이를 충돌(Collision) 이라고 한다.
- 해시 함수는 입력 원소가 테이블 전체에 균등하게 저장되도록 해시 값을 산출해야 하며, 계산이 간단해야 한다.
- 해시 함수를 만드는 대표적인 두 가지 방법은 나누기와 곱하기이다.  

```
m 은 해시 테이블의 크기이다.

1) 나누기 방법
- h(x) = x mod m
- m 은 2의 멱수에 가깝지 않은 소수를 택하는 것이 좋다. 
- 만일 m = 2^p 라면 하위 p 개 비트에 의해 해시값이 결정되어 분산시키기 어렵기 때문이다.

2) 곱하기 방법
- h(x) = [m (xA mod 1)]
- m 은 해시 테이블의 크기이고, A 는 해시 함수의 특성을 결정짓는 상수이다.
- 나누기 방법과 다르게 m 의 선택에 제한이 없다. 그러나 컴퓨터 환경에 맞게 보통 m = 2^p 로 잡는다.
```


- 체이닝 방법은 같은 주소로 해싱되는 원소를 하나의 연결 리스트에 매달아 관리하는 방법이다.
- 효율성 측면에서 새로 삽입되는 원소는 연결리스트에 제일 앞에 위치한다.
- Load Factor 가 1 을 초과하여도 사용할 수 있다.


- 개방주소(Open Addressing) 방법은 체이닝과 같은 추가 공간을 허용하지 않는다.
- 체이닝 방법과 다르게 Load Factor 가 1을 초과할 수 없다.
- 해시 함수를 0 번째 해시 함수, 충돌이 한 번 일어났을 때 다음 주소를 계산하는 것을 두 번째 해시 함수, ... 와 같이 여러 개의 해시 함수를 사용한다.
- 다음 주소를 결정짓는 대표적인 세 가지 방법은 선형조사, 이차조사, 더블 해싱이다.
- 개방주소 방식에서 특정 원소를 삭제한 후 검색을 하게 되면 해당 원소가 존재하더라도 그 경로 상에 데이터가 없어서 탐색되지 않는 문제가 발생할 수 있다.
- 따라서 삭제한 후에 DELETED 라는 상수값으로 대체하여 이후 충돌 해결 해시 값에 위치한 원소에 대하여도 탐색할 수 있도록 해야 한다.

```
선형조사 방법
h_i(x) = h(x) + i mod m
- 간단한 충돌 해결 방법으로 특정 영역에 원소가 몰릴 때에 치명적으로 성능이 떨어진다.
- 이러한 현상을 1차 군집(Primary Clustering) 이라고 한다.
```


```
이차조사 방법
h_i(x) = h(x) + a*i^2 + b*i mod m
- 해시 값이 특정 영역에 집중되어도 해당 영역을 선형조사 방법보다 빠르게 벗어날 수 있다는 장점이 있다.
- 그러나 여러 개의 원소가 동일한 초기 해시 값을 갖게 되면 똑같은 경로를 탐색하게 되므로 2차 군집(Secondary Clustering) 이 발생한다.
```


```
더블해싱
h_i(x) = h(x) + if(x) mod m
- 서로 다른 두 해시 함수를 갖고 해시값을 계산한다. 1차 군집과 2차 군집 현상이 발생하지 않는다.
- 권장되는 방법은 h(x) = x mod m 으로 잡고 f(x) = 1 + (x mod m') 으로 정하는 것이다. 이 때 m' 은 m 보다 조금 작은 소수이다.
```